#!/bin/bash
#
# Polis - Decentralized Social Network CLI
#
# Dependencies:
#   - ssh-keygen (OpenSSH 8.0+ for Ed25519 signing with -Y flag)
#   - jq (JSON processor for index management and JSON mode)
#   - curl (for API communication with discovery service)
#   - sha256sum or shasum (for content hashing)
#   - git (optional, for version control integration)
#   - pandoc (optional, for render command - markdown to HTML conversion)
#   - Standard Unix tools: date, sed, grep, mktemp, realpath/readlink
#
# Installation:
#   Linux:   sudo apt-get install openssh-client jq curl coreutils git pandoc
#   macOS:   brew install openssh jq curl coreutils git pandoc
#

set -e

# ============================================================================
# CONFIGURATION LOADING
# ============================================================================
# Precedence (highest to lowest):
#   1. Environment variables
#   2. .env file
#   3. .well-known/polis config section
#   4. Hardcoded defaults

# Fixed constants (never configurable - required for discovery)
VERSION="0.34.0"
WELL_KNOWN_DIR=".well-known"
WELL_KNOWN_FILE="polis"

# Load .env file with validation (does not override existing env vars)
load_env_file() {
    local env_file="${1:-.env}"
    [ ! -f "$env_file" ] && return 0

    while IFS='=' read -r key value || [ -n "$key" ]; do
        # Skip comments, empty lines
        [[ "$key" =~ ^[[:space:]]*# ]] && continue
        [[ -z "$key" ]] && continue

        # Trim whitespace from key
        key="${key#"${key%%[![:space:]]*}"}"
        key="${key%"${key##*[![:space:]]}"}"

        # Skip if key is empty or contains invalid characters
        [[ ! "$key" =~ ^[A-Za-z_][A-Za-z0-9_]*$ ]] && continue

        # Trim whitespace and quotes from value
        value="${value#"${value%%[![:space:]]*}"}"
        value="${value%"${value##*[![:space:]]}"}"
        value="${value%\"}"
        value="${value#\"}"
        value="${value%\'}"
        value="${value#\'}"

        # Only set if not already defined in environment
        if [ -z "${!key+x}" ]; then
            export "$key=$value"
        fi
    done < "$env_file"
}

# Load user config from .well-known/polis JSON
load_wellknown_config() {
    local config_file="$WELL_KNOWN_DIR/$WELL_KNOWN_FILE"
    [ ! -f "$config_file" ] && return 0

    # Check if jq is available
    command -v jq > /dev/null 2>&1 || return 0

    # Extract config values (only if not already set)
    local config_json
    config_json=$(jq -r '.config // empty' "$config_file" 2>/dev/null) || return 0
    [ -z "$config_json" ] && return 0

    # Directory config
    [ -z "${KEYS_DIR+x}" ] && KEYS_DIR=$(echo "$config_json" | jq -r '.directories.keys // empty')
    [ -z "${POSTS_DIR+x}" ] && POSTS_DIR=$(echo "$config_json" | jq -r '.directories.posts // empty')
    [ -z "${COMMENTS_DIR+x}" ] && COMMENTS_DIR=$(echo "$config_json" | jq -r '.directories.comments // empty')
    [ -z "${SNIPPETS_DIR+x}" ] && SNIPPETS_DIR=$(echo "$config_json" | jq -r '.directories.snippets // empty')
    [ -z "${THEMES_DIR+x}" ] && THEMES_DIR=$(echo "$config_json" | jq -r '.directories.themes // empty')
    [ -z "${VERSIONS_DIR_NAME+x}" ] && VERSIONS_DIR_NAME=$(echo "$config_json" | jq -r '.directories.versions // empty')

    # File config
    [ -z "${PUBLIC_INDEX+x}" ] && PUBLIC_INDEX=$(echo "$config_json" | jq -r '.files.public_index // empty')
    [ -z "${BLESSED_COMMENTS+x}" ] && BLESSED_COMMENTS=$(echo "$config_json" | jq -r '.files.blessed_comments // empty')
    [ -z "${FOLLOWING_INDEX+x}" ] && FOLLOWING_INDEX=$(echo "$config_json" | jq -r '.files.following_index // empty')
    [ -z "${SNIPPETS_INDEX+x}" ] && SNIPPETS_INDEX=$(echo "$config_json" | jq -r '.files.snippets_index // empty')
}

# Apply hardcoded defaults for any unset variables
apply_defaults() {
    # Developer config defaults
    : "${POLIS_BASE_URL:=}"
    : "${DISCOVERY_SERVICE_URL:=https://ltfpezriiaqvjupxbttw.supabase.co/functions/v1}"
    : "${DISCOVERY_SERVICE_KEY:=}"

    # Derived endpoints (always computed from base)
    POLIS_BESEECH_ENDPOINT="${DISCOVERY_SERVICE_URL}/comments-blessing-beseech"
    POLIS_BLESSING_REQUESTS_ENDPOINT="${DISCOVERY_SERVICE_URL}/comments-blessing-requests"
    POLIS_BLESS_ENDPOINT="${DISCOVERY_SERVICE_URL}/comments-blessing-grant"
    POLIS_DENY_ENDPOINT="${DISCOVERY_SERVICE_URL}/comments-blessing-deny"
    POLIS_COMMENTS_ENDPOINT="${DISCOVERY_SERVICE_URL}/comments"

    # User directory defaults
    : "${KEYS_DIR:=.polis/keys}"
    : "${POSTS_DIR:=posts}"
    : "${COMMENTS_DIR:=comments}"
    : "${SNIPPETS_DIR:=snippets}"
    : "${THEMES_DIR:=.polis/themes}"
    : "${VERSIONS_DIR_NAME:=.versions}"

    # User file defaults
    : "${PUBLIC_INDEX:=metadata/public.jsonl}"
    : "${BLESSED_COMMENTS:=metadata/blessed-comments.json}"
    : "${FOLLOWING_INDEX:=metadata/following.json}"
    : "${SNIPPETS_INDEX:=metadata/snippets.jsonl}"
    : "${MANIFEST:=metadata/manifest.json}"

    # Notification files (private, in .polis/)
    : "${NOTIFICATIONS_FILE:=.polis/notifications.jsonl}"
    : "${NOTIFICATIONS_MANIFEST:=.polis/notifications-manifest.json}"
}

# Main configuration initialization
init_config() {
    load_env_file ".env"
    load_wellknown_config
    apply_defaults
}

# Initialize configuration immediately
init_config

# Colors for output
GREEN='\033[0;32m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
RED='\033[0;31m'
BOLD='\033[1m'
DIM='\033[2m'
NC='\033[0m' # No Color

# JSON output mode flag
JSON_MODE=false

# Helper function for colored output
info() {
    echo -e "${CYAN}[i]${NC} $1"
}

success() {
    echo -e "${GREEN}[âœ“]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[!]${NC} $1" >&2
}

error() {
    echo -e "${RED}[x]${NC} $1" >&2
    exit 1
}

# JSON-aware output helpers
json_success() {
    local command="$1"
    local data="$2"

    if [ "$JSON_MODE" = true ]; then
        jq -n \
            --arg cmd "$command" \
            --argjson data "$data" \
            '{status: "success", command: $cmd, data: $data}'
    fi
}

json_error() {
    local command="$1"
    local code="$2"
    local message="$3"
    local details="${4:-{}}"

    if [ "$JSON_MODE" = true ]; then
        jq -n \
            --arg cmd "$command" \
            --arg code "$code" \
            --arg msg "$message" \
            --argjson details "$details" \
            '{status: "error", command: $cmd, error: {code: $code, message: $msg, details: $details}}' >&2
    else
        error "$message"
    fi
    exit 1
}

# Conditional output - only shows in human mode
info_human() {
    if [ "$JSON_MODE" = false ]; then
        info "$1"
    fi
}

success_human() {
    if [ "$JSON_MODE" = false ]; then
        success "$1"
    fi
}

warn_human() {
    if [ "$JSON_MODE" = false ]; then
        warn "$1"
    fi
}

# Print to stderr in JSON mode (for showing defaults)
# NOTE: Disabled - output interferes with tools that capture stderr
log_default() {
    :  # No-op - info is redundant with JSON response
}

# Command: polis init
cmd_init() {
    # Parse optional arguments for custom paths
    local custom_keys_dir=""
    local custom_posts_dir=""
    local custom_comments_dir=""
    local custom_snippets_dir=""
    local custom_themes_dir=""
    local custom_public_index=""
    local custom_blessed_comments=""
    local custom_following_index=""
    local custom_snippets_index=""
    local custom_versions_dir=""
    local custom_site_title=""
    local auto_register=false

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --keys-dir)
                custom_keys_dir="$2"
                shift 2
                ;;
            --posts-dir)
                custom_posts_dir="$2"
                shift 2
                ;;
            --comments-dir)
                custom_comments_dir="$2"
                shift 2
                ;;
            --snippets-dir)
                custom_snippets_dir="$2"
                shift 2
                ;;
            --themes-dir)
                custom_themes_dir="$2"
                shift 2
                ;;
            --public-index)
                custom_public_index="$2"
                shift 2
                ;;
            --blessed-comments)
                custom_blessed_comments="$2"
                shift 2
                ;;
            --following-index)
                custom_following_index="$2"
                shift 2
                ;;
            --snippets-index)
                custom_snippets_index="$2"
                shift 2
                ;;
            --versions-dir)
                custom_versions_dir="$2"
                shift 2
                ;;
            --site-title)
                custom_site_title="$2"
                shift 2
                ;;
            --register)
                auto_register=true
                shift
                ;;
            *)
                error "Unknown option: $1. Use 'polis help init' for usage."
                ;;
        esac
    done

    # Apply custom paths (override defaults for this init)
    local keys_dir="${custom_keys_dir:-$KEYS_DIR}"
    local posts_dir="${custom_posts_dir:-$POSTS_DIR}"
    local comments_dir="${custom_comments_dir:-$COMMENTS_DIR}"
    local snippets_dir="${custom_snippets_dir:-$SNIPPETS_DIR}"
    local themes_dir="${custom_themes_dir:-$THEMES_DIR}"
    local public_index="${custom_public_index:-$PUBLIC_INDEX}"
    local blessed_comments="${custom_blessed_comments:-$BLESSED_COMMENTS}"
    local following_index="${custom_following_index:-$FOLLOWING_INDEX}"
    local snippets_index="${custom_snippets_index:-$SNIPPETS_INDEX}"
    local versions_dir="${custom_versions_dir:-$VERSIONS_DIR_NAME}"

    # Derive metadata directory from file paths
    local metadata_dir=$(dirname "$public_index")

    info_human "Initializing Polis directory structure..."

    # Track created items for JSON output
    local dirs_created=()
    local files_created=()

    # Create directory structure
    mkdir -p "$keys_dir"
    mkdir -p "$posts_dir"
    mkdir -p "$comments_dir"
    mkdir -p "$snippets_dir"
    mkdir -p "$themes_dir"
    mkdir -p "$metadata_dir"
    mkdir -p "$WELL_KNOWN_DIR"

    dirs_created=("$keys_dir" "$posts_dir" "$comments_dir" "$snippets_dir" "$themes_dir" "$metadata_dir" "$WELL_KNOWN_DIR")
    success_human "Created directory structure"

    # Generate Ed25519 keypair
    if [ -f "$keys_dir/id_ed25519" ]; then
        json_error "init" "INVALID_STATE" "Keys already exist at $keys_dir/id_ed25519"
    fi

    info_human "Generating Ed25519 keypair..."
    ssh-keygen -t ed25519 -f "$keys_dir/id_ed25519" -N "" -C "polis@$(hostname)" > /dev/null 2>&1
    success_human "Generated Ed25519 keypair at $keys_dir/"

    # Get public key for metadata
    PUBKEY=$(cat "$keys_dir/id_ed25519.pub")

    # Create .well-known/polis metadata file with config section
    cat > "$WELL_KNOWN_DIR/polis" << EOF
{
  "version": "$VERSION",
  "author": "$(git config user.name || echo 'Unknown')",
  "email": "$(git config user.email || echo 'unknown@example.com')",
  "public_key": "$PUBKEY",
  "created": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "config": {
    "directories": {
      "keys": "$keys_dir",
      "posts": "$posts_dir",
      "comments": "$comments_dir",
      "snippets": "$snippets_dir",
      "themes": "$themes_dir",
      "versions": "$versions_dir"
    },
    "files": {
      "public_index": "$public_index",
      "blessed_comments": "$blessed_comments",
      "following_index": "$following_index",
      "snippets_index": "$snippets_index"
    }
  }
}
EOF
    files_created+=(".well-known/polis")
    success_human "Created $WELL_KNOWN_DIR/polis metadata"

    # Create empty public.jsonl index
    > "$public_index"
    files_created+=("$public_index")
    success_human "Created $public_index index"

    # Create empty blessed-comments.json
    cat > "$blessed_comments" << EOF
{
  "version": "$VERSION",
  "comments": []
}
EOF
    files_created+=("$blessed_comments")
    success_human "Created $blessed_comments"

    # Create empty following.json
    cat > "$following_index" << EOF
{
  "version": "$VERSION",
  "following": []
}
EOF
    files_created+=("$following_index")
    success_human "Created $following_index"

    # Create empty snippets.jsonl index
    > "$snippets_index"
    files_created+=("$snippets_index")
    success_human "Created $snippets_index index"

    # Create initial manifest.json
    local manifest_path="$metadata_dir/manifest.json"
    if [ -n "$custom_site_title" ]; then
        jq -n \
            --arg version "$VERSION" \
            --arg last_published "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
            --arg site_title "$custom_site_title" \
            '{
                version: $version,
                last_published: $last_published,
                post_count: 0,
                comment_count: 0,
                site_title: $site_title
            }' > "$manifest_path"
    else
        jq -n \
            --arg version "$VERSION" \
            --arg last_published "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
            '{
                version: $version,
                last_published: $last_published,
                post_count: 0,
                comment_count: 0
            }' > "$manifest_path"
    fi
    files_created+=("$manifest_path")
    success_human "Created $manifest_path"

    # Create .gitignore if it doesn't exist
    local private_key_path="$keys_dir/id_ed25519"
    if [ ! -f ".gitignore" ]; then
        cat > ".gitignore" << EOF
.polis/
/themes
/polis
/polis-tui
.env*
EOF
        files_created+=(".gitignore")
        success_human "Created .gitignore (excludes private key)"
    fi

    # Copy .env.example to .env if .env doesn't exist
    local env_created=false
    if [ ! -f ".env" ]; then
        local script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
        local cli_dir="$(dirname "$script_dir")"
        local env_example="$cli_dir/.env.example"

        if [ -f "$env_example" ]; then
            cp "$env_example" ".env"
            files_created+=(".env")
            env_created=true
            success_human "Created .env from .env.example"
            warn "Please update .env with your configuration values"
        fi
    fi

    # Copy default themes from same directory as polis script
    local themes_copied=()

    # Resolve the actual script location (follow symlinks)
    local script_path="${BASH_SOURCE[0]}"
    while [ -L "$script_path" ]; do
        local link_dir="$(cd "$(dirname "$script_path")" && pwd)"
        script_path="$(readlink "$script_path")"
        [[ "$script_path" != /* ]] && script_path="$link_dir/$script_path"
    done
    local script_dir="$(cd "$(dirname "$script_path")" && pwd)"
    local source_themes_dir="$script_dir/themes"

    if [ -d "$source_themes_dir" ]; then
        for theme_path in "$source_themes_dir"/*; do
            if [ -d "$theme_path" ]; then
                local theme_name=$(basename "$theme_path")
                local dest_theme="$themes_dir/$theme_name"
                if [ ! -d "$dest_theme" ]; then
                    cp -r "$theme_path" "$dest_theme"
                    themes_copied+=("$theme_name")
                fi
            fi
        done
        if [ ${#themes_copied[@]} -gt 0 ]; then
            success_human "Installed themes: ${themes_copied[*]}"
        fi
    else
        warn "Theme files not found at $source_themes_dir"
        info_human "Themes must be manually copied to $themes_dir"
    fi

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local themes_json="[]"
        if [ ${#themes_copied[@]} -gt 0 ]; then
            themes_json=$(printf '%s\n' "${themes_copied[@]}" | jq -R . | jq -s .)
        fi
        local result=$(jq -n \
            --argjson dirs "$(printf '%s\n' "${dirs_created[@]}" | jq -R . | jq -s .)" \
            --argjson files "$(printf '%s\n' "${files_created[@]}" | jq -R . | jq -s .)" \
            --argjson themes "$themes_json" \
            --arg private_key "$keys_dir/id_ed25519" \
            --arg public_key "$keys_dir/id_ed25519.pub" \
            --argjson env_created "$env_created" \
            '{
                directories_created: $dirs,
                files_created: $files,
                themes_installed: $themes,
                key_paths: {
                    private: $private_key,
                    public: $public_key
                },
                env_created: $env_created
            }')
        json_success "init" "$result"
    else
        success "Polis initialization complete!"
        info "Your public key has been added to $WELL_KNOWN_DIR/polis"
        info "Private key stored at $keys_dir/id_ed25519 (not committed to git)"
        if [ ${#themes_copied[@]} -gt 0 ]; then
            info "Themes installed: ${themes_copied[*]}"
        fi
        if [ "$env_created" = true ]; then
            echo ""
            warn "ACTION REQUIRED: Update .env with your configuration values:"
            info "  - POLIS_BASE_URL: Your site's public URL"
            info "  - DISCOVERY_SERVICE_KEY: Your API key for blessing operations"
        fi
    fi

    # Auto-register if requested
    if [ "$auto_register" = true ]; then
        if [ -z "$POLIS_BASE_URL" ]; then
            if [ "$JSON_MODE" != true ]; then
                echo ""
                warn "Cannot auto-register: POLIS_BASE_URL not set"
                info "Set it with: export POLIS_BASE_URL=https://yourdomain.com"
            fi
        elif [ -z "$DISCOVERY_SERVICE_URL" ] || [ -z "$DISCOVERY_SERVICE_KEY" ]; then
            if [ "$JSON_MODE" != true ]; then
                echo ""
                warn "Cannot auto-register: Discovery service not configured"
                info "Set DISCOVERY_SERVICE_URL and DISCOVERY_SERVICE_KEY in .env"
            fi
        else
            if [ "$JSON_MODE" != true ]; then
                echo ""
                info_human "Auto-registering with discovery service..."
            fi
            cmd_register
        fi
    fi
}

# Check if file has frontmatter
has_frontmatter() {
    local file="$1"
    [ "$(head -n 1 "$file")" = "---" ]
}

# Extract content without frontmatter
extract_content_without_frontmatter() {
    local file="$1"
    # Skip everything from first --- to second ---, then output the rest
    awk '/^---$/{if(++count==2){skip=0; next} skip=1; next} !skip' "$file"
}

# Extract frontmatter field value
extract_frontmatter_field() {
    local file="$1"
    local field="$2"
    awk -v field="$field:" '/^---$/{if(++count==2) exit} count==1 && $0 ~ "^"field{sub("^"field" *", ""); print; exit}' "$file"
}

# Extract version history lines
extract_version_history() {
    local file="$1"
    # More robust: extract all lines that are version entries
    # Start after version-history: and stop at next top-level field
    sed -n '/^version-history:/,/^[a-z-]/p' "$file" | grep '^  - sha256:' || true
}

# Extract in-reply-to section (for comments)
extract_in_reply_to() {
    local file="$1"
    # Extract the url and version lines from in-reply-to section
    sed -n '/^in-reply-to:/,/^[a-z-]/p' "$file" | grep -E '^  (url|version):' || true
}

# Extract title from first # heading in markdown file
extract_title() {
    local file="$1"
    # Find first line starting with # and extract the title
    local title=$(grep -m 1 '^#\s' "$file" | sed 's/^#\s*//')
    if [ -z "$title" ]; then
        # Fallback to filename without extension
        title=$(basename "$file" .md | sed 's/-/ /g' | awk '{for(i=1;i<=NF;i++)sub(/./,toupper(substr($i,1,1)),$i)}1')
    fi
    echo "$title"
}

# Canonicalize content by trimming trailing whitespace/newlines
# This ensures consistent signing/hashing regardless of editor or transfer differences
# Result always ends with exactly one newline
canonicalize_content() {
    local content="$1"
    local trimmed
    # Remove trailing whitespace from each line, then remove trailing empty lines
    # Finally add exactly one newline at the end
    # Note: /^$/ matches empty lines, the pattern accumulates trailing empties and deletes at EOF
    trimmed=$(printf '%s' "$content" | sed -e 's/[[:space:]]*$//' -e ':a' -e '/^$/{ $d; N; ba; }')
    printf '%s\n' "$trimmed"
}

# Canonicalize file content (reads file, canonicalizes, outputs to stdout)
canonicalize_file() {
    local file="$1"
    canonicalize_content "$(cat "$file")"
}

# Calculate SHA-256 hash of file content
hash_content() {
    local file="$1"
    # Hash the entire file content
    if command -v sha256sum > /dev/null; then
        sha256sum "$file" | awk '{print $1}'
    elif command -v shasum > /dev/null; then
        shasum -a 256 "$file" | awk '{print $1}'
    else
        error "Neither sha256sum nor shasum found. Please install coreutils."
    fi
}

# Calculate SHA-256 hash of canonicalized file content
# This ensures consistent hashing regardless of trailing whitespace
hash_content_canonical() {
    local file="$1"
    local temp=$(mktemp)
    canonicalize_file "$file" > "$temp"
    local hash=$(hash_content "$temp")
    rm -f "$temp"
    echo "$hash"
}

# Generate unified diff between two files (reverse: new -> old)
generate_version_diff() {
    local new_file="$1"
    local old_file="$2"
    # Generate unified diff from old to new (reverse direction for backward reconstruction)
    diff -u "$old_file" "$new_file" || true
}

# Get versions file path for a canonical file
# New structure: versions subdirectory in same directory as file
# Example: posts/2025/01/my-post.md -> posts/2025/01/.versions/my-post.md
# Directory name is configurable via VERSIONS_DIR_NAME
get_versions_file_path() {
    local canonical_file="$1"
    local dir=$(dirname "$canonical_file")
    local filename=$(basename "$canonical_file")
    echo "$dir/$VERSIONS_DIR_NAME/$filename"
}

# Initialize version history with full content (called on publish)
initialize_version_history() {
    local canonical_file="$1"
    local content_hash="$2"
    local timestamp="$3"
    local content="$4"

    # Determine versions file path
    local versions_file=$(get_versions_file_path "$canonical_file")
    local versions_dir=$(dirname "$versions_file")

    # Create .versions directory structure if it doesn't exist
    mkdir -p "$versions_dir"

    # Create versions file with header and first version as full content
    cat > "$versions_file" << EOF
# VERSION_FILE_FORMAT=1.0
# CANONICAL_FILE=$canonical_file
# CURRENT_HASH=sha256:$content_hash

[VERSION sha256:$content_hash]
TIMESTAMP=$timestamp
PARENT=none
FULL_CONTENT_START
$content
FULL_CONTENT_END

EOF
}

# Append version diff to history file
# NOTE: The diff format stored in .versions files is compatible with the standard
# Unix diff/patch utilities. Diffs are stored in unified diff format and can be
# applied using 'patch -R' to reconstruct previous versions.
append_version_to_history() {
    local canonical_file="$1"
    local old_hash="$2"
    local new_hash="$3"
    local timestamp="$4"
    local diff_content="$5"

    # Determine versions file path
    local versions_file=$(get_versions_file_path "$canonical_file")
    local versions_dir=$(dirname "$versions_file")

    # Create .versions directory structure if it doesn't exist
    mkdir -p "$versions_dir"

    # Create versions file if it doesn't exist
    if [ ! -f "$versions_file" ]; then
        cat > "$versions_file" << EOF
# VERSION_FILE_FORMAT=1.0
# CANONICAL_FILE=$canonical_file
# CURRENT_HASH=sha256:$new_hash

EOF
    else
        # Update CURRENT_HASH in header
        sed -i "s/^# CURRENT_HASH=.*/# CURRENT_HASH=sha256:$new_hash/" "$versions_file"
    fi

    # Append new version section
    cat >> "$versions_file" << EOF
[VERSION sha256:$new_hash]
TIMESTAMP=$timestamp
PARENT=sha256:$old_hash
DIFF_START
$diff_content
DIFF_END

EOF
}

# Extract diff for specific version from versions file
extract_diff_for_version() {
    local versions_file="$1"
    local version_hash="$2"

    # Extract content between DIFF_START and DIFF_END for the specified version
    awk -v version="$version_hash" '
        /^\[VERSION sha256:/ {
            if ($0 ~ version) {
                found=1
            } else {
                found=0
            }
        }
        found && /^DIFF_START$/ {
            in_diff=1
            next
        }
        found && in_diff && /^DIFF_END$/ {
            exit
        }
        found && in_diff {
            print
        }
    ' "$versions_file"
}

# Extract full content for specific version from versions file
extract_full_content_for_version() {
    local versions_file="$1"
    local version_hash="$2"

    # Extract content between FULL_CONTENT_START and FULL_CONTENT_END
    awk -v version="$version_hash" '
        /^\[VERSION sha256:/ {
            if ($0 ~ version) {
                found=1
            } else {
                found=0
            }
        }
        found && /^FULL_CONTENT_START$/ {
            in_content=1
            next
        }
        found && in_content && /^FULL_CONTENT_END$/ {
            exit
        }
        found && in_content {
            print
        }
    ' "$versions_file"
}

# Extract parent hash for specific version
extract_parent_hash() {
    local versions_file="$1"
    local version_hash="$2"

    # Find the PARENT= line for the specified version
    awk -v version="$version_hash" '
        /^\[VERSION sha256:/ {
            if ($0 ~ version) {
                found=1
            } else {
                found=0
            }
        }
        found && /^PARENT=/ {
            sub(/^PARENT=/, "")
            print
            exit
        }
    ' "$versions_file"
}

# Verify content matches expected hash
verify_version_integrity() {
    local content_file="$1"
    local expected_hash="$2"

    # Try canonical hashing first (matches new publish behavior)
    local canonical_hash=$(hash_content_canonical "$content_file")
    if [ "sha256:$canonical_hash" = "$expected_hash" ]; then
        return 0
    fi

    # Fall back to non-canonical hashing for backwards compatibility
    # (content published before canonicalization was introduced)
    local direct_hash=$(hash_content "$content_file")
    if [ "sha256:$direct_hash" = "$expected_hash" ]; then
        return 0
    fi

    return 1
}

# Reconstruct specific version from canonical file and diffs
reconstruct_version() {
    local canonical_file="$1"
    local target_hash="$2"
    local output_file="$3"

    local versions_file=$(get_versions_file_path "$canonical_file")

    # Check if versions file exists
    if [ ! -f "$versions_file" ]; then
        error "No version history found for $filename"
    fi

    # Check if target is the base version (has full content stored)
    local target_parent=$(extract_parent_hash "$versions_file" "$target_hash")
    if [ "$target_parent" = "none" ]; then
        # Target is base version - extract full content directly
        extract_full_content_for_version "$versions_file" "$target_hash" > "$output_file"
        # Verify integrity
        if ! verify_version_integrity "$output_file" "$target_hash"; then
            error "Integrity check failed for reconstructed version $target_hash"
        fi
        return 0
    fi

    # Try backward reconstruction first (efficient when canonical file is unchanged)
    if _reconstruct_version_backward "$canonical_file" "$target_hash" "$output_file" "$versions_file" 2>/dev/null; then
        return 0
    fi

    # Fallback: forward reconstruction from base version
    # This handles the case where the canonical file has been modified (e.g., during republish)
    _reconstruct_version_forward "$target_hash" "$output_file" "$versions_file"
}

# Internal: Reconstruct version by working backward from current canonical content
_reconstruct_version_backward() {
    local canonical_file="$1"
    local target_hash="$2"
    local output_file="$3"
    local versions_file="$4"

    # Get current version hash from versions file
    local current_hash=$(grep "^# CURRENT_HASH=" "$versions_file" | sed 's/^# CURRENT_HASH=//')

    # Extract current content (without frontmatter)
    local temp_current=$(mktemp)
    extract_content_without_frontmatter "$canonical_file" > "$temp_current"

    # Walk backward through version chain
    local current_version="$current_hash"
    local temp_work=$(mktemp)
    cp "$temp_current" "$temp_work"

    while [ "$current_version" != "$target_hash" ]; do
        # Get parent version first to check if we're at the base
        local parent_version=$(extract_parent_hash "$versions_file" "$current_version")

        # If parent is "none", we've reached the base but haven't found target
        if [ "$parent_version" = "none" ]; then
            rm -f "$temp_current" "$temp_work"
            return 1
        fi

        # Extract diff for current version
        local diff_content=$(extract_diff_for_version "$versions_file" "$current_version")

        if [ -z "$diff_content" ]; then
            rm -f "$temp_current" "$temp_work"
            return 1
        fi

        # Apply reverse patch (go backward in time)
        local temp_diff=$(mktemp)
        echo "$diff_content" > "$temp_diff"

        local temp_patched=$(mktemp)
        if patch -R -s -o "$temp_patched" "$temp_work" "$temp_diff" 2>/dev/null; then
            cp "$temp_patched" "$temp_work"
            rm -f "$temp_patched" "$temp_diff"
        else
            rm -f "$temp_current" "$temp_work" "$temp_patched" "$temp_diff"
            return 1
        fi

        # Move to parent version
        current_version="$parent_version"
    done

    # Copy reconstructed content to output
    cp "$temp_work" "$output_file"

    # Cleanup
    rm -f "$temp_current" "$temp_work"

    # Verify integrity
    if ! verify_version_integrity "$output_file" "$target_hash"; then
        return 1
    fi
    return 0
}

# Internal: Reconstruct version by applying diffs forward from base version
_reconstruct_version_forward() {
    local target_hash="$1"
    local output_file="$2"
    local versions_file="$3"

    # Build chain from base to target by walking backward and collecting versions
    local -a version_chain=()
    local current="$target_hash"

    while true; do
        version_chain=("$current" "${version_chain[@]}")
        local parent=$(extract_parent_hash "$versions_file" "$current")
        if [ "$parent" = "none" ]; then
            break
        fi
        if [ -z "$parent" ]; then
            error "Version $target_hash not found in history (broken chain)"
        fi
        current="$parent"
    done

    # First version in chain is base - extract its full content
    local base_hash="${version_chain[0]}"
    local temp_work=$(mktemp)
    extract_full_content_for_version "$versions_file" "$base_hash" > "$temp_work"

    # Apply diffs forward through the chain
    local i
    for (( i=1; i<${#version_chain[@]}; i++ )); do
        local version_hash="${version_chain[$i]}"
        local diff_content=$(extract_diff_for_version "$versions_file" "$version_hash")

        if [ -z "$diff_content" ]; then
            rm -f "$temp_work"
            error "Missing diff for version $version_hash"
        fi

        local temp_diff=$(mktemp)
        echo "$diff_content" > "$temp_diff"

        local temp_patched=$(mktemp)
        if patch -s -o "$temp_patched" "$temp_work" "$temp_diff" 2>/dev/null; then
            cp "$temp_patched" "$temp_work"
            rm -f "$temp_patched" "$temp_diff"
        else
            rm -f "$temp_work" "$temp_patched" "$temp_diff"
            error "Failed to apply forward patch for version ${version_hash:0:13}..."
        fi
    done

    # Copy result to output
    cp "$temp_work" "$output_file"
    rm -f "$temp_work"

    # Verify integrity
    if ! verify_version_integrity "$output_file" "$target_hash"; then
        error "Integrity check failed for reconstructed version $target_hash"
    fi
}

# ============================================================================
# BLESSING HELPER FUNCTIONS
# ============================================================================

# Extract author email from .well-known/polis
extract_author_from_wellknown() {
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        error "Polis not initialized. Run 'polis init' first."
    fi

    local author=$(grep -m 1 '"email"' "$WELL_KNOWN_DIR/polis" | sed 's/.*"email": *"\([^"]*\)".*/\1/')

    if [ -z "$author" ]; then
        error "Could not extract author email from .well-known/polis"
    fi

    echo "$author"
}

# Extract domain from POLIS_BASE_URL
# Uses bash parameter expansion for portability (works on both Linux and macOS)
extract_domain_from_url() {
    local url="$1"
    # Remove protocol (http:// or https://) using parameter expansion
    # ${url#*://} removes everything up to and including ://
    local domain="${url#*://}"
    # Remove path and trailing slash
    # ${domain%%/*} removes everything from the first / onwards
    domain="${domain%%/*}"
    echo "$domain"
}

# Check if a URL is a comment (vs a post)
# Comments are typically in /comments/ path
is_comment_url() {
    local url="$1"
    [[ "$url" =~ /comments/ ]]
}

# Fetch root_post for a comment URL from discovery service
# Returns: root_post URL or empty if not found/error
fetch_root_post_for_comment() {
    local comment_url="$1"

    if [ -z "$DISCOVERY_SERVICE_KEY" ]; then
        # Can't query without API key
        return 1
    fi

    # URL-encode the comment URL
    local encoded_url=$(jq -rn --arg url "$comment_url" '$url | @uri')

    local response=$(curl -s --max-time 10 \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_COMMENTS_ENDPOINT}?url=${encoded_url}" 2>/dev/null)

    if [ -z "$response" ]; then
        return 1
    fi

    # Check for error response (comment not found in database)
    local error_msg=$(echo "$response" | jq -r '.error // empty' 2>/dev/null)
    if [ -n "$error_msg" ]; then
        return 1
    fi

    # Try to extract root_post from response
    local root_post=$(echo "$response" | jq -r '.root_post // empty' 2>/dev/null)

    if [ -n "$root_post" ] && [ "$root_post" != "null" ]; then
        echo "$root_post"
        return 0
    fi

    # Fallback: try in_reply_to (for older comments before nested threads)
    local in_reply_to=$(echo "$response" | jq -r '.in_reply_to // empty' 2>/dev/null)
    if [ -n "$in_reply_to" ] && [ "$in_reply_to" != "null" ]; then
        echo "$in_reply_to"
        return 0
    fi

    return 1
}

# ============================================================================
# DOMAIN MIGRATION HELPERS
# ============================================================================

# Collect all domains the user "cares about" for migration tracking
# Returns: newline-separated list of unique domains
collect_relevant_domains() {
    local domains=()

    # 1. Domains from following.json
    if [ -f "$FOLLOWING_INDEX" ]; then
        while IFS= read -r url; do
            local domain=$(extract_domain_from_url "$url")
            if [ -n "$domain" ]; then
                domains+=("$domain")
            fi
        done < <(jq -r '.following[].url // empty' "$FOLLOWING_INDEX" 2>/dev/null)
    fi

    # 2. Domains from blessed-comments.json (post URLs that have blessed comments)
    if [ -f "$BLESSED_COMMENTS" ]; then
        while IFS= read -r url; do
            local domain=$(extract_domain_from_url "$url")
            if [ -n "$domain" ]; then
                domains+=("$domain")
            fi
        done < <(jq -r '.posts[].url // empty' "$BLESSED_COMMENTS" 2>/dev/null)

        # Also check comment author domains
        while IFS= read -r url; do
            local domain=$(extract_domain_from_url "$url")
            if [ -n "$domain" ]; then
                domains+=("$domain")
            fi
        done < <(jq -r '.posts[].blessed[].url // empty' "$BLESSED_COMMENTS" 2>/dev/null)
    fi

    # 3. Domains from in-reply-to in local comments
    if [ -d "$COMMENTS_DIR" ]; then
        for file in $(find "$COMMENTS_DIR" -name "*.md" -type f 2>/dev/null); do
            local in_reply_to=$(extract_frontmatter_field "$file" "in-reply-to")
            # Handle nested YAML - extract URL from the block
            if [[ "$in_reply_to" == *"url:"* ]]; then
                in_reply_to=$(echo "$in_reply_to" | grep -oE 'https://[^[:space:]]+' | head -1)
            fi
            if [ -n "$in_reply_to" ]; then
                local domain=$(extract_domain_from_url "$in_reply_to")
                if [ -n "$domain" ]; then
                    domains+=("$domain")
                fi
            fi
        done
    fi

    # Deduplicate and output
    printf '%s\n' "${domains[@]}" | sort -u
}

# Query discovery service for migrations affecting specified domains
# Args: $1 = comma-separated domains
# Returns: JSON response with migrations array
query_domain_migrations() {
    local domains="$1"

    if [ -z "$DISCOVERY_SERVICE_URL" ] || [ -z "$DISCOVERY_SERVICE_KEY" ]; then
        echo '{"migrations":[],"count":0,"checked_domains":0}'
        return 1
    fi

    local endpoint="${DISCOVERY_SERVICE_URL}/migrations"
    local response=$(curl -s --max-time 30 \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${endpoint}?domains=${domains}" 2>/dev/null)

    if [ -z "$response" ]; then
        echo '{"migrations":[],"count":0,"checked_domains":0}'
        return 1
    fi

    echo "$response"
}

# Fetch public key from a domain's .well-known/polis
# Args: $1 = domain (e.g., "example.com")
# Returns: public key string or empty on failure
fetch_domain_public_key() {
    local domain="$1"
    local wellknown_url="https://${domain}/.well-known/polis"

    local response=$(curl -s --max-time 10 "$wellknown_url" 2>/dev/null)
    if [ -z "$response" ]; then
        return 1
    fi

    local public_key=$(echo "$response" | jq -r '.public_key // empty' 2>/dev/null)
    if [ -n "$public_key" ] && [ "$public_key" != "null" ]; then
        echo "$public_key"
        return 0
    fi

    return 1
}

# Update domain references in following.json
# Args: $1 = old_domain, $2 = new_domain
update_domain_in_following() {
    local old_domain="$1"
    local new_domain="$2"

    if [ ! -f "$FOLLOWING_INDEX" ]; then
        return 0
    fi

    local temp_file="${FOLLOWING_INDEX}.tmp"
    jq --arg old "https://$old_domain" \
       --arg new "https://$new_domain" \
       '.following |= map(if .url | startswith($old) then .url = ($new + (.url | ltrimstr($old))) else . end)' \
       "$FOLLOWING_INDEX" > "$temp_file" 2>/dev/null

    if [ $? -eq 0 ]; then
        mv "$temp_file" "$FOLLOWING_INDEX"
        return 0
    else
        rm -f "$temp_file"
        return 1
    fi
}

# Update domain references in blessed-comments.json
# Args: $1 = old_domain, $2 = new_domain
update_domain_in_blessed_comments() {
    local old_domain="$1"
    local new_domain="$2"

    if [ ! -f "$BLESSED_COMMENTS" ]; then
        return 0
    fi

    local temp_file="${BLESSED_COMMENTS}.tmp"
    # Update both post URLs and blessed comment URLs
    jq --arg old "https://$old_domain" \
       --arg new "https://$new_domain" \
       '.posts |= map(
           (if .url | startswith($old) then .url = ($new + (.url | ltrimstr($old))) else . end) |
           .blessed |= map(if .url | startswith($old) then .url = ($new + (.url | ltrimstr($old))) else . end)
       )' \
       "$BLESSED_COMMENTS" > "$temp_file" 2>/dev/null

    if [ $? -eq 0 ]; then
        mv "$temp_file" "$BLESSED_COMMENTS"
        return 0
    else
        rm -f "$temp_file"
        return 1
    fi
}

# Update domain references in a comment markdown file (frontmatter only)
# Args: $1 = file path, $2 = old_domain, $3 = new_domain
update_domain_in_comment_file() {
    local file="$1"
    local old_domain="$2"
    local new_domain="$3"

    if [ ! -f "$file" ]; then
        return 1
    fi

    # Use sed to replace domain in frontmatter URLs
    # Note: This updates in-reply-to URLs, not the canonical_url (that's the commenter's domain)
    sed -i.bak "s|https://$old_domain/|https://$new_domain/|g" "$file"
    rm -f "${file}.bak"
    return 0
}

# Fetch comment content and extract excerpt (first ~100 chars)
fetch_comment_excerpt() {
    local comment_url="$1"
    local max_length=100

    # Fetch with timeout (follow redirects)
    local content=$(curl -sL --max-time 10 "$comment_url" 2>/dev/null)

    if [ -z "$content" ]; then
        echo "[Could not fetch]"
        return
    fi

    # Use existing helper to extract body (handles frontmatter correctly)
    local body=$(extract_body_from_content "$content")

    # If no body found, return placeholder
    if [ -z "$body" ]; then
        echo "[No content]"
        return
    fi

    # Get first meaningful line, strip markdown headers, trim whitespace
    body=$(echo "$body" | grep -v '^$' | head -1 | sed 's/^#* *//' | tr -d '\n')

    # Truncate to max_length and add ellipsis if longer
    if [ ${#body} -gt $max_length ]; then
        echo "${body:0:$max_length}..."
    else
        echo "$body"
    fi
}

# Format full hash to short hash (e.g., "sha256:abc123...xyz789" -> "abc123-xyz789")
format_short_hash() {
    local full_version="$1"
    # Remove sha256: prefix and extract first 6 and last 6 characters
    local hash=$(echo "$full_version" | sed 's/sha256://')
    echo "${hash:0:6}-${hash: -6}"
}

# Resolve short hash to full comment_version
# Searches pending requests for a matching hash prefix/suffix
resolve_short_hash() {
    local short_hash="$1"
    local domain="$2"  # Used to filter requests

    # Normalize: remove dash if present, lowercase
    local normalized=$(echo "$short_hash" | tr -d '-' | tr '[:upper:]' '[:lower:]')

    # Fetch all pending requests for this domain
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_BLESSING_REQUESTS_ENDPOINT}?in_reply_to_domain=${domain}&blessing_status=pending")

    # Search for matching comment_version
    # Match if hash starts with first 6 chars or ends with last 6 chars or contains both parts
    local full_version=$(echo "$response" | jq -r --arg hash "$normalized" '
        .requests[] |
        select(
            (.comment_version | gsub("sha256:"; "") | ascii_downcase) |
            (startswith($hash[0:6]) and endswith($hash | .[-6:]))
            or startswith($hash)
            or endswith($hash)
        ) |
        .comment_version
    ' 2>/dev/null | head -1)

    echo "$full_version"
}

# Fetch request details from blessing-requests API by comment_version
fetch_request_details() {
    local comment_version="$1"

    # Extract domain from POLIS_BASE_URL to filter requests
    local domain=$(echo "$POLIS_BASE_URL" | sed 's|https\?://||' | sed 's|/.*||')

    # Fetch pending requests for this domain
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_BLESSING_REQUESTS_ENDPOINT}?in_reply_to_domain=${domain}&blessing_status=pending")

    # Filter by comment_version - encode the version for URL safety
    local request_data=$(echo "$response" | jq -r --arg ver "$comment_version" '
        .requests[] | select(.comment_version == $ver)
    ' 2>/dev/null)

    # Check for API errors
    local error_msg=$(echo "$response" | jq -r '.error // empty' 2>/dev/null)
    if [ -n "$error_msg" ]; then
        echo "ERROR: API returned error: $error_msg" >&2
        return 1
    fi

    echo "$request_data"
}

# Prompt user for confirmation
prompt_confirmation() {
    local short_hash="$1"
    local request_json="$2"

    # Parse request details
    local author=$(echo "$request_json" | jq -r '.author')
    local comment_url=$(echo "$request_json" | jq -r '.comment_url')
    local in_reply_to=$(echo "$request_json" | jq -r '.in_reply_to')
    local timestamp=$(echo "$request_json" | jq -r '.timestamp')

    # Fetch comment content
    local excerpt=$(fetch_comment_excerpt "$comment_url")

    # Display request details
    echo ""
    info "Request ${short_hash}:"
    echo "    Author: $author"
    echo "    Comment: $comment_url"
    echo "    In reply to: $in_reply_to"
    echo "    Timestamp: $timestamp"
    echo ""
    echo "    Preview:"
    echo "    $excerpt"
    echo ""
}

# Display request details (for blessing operations)
display_request_details() {
    prompt_confirmation "$@"
}

# Update blessed-comments.json file
update_blessed_comments_json() {
    local comment_url="$1"
    local comment_version="$2"
    local in_reply_to="$3"
    local blessed_at="$4"

    # Normalize post URL to always use .md extension
    local base="${in_reply_to%.html}"
    base="${base%.md}"
    in_reply_to="${base}.md"

    local blessed_file="$BLESSED_COMMENTS"

    if [ ! -f "$blessed_file" ]; then
        error "blessed-comments.json not found. Run 'polis init' first."
    fi

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        error "jq is required but not installed. Please install jq to continue."
    fi

    local temp_file="${blessed_file}.tmp"

    # Use jq to update JSON
    jq --arg post "$in_reply_to" \
       --arg url "$comment_url" \
       --arg version "$comment_version" \
       --arg timestamp "$blessed_at" \
       '
       .comments |= (
         if any(.[]; .post == $post) then
           map(if .post == $post then
             .blessed += [{
               url: $url,
               version: $version,
               blessed_at: $timestamp
             }]
           else . end)
         else
           . + [{
             post: $post,
             blessed: [{
               url: $url,
               version: $version,
               blessed_at: $timestamp
             }]
           }]
         end
       )
       ' "$blessed_file" > "$temp_file"

    # Atomic replace
    mv "$temp_file" "$blessed_file"
}

# Remove comment from blessed-comments.json file
remove_from_blessed_comments_json() {
    local comment_url="$1"
    local in_reply_to="$2"

    local blessed_file="$BLESSED_COMMENTS"

    if [ ! -f "$blessed_file" ]; then
        # File doesn't exist, nothing to remove
        return 0
    fi

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        error "jq is required but not installed. Please install jq to continue."
    fi

    local temp_file="${blessed_file}.tmp"

    # Use jq to remove the comment from blessed array
    jq --arg post "$in_reply_to" \
       --arg url "$comment_url" \
       '
       .comments |= map(
         if .post == $post then
           .blessed |= map(select(.url != $url))
         else . end
       ) |
       # Remove post entries with empty blessed arrays
       .comments |= map(select(.blessed | length > 0))
       ' "$blessed_file" > "$temp_file"

    # Atomic replace
    mv "$temp_file" "$blessed_file"
}

# Fetch author email from author's .well-known/polis
# Args: $1 = author_url (e.g., "https://alice.com")
# Returns: email address (echoed to stdout)
# Exits: with error if fetch fails
fetch_author_email_from_wellknown() {
    local author_url="$1"

    # Normalize URL (remove trailing slash)
    author_url="${author_url%/}"

    # Construct .well-known URL
    local wellknown_url="${author_url}/.well-known/polis"

    # Fetch with curl
    local response=$(curl -s --max-time 10 "$wellknown_url" 2>&1)

    if [ $? -ne 0 ]; then
        error "Failed to fetch $wellknown_url
Check that the URL is accessible and the author has Polis initialized."
    fi

    # Parse JSON to extract email
    local email=$(echo "$response" | jq -r '.email // empty' 2>/dev/null)

    if [ -z "$email" ]; then
        error "No email found in $wellknown_url
Author may not have Polis properly configured."
    fi

    echo "$email"
}

# Fetch all blessing requests for a specific author on current user's posts
# Args: $1 = author_email, $2 = blessing_status_filter (optional: "pending", "blessed", "denied", or empty for all)
# Returns: JSON array of request objects (echoed to stdout)
fetch_comments_by_author() {
    local author_email="$1"
    local status_filter="$2"  # optional

    # Extract current user's domain
    local user_domain=$(extract_domain_from_url "$POLIS_BASE_URL")

    if [ -z "$user_domain" ]; then
        error "Invalid POLIS_BASE_URL. Cannot extract domain."
    fi

    # Fetch all requests for user's domain
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_BLESSING_REQUESTS_ENDPOINT}?in_reply_to_domain=${user_domain}")

    if [ $? -ne 0 ]; then
        error "Failed to connect to blessing requests endpoint"
    fi

    # Filter by author email (and optionally blessing_status)
    local filtered_result
    if [ -n "$status_filter" ]; then
        filtered_result=$(echo "$response" | jq --arg author "$author_email" --arg status "$status_filter" \
            '.requests | map(select(.author == $author and .blessing_status == $status))')
    else
        filtered_result=$(echo "$response" | jq --arg author "$author_email" \
            '.requests | map(select(.author == $author))')
    fi

    echo "$filtered_result"
}

# Extract base URL (protocol + domain) from a content URL
# Input:  https://alice.com/posts/2025/01/hello.md
# Output: https://alice.com
extract_base_url() {
    local url="$1"
    echo "$url" | sed -E 's|(https?://[^/]+).*|\1|'
}

# Fetch content from a remote URL
# Returns: content string or empty on error
fetch_remote_content() {
    local url="$1"
    curl -s --max-time 30 "$url" 2>/dev/null
}

# Fetch public key from author's .well-known/polis
# Input:  https://alice.com
# Output: ssh-ed25519 AAAA... (public key string)
fetch_remote_public_key() {
    local base_url="$1"
    local wellknown_url="${base_url}/.well-known/polis"
    local response=$(curl -s --max-time 10 "$wellknown_url" 2>/dev/null)

    if [ -z "$response" ]; then
        echo ""
        return 1
    fi

    local public_key=$(echo "$response" | jq -r '.public_key // empty')
    echo "$public_key"
}

# Extract frontmatter field from content string (not file)
# Args: $1=content, $2=field_name
extract_frontmatter_field_from_content() {
    local content="$1"
    local field="$2"
    echo "$content" | awk -v field="$field:" '/^---$/{if(++count==2) exit} count==1 && $0 ~ "^"field{sub("^"field" *", ""); print; exit}'
}

# Extract content body (without frontmatter) from content string
# Works with both gawk and mawk
extract_body_from_content() {
    local content="$1"
    local in_body=0
    local dash_count=0
    local body=""

    while IFS= read -r line; do
        if [[ "$line" == "---" ]]; then
            ((dash_count++))
            if [[ $dash_count -eq 2 ]]; then
                in_body=1
            fi
            continue
        fi
        if [[ $in_body -eq 1 ]]; then
            body+="$line"$'\n'
        fi
    done <<< "$content"

    # Print without trailing newline - echo will add it back
    # This preserves the exact trailing newline count through command substitution
    printf '%s' "$body"
}

# Verify signature of remote content
# Args: $1=content, $2=public_key, $3=author_email
# Returns: 0 if valid, 1 if invalid
# Canonicalizes content before verification for consistent results
verify_remote_signature() {
    local content="$1"
    local public_key="$2"
    local author_email="$3"

    # Extract signature from frontmatter (signature: only appears in frontmatter)
    local signature=$(echo "$content" | grep '^signature:' | sed 's/^signature: *//')

    if [ -z "$signature" ]; then
        return 1
    fi

    # Create temp files
    local temp_content=$(mktemp)
    local temp_sig=$(mktemp)
    local temp_allowed=$(mktemp)

    # Write public key to allowed_signers file format: email key-type key-data [comment]
    # The namespace "file" is specified via -n flag to ssh-keygen, not in allowed_signers
    echo "$author_email $public_key" > "$temp_allowed"

    # Write signature to temp file (restore PEM format)
    echo "-----BEGIN SSH SIGNATURE-----" > "$temp_sig"
    echo "$signature" >> "$temp_sig"
    echo "-----END SSH SIGNATURE-----" >> "$temp_sig"

    # Reconstruct the content without signature field and canonicalize
    # Canonicalization ensures consistent verification regardless of whitespace differences
    local base_content
    base_content=$(echo "$content" | sed '/^signature:/d')

    # Canonicalize the content before verification
    canonicalize_content "$base_content" > "$temp_content"

    local result=1
    if ssh-keygen -Y verify -f "$temp_allowed" -I "$author_email" -n file -s "$temp_sig" < "$temp_content" >/dev/null 2>&1; then
        result=0
    fi

    # Cleanup
    rm -f "$temp_content" "$temp_sig" "$temp_allowed"

    return $result
}

# Add an author URL to following.json
# Args: $1 = author_url, $2 = timestamp
add_to_following_json() {
    local author_url="$1"
    local timestamp="$2"
    local following_file="$FOLLOWING_INDEX"

    if [ ! -f "$following_file" ]; then
        error "following.json not found. Run 'polis init' first."
    fi

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        error "jq is required but not installed. Please install jq to continue."
    fi

    local temp_file="${following_file}.tmp"

    # Use jq to add author to following list (unique by URL)
    jq --arg url "$author_url" \
       --arg ts "$timestamp" \
       '.following |= (. + [{url: $url, followed_at: $ts}] | unique_by(.url))' \
       "$following_file" > "$temp_file"

    # Atomic replace
    mv "$temp_file" "$following_file"
}

# Remove an author URL from following.json
# Args: $1 = author_url
remove_from_following_json() {
    local author_url="$1"
    local following_file="$FOLLOWING_INDEX"

    if [ ! -f "$following_file" ]; then
        # File doesn't exist, nothing to remove
        return 0
    fi

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        error "jq is required but not installed. Please install jq to continue."
    fi

    local temp_file="${following_file}.tmp"

    # Use jq to remove author from following list
    jq --arg url "$author_url" \
       '.following |= map(select(.url != $url))' \
       "$following_file" > "$temp_file"

    # Atomic replace
    mv "$temp_file" "$following_file"
}

# Check if currently following an author
# Args: $1 = author_url
# Returns: 0 (true) if following, 1 (false) otherwise
is_following() {
    local author_url="$1"
    local following_file="$FOLLOWING_INDEX"

    if [ ! -f "$following_file" ]; then
        return 1
    fi

    # Check if URL exists in following array
    local count=$(jq --arg url "$author_url" \
        '.following | map(select(.url == $url)) | length' \
        "$following_file")

    [ "$count" -gt 0 ]
}

# Check if a comment URL is already in blessed-comments.json
# Args: $1 = comment_url
# Returns: 0 (true) if blessed, 1 (false) otherwise
is_comment_blessed() {
    local comment_url="$1"
    local blessed_file="$BLESSED_COMMENTS"

    if [ ! -f "$blessed_file" ]; then
        return 1
    fi

    # Check if URL exists in any blessed array
    local count=$(jq --arg url "$comment_url" \
        '[.comments[].blessed[] | select(.url == $url)] | length' \
        "$blessed_file" 2>/dev/null || echo "0")

    [ "$count" -gt 0 ]
}

# ============================================================================
# NOTIFICATION HELPERS
# ============================================================================

# Initialize notifications manifest if it doesn't exist
init_notifications_manifest() {
    local manifest="$NOTIFICATIONS_MANIFEST"
    local manifest_dir=$(dirname "$manifest")

    # Create directory if needed
    [ ! -d "$manifest_dir" ] && mkdir -p "$manifest_dir"

    if [ ! -f "$manifest" ]; then
        local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        jq -n \
            --arg version "$VERSION" \
            --arg ts "$timestamp" \
            '{
                version: $version,
                last_requested_ts: $ts,
                preferences: {
                    poll_interval_minutes: 60,
                    enabled_types: ["new_follower", "new_post", "version_available", "blessing_changed"],
                    muted_domains: []
                }
            }' > "$manifest"
    fi
}

# Get last_requested_ts from notifications manifest
get_notifications_watermark() {
    local manifest="$NOTIFICATIONS_MANIFEST"

    if [ ! -f "$manifest" ]; then
        # Return epoch if no manifest
        echo "1970-01-01T00:00:00Z"
        return
    fi

    jq -r '.last_requested_ts // "1970-01-01T00:00:00Z"' "$manifest"
}

# Update last_requested_ts in notifications manifest
update_notifications_watermark() {
    local new_ts="$1"
    local manifest="$NOTIFICATIONS_MANIFEST"

    if [ ! -f "$manifest" ]; then
        init_notifications_manifest
    fi

    local temp_file="${manifest}.tmp"
    jq --arg ts "$new_ts" '.last_requested_ts = $ts' "$manifest" > "$temp_file"
    mv "$temp_file" "$manifest"
}

# Get notification preferences
get_notification_preferences() {
    local manifest="$NOTIFICATIONS_MANIFEST"

    if [ ! -f "$manifest" ]; then
        echo '{}'
        return
    fi

    jq -c '.preferences // {}' "$manifest"
}

# Update notification preference
update_notification_preference() {
    local key="$1"
    local value="$2"
    local manifest="$NOTIFICATIONS_MANIFEST"

    if [ ! -f "$manifest" ]; then
        init_notifications_manifest
    fi

    local temp_file="${manifest}.tmp"
    jq --arg key "$key" --argjson value "$value" '.preferences[$key] = $value' "$manifest" > "$temp_file"
    mv "$temp_file" "$manifest"
}

# Add a notification to the JSONL file
add_notification() {
    local type="$1"
    local source="$2"
    local payload="$3"
    local dedup_key="$4"

    local notif_file="$NOTIFICATIONS_FILE"
    local notif_dir=$(dirname "$notif_file")

    # Create directory if needed
    [ ! -d "$notif_dir" ] && mkdir -p "$notif_dir"

    # Check for duplicate using dedup_key
    if [ -n "$dedup_key" ] && [ -f "$notif_file" ]; then
        if grep -q "\"dedup_key\":\"$dedup_key\"" "$notif_file" 2>/dev/null; then
            # Already exists, skip
            return 0
        fi
    fi

    # Generate unique ID
    local timestamp=$(date +%s)
    local random=$(head -c 4 /dev/urandom | od -An -tx1 | tr -d ' \n')
    local id="notif_${timestamp}_${random}"
    local created_at=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Create notification entry
    local entry=$(jq -n -c \
        --arg id "$id" \
        --arg type "$type" \
        --arg created "$created_at" \
        --arg source "$source" \
        --argjson payload "$payload" \
        --arg dedup "$dedup_key" \
        '{
            id: $id,
            type: $type,
            created_at: $created,
            source: $source,
            payload: $payload,
            dedup_key: $dedup
        }')

    # Append to JSONL
    echo "$entry" >> "$notif_file"
    echo "$id"
}

# Get all notifications (returns JSONL content)
get_notifications() {
    local notif_file="$NOTIFICATIONS_FILE"

    if [ ! -f "$notif_file" ]; then
        return 0
    fi

    cat "$notif_file"
}

# Get notification count
get_notification_count() {
    local notif_file="$NOTIFICATIONS_FILE"

    if [ ! -f "$notif_file" ]; then
        echo "0"
        return
    fi

    wc -l < "$notif_file" | tr -d ' '
}

# Remove notification by ID (mark as read/dismissed)
remove_notification() {
    local id="$1"
    local notif_file="$NOTIFICATIONS_FILE"

    if [ ! -f "$notif_file" ]; then
        return 1
    fi

    local temp_file="${notif_file}.tmp"

    # Filter out the notification with matching ID
    grep -v "\"id\":\"$id\"" "$notif_file" > "$temp_file" 2>/dev/null || true
    mv "$temp_file" "$notif_file"
}

# Remove notifications older than N days
remove_old_notifications() {
    local days="$1"
    local notif_file="$NOTIFICATIONS_FILE"

    if [ ! -f "$notif_file" ]; then
        return 0
    fi

    # Calculate cutoff timestamp
    local cutoff_epoch
    if [[ "$OSTYPE" == "darwin"* ]]; then
        cutoff_epoch=$(date -v-${days}d +%s)
    else
        cutoff_epoch=$(date -d "$days days ago" +%s)
    fi

    local temp_file="${notif_file}.tmp"
    local removed=0

    # Filter notifications newer than cutoff
    while IFS= read -r line; do
        local created_at=$(echo "$line" | jq -r '.created_at // empty')
        if [ -n "$created_at" ]; then
            local entry_epoch
            if [[ "$OSTYPE" == "darwin"* ]]; then
                entry_epoch=$(date -jf "%Y-%m-%dT%H:%M:%SZ" "$created_at" +%s 2>/dev/null || echo "0")
            else
                entry_epoch=$(date -d "$created_at" +%s 2>/dev/null || echo "0")
            fi

            if [ "$entry_epoch" -ge "$cutoff_epoch" ]; then
                echo "$line" >> "$temp_file"
            else
                removed=$((removed + 1))
            fi
        fi
    done < "$notif_file"

    if [ -f "$temp_file" ]; then
        mv "$temp_file" "$notif_file"
    else
        # All notifications were old, create empty file
        : > "$notif_file"
    fi

    echo "$removed"
}

# Remove all notifications
remove_all_notifications() {
    local notif_file="$NOTIFICATIONS_FILE"

    if [ -f "$notif_file" ]; then
        : > "$notif_file"
    fi
}

# Check if notification type is enabled
is_notification_type_enabled() {
    local type="$1"
    local manifest="$NOTIFICATIONS_MANIFEST"

    if [ ! -f "$manifest" ]; then
        # Default: all types enabled
        return 0
    fi

    local enabled=$(jq -r --arg t "$type" '.preferences.enabled_types // [] | index($t) != null' "$manifest")
    [ "$enabled" = "true" ]
}

# Check if domain is muted
is_domain_muted() {
    local domain="$1"
    local manifest="$NOTIFICATIONS_MANIFEST"

    if [ ! -f "$manifest" ]; then
        return 1
    fi

    local muted=$(jq -r --arg d "$domain" '.preferences.muted_domains // [] | index($d) != null' "$manifest")
    [ "$muted" = "true" ]
}

# ============================================================================
# VERSION CHECK HELPERS
# ============================================================================

# Compare two semantic versions
# Returns: 1 if a > b, 0 if equal, 2 if a < b
compare_versions() {
    local a="$1"
    local b="$2"

    # Split into arrays
    IFS='.' read -ra a_parts <<< "$a"
    IFS='.' read -ra b_parts <<< "$b"

    # Compare each part
    local max=${#a_parts[@]}
    [ ${#b_parts[@]} -gt $max ] && max=${#b_parts[@]}

    for ((i=0; i<max; i++)); do
        local a_val=${a_parts[$i]:-0}
        local b_val=${b_parts[$i]:-0}

        if [ "$a_val" -gt "$b_val" ]; then
            return 1
        elif [ "$a_val" -lt "$b_val" ]; then
            return 2
        fi
    done
    return 0
}

# Check for CLI version updates from discovery service
# Returns JSON with version info or empty on failure
# Sets global variables: LATEST_VERSION, UPGRADE_AVAILABLE, LATEST_DOWNLOAD_URL
check_version_update() {
    # Skip if discovery service not configured
    if [ -z "$DISCOVERY_SERVICE_URL" ]; then
        LATEST_VERSION=""
        UPGRADE_AVAILABLE=false
        return 1
    fi

    local endpoint="${DISCOVERY_SERVICE_URL}/polis-version?current=${VERSION}"

    # Make request (no auth required for version check)
    local response
    response=$(curl -s --max-time 10 -w "\n%{http_code}" \
        --location --request GET "$endpoint" \
        --header 'Content-Type: application/json' 2>/dev/null)

    local http_code=$(echo "$response" | tail -n 1)
    local body=$(echo "$response" | sed '$d')

    if [ "$http_code" != "200" ]; then
        LATEST_VERSION=""
        UPGRADE_AVAILABLE=false
        return 1
    fi

    # Parse response
    LATEST_VERSION=$(echo "$body" | jq -r '.latest // empty' 2>/dev/null)
    UPGRADE_AVAILABLE=$(echo "$body" | jq -r '.upgrade_available // false' 2>/dev/null)
    LATEST_DOWNLOAD_URL=$(echo "$body" | jq -r '.download_url // empty' 2>/dev/null)
    LATEST_RELEASE_NOTES=$(echo "$body" | jq -r '.release_notes // empty' 2>/dev/null)

    # Store notification if upgrade available
    if [ "$UPGRADE_AVAILABLE" = "true" ] && is_notification_type_enabled "version_available"; then
        local payload=$(jq -n \
            --arg current "$VERSION" \
            --arg latest "$LATEST_VERSION" \
            --arg url "$LATEST_DOWNLOAD_URL" \
            '{
                current_version: $current,
                latest_version: $latest,
                download_url: $url
            }')
        add_notification "version_available" "discovery" "$payload" "version_available:${LATEST_VERSION}" > /dev/null
    fi

    return 0
}

# Check for version pending apply (CLI newer than metadata files)
check_version_pending() {
    if [ ! -f "$MANIFEST" ]; then
        return 1
    fi

    local metadata_version=$(jq -r '.version // empty' "$MANIFEST" 2>/dev/null)
    if [ -z "$metadata_version" ]; then
        return 1
    fi

    # Compare versions
    compare_versions "$VERSION" "$metadata_version"
    local result=$?

    if [ $result -eq 1 ]; then
        # CLI version > metadata version, suggest rebuild
        if is_notification_type_enabled "version_pending"; then
            local payload=$(jq -n \
                --arg cli "$VERSION" \
                --arg metadata "$metadata_version" \
                '{
                    cli_version: $cli,
                    metadata_version: $metadata,
                    suggestion: "Run '\''polis rebuild'\'' to update metadata files"
                }')
            add_notification "version_pending" "local" "$payload" "version_pending:${VERSION}" > /dev/null
        fi
        return 0
    fi

    return 1
}

# ============================================================================
# CLONE HELPERS
# ============================================================================

# Normalize a server URL (add https if missing, remove trailing slash)
normalize_server_url() {
    local url="$1"
    # Add https:// if no protocol
    [[ ! "$url" =~ ^https?:// ]] && url="https://$url"
    # Remove trailing slash
    url="${url%/}"
    echo "$url"
}

# Extract domain from URL for default target directory name
extract_domain_for_clone() {
    local url="$1"
    echo "$url" | sed -E 's|https?://([^/]+).*|\1|'
}

# Download a single file from remote server to local directory
# Args: $1=server_url, $2=target_dir, $3=file_path
# Returns: 0 on success, 1 on failure
clone_single_file() {
    local server_url="$1"
    local target_dir="$2"
    local file_path="$3"

    local remote_url="${server_url}/${file_path}"
    local local_path="${target_dir}/${file_path}"

    # Create directory structure
    mkdir -p "$(dirname "$local_path")"

    # Fetch content (use -f to fail on HTTP errors)
    local content
    content=$(curl -s --max-time 30 -f "$remote_url" 2>/dev/null)

    if [ $? -ne 0 ] || [ -z "$content" ]; then
        return 1
    fi

    # Write to file
    echo "$content" > "$local_path"
    return 0
}

# Get the .versions path for a content file
# Input: posts/2025/01/hello.md
# Output: posts/2025/01/.versions/hello.md
get_versions_path_for_clone() {
    local content_path="$1"
    local dir=$(dirname "$content_path")
    local filename=$(basename "$content_path")
    echo "$dir/.versions/$filename"
}

# Write clone state file for incremental syncs
# Args: $1=target_dir, $2=server_url, $3=entries_json (array)
write_clone_state() {
    local target_dir="$1"
    local server_url="$2"
    local entries_json="$3"
    local blessed_urls_json="${4:-[]}"

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    jq -n \
        --arg version "$VERSION" \
        --arg url "$server_url" \
        --arg ts "$timestamp" \
        --argjson entries "$entries_json" \
        --argjson blessed "$blessed_urls_json" \
        '{
            polis_version: $version,
            server_url: $url,
            last_sync: $ts,
            entries: $entries,
            blessed_comments_cached: $blessed
        }' > "$target_dir/.polis-clone-state.json"
}

# Clone blessed comments from other authors
# Args: $1=target_dir, $2=blessed_content (JSON)
# Echoes: count of cached comments
clone_blessed_comments() {
    local target_dir="$1"
    local blessed_content="$2"

    local count=0
    local cached_urls=()
    local cache_dir="$target_dir/.blessed-comments-cache"
    mkdir -p "$cache_dir"

    # Parse blessed-comments.json and download each blessed comment
    # Structure: { "comments": [{ "post": "...", "blessed": [{ "url": "...", "version": "..." }] }] }

    while IFS= read -r comment_entry; do
        [ -z "$comment_entry" ] && continue

        local comment_url=$(echo "$comment_entry" | jq -r '.url // empty')
        local comment_version=$(echo "$comment_entry" | jq -r '.version // empty')

        [ -z "$comment_url" ] && continue

        # Download blessed comment from other author's domain
        local comment_content
        comment_content=$(fetch_remote_content "$comment_url")

        if [ -n "$comment_content" ]; then
            # Use URL hash as filename
            local url_hash=$(echo -n "$comment_url" | sha256sum | cut -c1-16)
            echo "$comment_content" > "$cache_dir/${url_hash}.md"

            # Store metadata
            jq -nc --arg url "$comment_url" --arg version "$comment_version" \
                --arg cached_at "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
                '{url: $url, version: $version, cached_at: $cached_at}' \
                > "$cache_dir/${url_hash}.json"

            cached_urls+=("$comment_url")
            count=$((count + 1))
        fi
    done < <(echo "$blessed_content" | jq -c '.comments[].blessed[]' 2>/dev/null)

    # Return URLs as JSON array for state tracking
    printf '%s\n' "${cached_urls[@]}" | jq -R . | jq -s . > "$target_dir/.blessed-urls-temp.json"

    echo "$count"
}

# Sync blessed comments from discovery service to local blessed-comments.json
# Fetches all blessed comments for current user's posts and adds any missing entries
# Returns: count of newly synced comments (echoed to stdout)
# Rebuild blessed-comments.json entirely from discovery service
# This is a "full" rebuild - truncates local file and rebuilds from scratch
rebuild_blessed_comments_full() {
    local domain=$(extract_domain_from_url "$POLIS_BASE_URL")

    if [ -z "$domain" ]; then
        error "Could not determine domain from POLIS_BASE_URL"
    fi

    info "Rebuilding blessed-comments.json from discovery service..."

    # Fetch all blessed comments for our posts
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_BLESSING_REQUESTS_ENDPOINT}?in_reply_to_domain=${domain}&blessing_status=blessed" 2>/dev/null)

    # Initialize fresh blessed-comments.json
    echo "{\"version\":\"$VERSION\",\"comments\":[]}" > "$BLESSED_COMMENTS"

    # Check if response is valid JSON with requests
    local request_count=$(echo "$response" | jq -r '.count // 0' 2>/dev/null)
    if [ -z "$request_count" ] || [ "$request_count" = "0" ] || [ "$request_count" = "null" ]; then
        success "Rebuilt blessed-comments.json (0 blessed comments)"
        return
    fi

    local added_count=0

    # Process each blessed comment
    while IFS= read -r request; do
        [ -z "$request" ] && continue

        local comment_url=$(echo "$request" | jq -r '.comment_url')
        local comment_version=$(echo "$request" | jq -r '.comment_version')
        local in_reply_to=$(echo "$request" | jq -r '.in_reply_to')
        local blessed_at=$(echo "$request" | jq -r '.blessed_at // empty')

        # Use current timestamp if blessed_at is empty
        if [ -z "$blessed_at" ]; then
            blessed_at=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        fi

        update_blessed_comments_json "$comment_url" "$comment_version" "$in_reply_to" "$blessed_at"
        added_count=$((added_count + 1))
    done < <(echo "$response" | jq -c '.requests[]' 2>/dev/null)

    success "Rebuilt blessed-comments.json ($added_count blessed comments)"
}

sync_blessed_comments() {
    local domain=$(extract_domain_from_url "$POLIS_BASE_URL")

    if [ -z "$domain" ]; then
        echo "0"
        return
    fi

    # Fetch all blessed comments for our posts from discovery service
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_BLESSING_REQUESTS_ENDPOINT}?in_reply_to_domain=${domain}&blessing_status=blessed" 2>/dev/null)

    # Check if response is valid JSON with requests
    local request_count=$(echo "$response" | jq -r '.count // 0' 2>/dev/null)
    if [ -z "$request_count" ] || [ "$request_count" = "0" ] || [ "$request_count" = "null" ]; then
        echo "0"
        return
    fi

    local synced_count=0

    # Process each blessed comment
    # Note: Using process substitution to avoid subshell variable scope issues
    while IFS= read -r request; do
        [ -z "$request" ] && continue

        local comment_url=$(echo "$request" | jq -r '.comment_url')
        local comment_version=$(echo "$request" | jq -r '.comment_version')
        local in_reply_to=$(echo "$request" | jq -r '.in_reply_to')
        local blessed_at=$(echo "$request" | jq -r '.blessed_at // empty')

        # Use current timestamp if blessed_at is empty
        if [ -z "$blessed_at" ]; then
            blessed_at=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        fi

        # Check if already in blessed-comments.json
        if ! is_comment_blessed "$comment_url"; then
            update_blessed_comments_json "$comment_url" "$comment_version" "$in_reply_to" "$blessed_at"
            synced_count=$((synced_count + 1))
        fi
    done < <(echo "$response" | jq -c '.requests[]' 2>/dev/null)

    echo "$synced_count"
}

# Get comment ID by URL
# Args: $1 = comment_url
# Returns: comment id (echoed to stdout), or empty string if not found
get_comment_id_by_url() {
    local comment_url="$1"

    # URL encode the comment_url
    local encoded_url=$(jq -rn --arg url "$comment_url" '$url | @uri')

    # Call comments endpoint
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${POLIS_COMMENTS_ENDPOINT}?url=${encoded_url}")

    # Check if we got a valid response
    local comment_id=$(echo "$response" | jq -r '.id // empty' 2>/dev/null)

    if [ -z "$comment_id" ] || [ "$comment_id" = "null" ]; then
        return 1
    fi

    echo "$comment_id"
}

# Get all blessed comment URLs from a specific author domain
# Args: $1 = author_url (e.g., "https://polis-poc.vercel.app/")
# Returns: JSON array of comment URLs
get_blessed_comment_urls_by_author() {
    local author_url="$1"
    local blessed_file="$BLESSED_COMMENTS"

    if [ ! -f "$blessed_file" ]; then
        echo "[]"
        return
    fi

    # Normalize URL (remove trailing slash)
    author_url="${author_url%/}"

    # Extract all blessed comment URLs that start with author_url
    jq --arg author_prefix "${author_url}/" \
        '[.comments[].blessed[] | select(.url | startswith($author_prefix)) | .url]' \
        "$blessed_file"
}

# Format blessing requests as a table
format_blessing_table() {
    local requests_json="$1"

    # Validate JSON and check if there are any requests
    local count=$(echo "$requests_json" | jq -r '.count // 0' 2>/dev/null)

    # Handle invalid JSON or null count
    if [ -z "$count" ] || [ "$count" = "null" ]; then
        count=0
    fi

    # Check if count is zero
    if [ "$count" -eq 0 ] 2>/dev/null || [ "$count" = "0" ]; then
        info "No pending blessing requests found"
        return
    fi

    # Print header
    printf "\n%-15s %-20s %-60s %s\n" "Hash" "Author" "Comment URL" "Timestamp"
    printf "%.sâ”€" {1..120}
    echo ""

    # Process each request (with null check)
    local requests_data=$(echo "$requests_json" | jq -r '.requests // [] | .[] | "\(.comment_version)|\(.author)|\(.comment_url)|\(.timestamp)"' 2>/dev/null)

    if [ -z "$requests_data" ]; then
        info "No pending blessing requests found"
        return
    fi

    echo "$requests_data" | while IFS='|' read -r version author url timestamp; do
        # Skip empty lines
        [ -z "$version" ] && continue

        # Format short hash from comment_version
        local short_hash=$(format_short_hash "$version")
        # Truncate long fields for display
        local display_author=$(echo "$author" | cut -c1-20)
        local display_url=$(echo "$url" | cut -c1-60)
        # Format timestamp: replace T with space, keep timezone
        local display_timestamp=$(echo "$timestamp" | tr 'T' ' ')

        printf "%-15s %-20s %-60s %s\n" "$short_hash" "$display_author" "$display_url" "$display_timestamp"
    done

    echo ""
    success "Found $count pending request(s)"
    info "Run 'polis preview <URL>' to see comment details"
    info "Run 'polis blessing grant <hash>' to bless or 'polis blessing deny <hash>' to deny"
}

# Rebuild public.json index from all posts and comments
rebuild_index() {
    info "Rebuilding public.jsonl index..."

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        error "jq not found. Please install jq: sudo apt-get install jq (or brew install jq on macOS)"
    fi

    # Truncate the index file
    > "$PUBLIC_INDEX"

    # Counters
    local post_count=0
    local comment_count=0

    # Helper function to process a file and append JSONL entry
    process_file() {
        local file="$1"
        local filename=$(basename "$file")

        # Skip hash snapshot files (format: abc123-xyz789.md) and files in versions directory
        if [[ "$filename" =~ ^[a-f0-9]{6}-[a-f0-9]{6}\.md$ ]] || [[ "$file" =~ /$VERSIONS_DIR_NAME/ ]]; then
            return
        fi

        # Extract frontmatter fields
        local title=$(grep -m 1 '^title:' "$file" | sed 's/^title: *//')
        local published=$(grep -m 1 '^published:' "$file" | sed 's/^published: *//')
        local version=$(grep -m 1 '^current-version:' "$file" | sed 's/^current-version: *//')
        local content_type=$(grep -m 1 '^type:' "$file" | sed 's/^type: *//')

        # Skip if missing required fields
        if [ -z "$title" ] || [ -z "$published" ] || [ -z "$version" ]; then
            return
        fi

        # Create JSONL entry based on content type
        if [ "$content_type" = "comment" ]; then
            # Extract in-reply-to for comments
            local reply_url=$(grep -m 1 '^  url:' "$file" | sed 's/^  url: *//')
            local reply_version=$(grep -m 1 '^  version:' "$file" | sed 's/^  version: *//')

            jq -nc \
                --arg type "comment" \
                --arg path "$file" \
                --arg title "$title" \
                --arg published "$published" \
                --arg current_version "$version" \
                --arg reply_url "$reply_url" \
                --arg reply_version "$reply_version" \
                '{
                    type: $type,
                    path: $path,
                    title: $title,
                    published: $published,
                    current_version: $current_version,
                    in_reply_to: {
                        url: $reply_url,
                        version: ($reply_version // null)
                    }
                }' >> "$PUBLIC_INDEX"

            comment_count=$((comment_count + 1))
        else
            jq -nc \
                --arg type "post" \
                --arg path "$file" \
                --arg title "$title" \
                --arg published "$published" \
                --arg current_version "$version" \
                '{
                    type: $type,
                    path: $path,
                    title: $title,
                    published: $published,
                    current_version: $current_version
                }' >> "$PUBLIC_INDEX"

            post_count=$((post_count + 1))
        fi
    }

    # Process all markdown files in posts/
    if [ -d "$POSTS_DIR" ]; then
        while IFS= read -r -d '' file; do
            process_file "$file"
        done < <(find "$POSTS_DIR" -name "*.md" -type f -print0 | sort -z)
    fi

    # Process all markdown files in comments/
    if [ -d "$COMMENTS_DIR" ]; then
        while IFS= read -r -d '' file; do
            process_file "$file"
        done < <(find "$COMMENTS_DIR" -name "*.md" -type f -print0 | sort -z)
    fi

    local total_count=$((post_count + comment_count))
    success "Rebuilt public.jsonl ($total_count entries: $post_count posts, $comment_count comments)"
}

# Rebuild snippets.jsonl index from all snippet files
rebuild_snippets_index() {
    info "Rebuilding snippets.jsonl index..."

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        error "jq not found. Please install jq: sudo apt-get install jq (or brew install jq on macOS)"
    fi

    # Truncate the index file
    > "$SNIPPETS_INDEX"

    # Counter
    local snippet_count=0

    # Helper function to process a snippet file and append JSONL entry
    process_snippet() {
        local file="$1"
        local filename=$(basename "$file")

        # Skip hash snapshot files and files in versions directory
        if [[ "$filename" =~ ^[a-f0-9]{6}-[a-f0-9]{6}\.(md|html)$ ]] || [[ "$file" =~ /$VERSIONS_DIR_NAME/ ]]; then
            return
        fi

        # Extract frontmatter fields
        local title=$(grep -m 1 '^title:' "$file" | sed 's/^title: *//')
        local published=$(grep -m 1 '^published:' "$file" | sed 's/^published: *//')
        local version=$(grep -m 1 '^current-version:' "$file" | sed 's/^current-version: *//')

        # Skip if missing required fields
        if [ -z "$title" ] || [ -z "$published" ] || [ -z "$version" ]; then
            return
        fi

        jq -nc \
            --arg type "snippet" \
            --arg path "$file" \
            --arg title "$title" \
            --arg published "$published" \
            --arg current_version "$version" \
            '{
                type: $type,
                path: $path,
                title: $title,
                published: $published,
                current_version: $current_version
            }' >> "$SNIPPETS_INDEX"

        snippet_count=$((snippet_count + 1))
    }

    # Process all markdown and html files in snippets/
    if [ -d "$SNIPPETS_DIR" ]; then
        while IFS= read -r -d '' file; do
            process_snippet "$file"
        done < <(find "$SNIPPETS_DIR" \( -name "*.md" -o -name "*.html" \) -type f -print0 | sort -z)
    fi

    success "Rebuilt snippets.jsonl ($snippet_count snippets)"
}

# Generate manifest.json from public.jsonl
# Contains summary metadata for efficient discovery polling
generate_manifest() {
    local silent="${1:-false}"

    # Check if public.jsonl exists
    if [ ! -f "$PUBLIC_INDEX" ]; then
        if [ "$silent" != "true" ]; then
            error "public.jsonl not found. Run 'polis rebuild' first."
        fi
        return 1
    fi

    # Count posts and comments from public.jsonl
    local post_count=$(jq -s '[.[] | select(.type == "post")] | length' "$PUBLIC_INDEX" 2>/dev/null || echo "0")
    local comment_count=$(jq -s '[.[] | select(.type == "comment")] | length' "$PUBLIC_INDEX" 2>/dev/null || echo "0")

    # Get the most recent published timestamp
    local last_published=$(jq -s 'map(.published) | sort | last // empty' "$PUBLIC_INDEX" 2>/dev/null)

    # If no content yet, use current time
    if [ -z "$last_published" ] || [ "$last_published" = "null" ]; then
        last_published="\"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\""
    fi

    # Preserve existing site_title and active_theme if set
    local site_title=""
    local active_theme=""
    if [ -f "$MANIFEST" ]; then
        site_title=$(jq -r '.site_title // empty' "$MANIFEST" 2>/dev/null)
        active_theme=$(jq -r '.active_theme // empty' "$MANIFEST" 2>/dev/null)
    fi

    # Generate manifest.json
    local metadata_dir=$(dirname "$MANIFEST")
    mkdir -p "$metadata_dir"

    # Build base manifest
    local manifest_json
    manifest_json=$(jq -n \
        --arg version "$VERSION" \
        --argjson last_published "$last_published" \
        --argjson post_count "$post_count" \
        --argjson comment_count "$comment_count" \
        '{
            version: $version,
            last_published: $last_published,
            post_count: $post_count,
            comment_count: $comment_count
        }')

    # Add optional fields if they exist
    if [ -n "$site_title" ]; then
        manifest_json=$(echo "$manifest_json" | jq --arg site_title "$site_title" '. + {site_title: $site_title}')
    fi
    if [ -n "$active_theme" ]; then
        manifest_json=$(echo "$manifest_json" | jq --arg active_theme "$active_theme" '. + {active_theme: $active_theme}')
    fi

    echo "$manifest_json" > "$MANIFEST"

    if [ "$silent" != "true" ]; then
        success "Generated $MANIFEST (last_published: $(echo $last_published | tr -d '"'), $post_count posts, $comment_count comments)"
    fi
}

# Append a single entry to public.jsonl
# Used by publish/comment for incremental updates
append_to_index() {
    local file_path="$1"
    local entry_type="$2"  # "post", "comment", or "snippet"

    # Extract frontmatter fields
    local title=$(grep -m 1 '^title:' "$file_path" | sed 's/^title: *//')
    local published=$(grep -m 1 '^published:' "$file_path" | sed 's/^published: *//')
    local current_version=$(grep -m 1 '^current-version:' "$file_path" | sed 's/^current-version: *//')

    if [ "$entry_type" = "comment" ]; then
        # Extract in-reply-to for comments
        local reply_url=$(grep -m 1 '^  url:' "$file_path" | sed 's/^  url: *//')
        local reply_version=$(grep -m 1 '^  version:' "$file_path" | sed 's/^  version: *//')

        jq -nc \
            --arg type "comment" \
            --arg path "$file_path" \
            --arg title "$title" \
            --arg published "$published" \
            --arg current_version "$current_version" \
            --arg reply_url "$reply_url" \
            --arg reply_version "$reply_version" \
            '{
                type: $type,
                path: $path,
                title: $title,
                published: $published,
                current_version: $current_version,
                in_reply_to: {
                    url: $reply_url,
                    version: ($reply_version // null)
                }
            }' >> "$PUBLIC_INDEX"
    elif [ "$entry_type" = "snippet" ]; then
        jq -nc \
            --arg type "snippet" \
            --arg path "$file_path" \
            --arg title "$title" \
            --arg published "$published" \
            --arg current_version "$current_version" \
            '{
                type: $type,
                path: $path,
                title: $title,
                published: $published,
                current_version: $current_version
            }' >> "$SNIPPETS_INDEX"
    else
        jq -nc \
            --arg type "post" \
            --arg path "$file_path" \
            --arg title "$title" \
            --arg published "$published" \
            --arg current_version "$current_version" \
            '{
                type: $type,
                path: $path,
                title: $title,
                published: $published,
                current_version: $current_version
            }' >> "$PUBLIC_INDEX"
    fi
}

# Sign file with Ed25519 key
# Canonicalizes content before signing for consistent verification
sign_file() {
    local file="$1"
    local keyfile="$KEYS_DIR/id_ed25519"

    if [ ! -f "$keyfile" ]; then
        error "Private key not found. Run 'polis init' first."
    fi

    # Canonicalize the content before signing
    # This ensures consistent verification regardless of trailing whitespace
    local temp_canonical=$(mktemp)
    canonicalize_file "$file" > "$temp_canonical"

    # Use ssh-keygen -Y sign to sign the canonicalized file
    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_canonical" > /dev/null 2>&1

    # Extract the signature (skip the header/footer lines, get base64 content)
    local sig=$(grep -v '^-----' "$temp_canonical.sig" | tr -d '\n')

    # Clean up
    rm -f "$temp_canonical" "$temp_canonical.sig"

    echo "$sig"
}

# Re-sign a file with current key (preserves all metadata, updates signature)
# Works for both posts and comments
resign_file() {
    local input_file="$1"

    if [ ! -f "$input_file" ]; then
        return 1
    fi

    if ! has_frontmatter "$input_file"; then
        return 1
    fi

    # Extract existing metadata
    local title=$(extract_frontmatter_field "$input_file" "title")
    local original_published=$(extract_frontmatter_field "$input_file" "published")
    local content_type=$(extract_frontmatter_field "$input_file" "type")
    local current_version=$(extract_frontmatter_field "$input_file" "current-version")

    # Extract content without frontmatter
    local content_only=$(mktemp)
    extract_content_without_frontmatter "$input_file" > "$content_only"

    # Extract existing version history
    local version_history=$(extract_version_history "$input_file")

    # Build frontmatter (without signature)
    local frontmatter_template
    if [ "$content_type" = "comment" ]; then
        # Extract in-reply-to section for comments
        local in_reply_to=$(extract_in_reply_to "$input_file")
        frontmatter_template="---
title: $title
type: comment
published: $original_published
generator: polis-cli/$VERSION
in-reply-to:
$in_reply_to
current-version: $current_version
version-history:
$version_history
---"
    else
        frontmatter_template="---
title: $title
published: $original_published
generator: polis-cli/$VERSION
current-version: $current_version
version-history:
$version_history
---"
    fi

    # Create temporary file with frontmatter + content (for signing)
    # Note: content_only already includes the blank line separator after frontmatter
    local temp_file=$(mktemp)
    echo "$frontmatter_template" > "$temp_file"
    cat "$content_only" >> "$temp_file"

    # Sign the file
    local signature=$(sign_file "$temp_file")

    # Create final frontmatter with signature
    local frontmatter
    if [ "$content_type" = "comment" ]; then
        local in_reply_to=$(extract_in_reply_to "$input_file")
        frontmatter="---
title: $title
type: comment
published: $original_published
generator: polis-cli/$VERSION
in-reply-to:
$in_reply_to
current-version: $current_version
version-history:
$version_history
signature: $signature
---"
    else
        frontmatter="---
title: $title
published: $original_published
generator: polis-cli/$VERSION
current-version: $current_version
version-history:
$version_history
signature: $signature
---"
    fi

    # Write back to file
    # Note: content_only already includes the blank line separator
    echo "$frontmatter" > "$input_file"
    cat "$content_only" >> "$input_file"

    # Clean up temp files
    rm -f "$temp_file" "$content_only"

    return 0
}

# Update .well-known/polis with new public key
update_wellknown_pubkey() {
    local new_pubkey=$(cat "$KEYS_DIR/id_ed25519.pub")

    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        return 1
    fi

    # Update public_key field using jq
    local temp_file=$(mktemp)
    jq --arg key "$new_pubkey" '.public_key = $key' "$WELL_KNOWN_DIR/polis" > "$temp_file"
    mv "$temp_file" "$WELL_KNOWN_DIR/polis"

    return 0
}

# Command: polis beseech <filename>
# Request blessing from post author for a comment
# Internal function for file-based beseech (used by auto-beseech in comment/republish)
_internal_beseech_from_file() {
    local input_file="$1"
    local suppress_output="${2:-false}"  # If true, echo result instead of json_success

    if [ -z "$input_file" ]; then
        json_error "beseech" "INVALID_INPUT" "Usage: _internal_beseech_from_file <filename>"
    fi

    if [ ! -f "$input_file" ]; then
        json_error "beseech" "FILE_NOT_FOUND" "File not found: $input_file"
    fi

    # Check if file has frontmatter
    if ! has_frontmatter "$input_file"; then
        json_error "beseech" "INVALID_INPUT" "File has no frontmatter"
    fi

    # Check if file is a comment (only comments can be beseeched)
    local content_type=$(extract_frontmatter_field "$input_file" "type")
    if [ "$content_type" != "comment" ]; then
        json_error "beseech" "INVALID_INPUT" "File is not a comment. Only comments can request blessing from discovery service."
    fi

    info_human "Requesting blessing from discovery service..."
    if [ "$JSON_MODE" = false ]; then
        echo ""
    fi

    # Extract comment metadata
    local title=$(extract_frontmatter_field "$input_file" "title")
    local published=$(extract_frontmatter_field "$input_file" "published")
    local version=$(extract_frontmatter_field "$input_file" "current-version")
    local in_reply_to=$(extract_in_reply_to "$input_file")

    # Parse in-reply-to section
    local reply_url=$(echo "$in_reply_to" | grep 'url:' | sed 's/.*url: *//')
    local reply_version=$(echo "$in_reply_to" | grep 'version:' | sed 's/.*version: *//')
    local root_post=$(echo "$in_reply_to" | grep 'root-post:' | sed 's/.*root-post: *//')

    # Fallback: if no root-post in frontmatter, use reply_url (for backward compatibility)
    if [ -z "$root_post" ]; then
        root_post="$reply_url"
    fi

    # Get author info from .well-known/polis
    local author=""
    if [ -f "$WELL_KNOWN_DIR/polis" ]; then
        author=$(grep -m 1 '"email"' "$WELL_KNOWN_DIR/polis" | sed 's/.*"email": *"\([^"]*\)".*/\1/')
    fi

    # Validation checks
    if [ -z "$version" ]; then
        json_error "beseech" "INVALID_INPUT" "Missing current-version in frontmatter"
    fi
    if [ -z "$reply_url" ]; then
        json_error "beseech" "INVALID_INPUT" "Missing in-reply-to URL in frontmatter"
    fi
    if [ -z "$published" ]; then
        json_error "beseech" "INVALID_INPUT" "Missing published date in frontmatter"
    fi
    if [ -z "$author" ]; then
        json_error "beseech" "INVALID_INPUT" "Missing author email. Set it in .well-known/polis config file."
    fi

    # Get configuration from environment variables
    local base_url="$POLIS_BASE_URL"
    local discovery_endpoint="$POLIS_BESEECH_ENDPOINT"

    if [ -z "$base_url" ]; then
        json_error "beseech" "INVALID_INPUT" "POLIS_BASE_URL not set. Set it with: export POLIS_BASE_URL=https://yourdomain.com"
    fi

    if [ -z "$discovery_endpoint" ]; then
        json_error "beseech" "INVALID_INPUT" "POLIS_BESEECH_ENDPOINT not set. Set it with: export POLIS_BESEECH_ENDPOINT=https://xxx.supabase.co/functions/v1/beseech"
    fi

    # Construct proper HTTPS comment URL
    # Convert local file path to public URL
    # Example: comments/my-comment.md -> https://yourdomain.com/comments/my-comment.md
    local comment_url="$base_url/$input_file"

    # Build canonical JSON payload (WITHOUT signature field)
    # This is what we'll sign
    # IMPORTANT: Use printf (not heredoc) to avoid trailing newline
    local canonical_payload
    if [ -n "$reply_version" ]; then
        canonical_payload=$(printf '{"comment_url":"%s","comment_version":"%s","in_reply_to":"%s","in_reply_to_version":"%s","root_post":"%s","author":"%s","timestamp":"%s"}' \
            "$comment_url" "$version" "$reply_url" "$reply_version" "$root_post" "$author" "$published")
    else
        canonical_payload=$(printf '{"comment_url":"%s","comment_version":"%s","in_reply_to":"%s","root_post":"%s","author":"%s","timestamp":"%s"}' \
            "$comment_url" "$version" "$reply_url" "$root_post" "$author" "$published")
    fi

    # Sign the canonical JSON
    # Create a temporary file with the canonical payload
    local temp_file=$(mktemp)
    echo -n "$canonical_payload" > "$temp_file"

    # Sign using ssh-keygen
    local keyfile="$KEYS_DIR/id_ed25519"
    if [ ! -f "$keyfile" ]; then
        rm -f "$temp_file"
        error "Private key not found. Run 'polis init' first."
    fi

    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1
    if [ $? -ne 0 ]; then
        rm -f "$temp_file" "$temp_file.sig"
        json_error "beseech" "SIGNATURE_ERROR" "Failed to sign payload. Check your private key."
    fi

    # Read the full signature (including PEM headers)
    local signature=""
    if [ -f "$temp_file.sig" ]; then
        signature=$(cat "$temp_file.sig")
    fi

    # Clean up temporary files
    rm -f "$temp_file" "$temp_file.sig"

    if [ -z "$signature" ]; then
        json_error "beseech" "SIGNATURE_ERROR" "Failed to generate signature"
    fi

    # Build final JSON payload with signature
    # Need to escape the signature properly for JSON
    local signature_escaped=$(echo "$signature" | sed ':a;N;$!ba;s/\n/\\n/g' | sed 's/"/\\"/g')

    local final_payload
    if [ -n "$reply_version" ]; then
        final_payload=$(cat << EOF
{
  "comment_url": "$comment_url",
  "comment_version": "$version",
  "in_reply_to": "$reply_url",
  "in_reply_to_version": "$reply_version",
  "root_post": "$root_post",
  "author": "$author",
  "timestamp": "$published",
  "signature": "$signature_escaped"
}
EOF
)
    else
        final_payload=$(cat << EOF
{
  "comment_url": "$comment_url",
  "comment_version": "$version",
  "in_reply_to": "$reply_url",
  "root_post": "$root_post",
  "author": "$author",
  "timestamp": "$published",
  "signature": "$signature_escaped"
}
EOF
)
    fi

    # Send HTTP POST request to discovery service
    info_human "Sending blessing request to discovery service..."
    if [ "$JSON_MODE" = false ]; then
        echo "  URL: $comment_url"
        echo "  Reply to: $reply_url"
        echo ""
    fi

    local response
    local http_code

    # Make the HTTP request and capture both response body and status code
    response=$(curl -s -w "\n%{http_code}" \
        --location --request POST "$discovery_endpoint" \
        --header "${DISCOVERY_SERVICE_KEY:+Authorization: Bearer $DISCOVERY_SERVICE_KEY}" \
        --header 'Content-Type: application/json' \
        --data "$final_payload" 2>&1)

    # Extract HTTP status code (last line)
    http_code=$(echo "$response" | tail -n 1)
    # Extract response body (everything except last line)
    response=$(echo "$response" | sed '$d')

    # Handle response based on HTTP status code
    case "$http_code" in
        201)
            # Parse status from server response (blessed or pending)
            local response_status=$(echo "$response" | jq -r '.status // "pending"')
            local blessed_at=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

            if [ "$response_status" = "blessed" ]; then
                # Auto-blessed! Update blessed-comments.json
                update_blessed_comments_json "$comment_url" "$version" "$reply_url" "$blessed_at"

                if [ "$JSON_MODE" = true ]; then
                    local result=$(jq -n \
                        --arg url "$comment_url" \
                        --arg version "$version" \
                        --arg reply_to "$reply_url" \
                        --arg msg "Comment automatically blessed" \
                        --arg status "blessed" \
                        --argjson auto_blessed "true" \
                        '{
                            comment_url: $url,
                            comment_version: $version,
                            in_reply_to: $reply_to,
                            auto_blessed: $auto_blessed,
                            discovery_response: {
                                success: true,
                                message: $msg,
                                status: $status
                            }
                        }')
                    if [ "$suppress_output" = "true" ]; then
                        echo "$result"
                    else
                        json_success "beseech" "$result"
                    fi
                else
                    success "Comment automatically blessed!"
                    echo ""
                    info "The post author follows you, so your comment was auto-approved."
                    info "Added to blessed-comments.json"
                fi
            else
                # Pending - existing behavior
                if [ "$JSON_MODE" = true ]; then
                    local result=$(jq -n \
                        --arg url "$comment_url" \
                        --arg version "$version" \
                        --arg reply_to "$reply_url" \
                        --arg msg "Beseech request recorded" \
                        --arg status "pending" \
                        --argjson auto_blessed "false" \
                        '{
                            comment_url: $url,
                            comment_version: $version,
                            in_reply_to: $reply_to,
                            auto_blessed: $auto_blessed,
                            discovery_response: {
                                success: true,
                                message: $msg,
                                status: $status
                            }
                        }')
                    if [ "$suppress_output" = "true" ]; then
                        echo "$result"
                    else
                        json_success "beseech" "$result"
                    fi
                else
                    success "Blessing request sent successfully!"
                    echo ""
                    info "Your comment is now pending blessing from the post author."
                    info "Once blessed, it will appear in the public comment feed."
                fi
            fi
            ;;
        403)
            json_error "beseech" "SIGNATURE_ERROR" "Signature verification failed (HTTP 403). Possible causes: 1) Public key doesn't match private key, 2) .well-known/polis not accessible, 3) Public key format is incorrect. Response: $response"
            ;;
        409)
            if [ "$JSON_MODE" = true ]; then
                local result=$(jq -n \
                    --arg url "$comment_url" \
                    --arg version "$version" \
                    --arg reply_to "$reply_url" \
                    --arg msg "Comment version already submitted" \
                    --arg status "duplicate" \
                    '{
                        comment_url: $url,
                        comment_version: $version,
                        in_reply_to: $reply_to,
                        discovery_response: {
                            success: true,
                            message: $msg,
                            status: $status
                        }
                    }')
                if [ "$suppress_output" = "true" ]; then
                    echo "$result"
                else
                    json_success "beseech" "$result"
                fi
            else
                warn "This comment version was already submitted (HTTP 409)"
                echo ""
                info "This is normal if you've already requested blessing for this exact version before."
            fi
            ;;
        400)
            json_error "beseech" "INVALID_INPUT" "Invalid data sent to discovery service (HTTP 400): $response"
            ;;
        401)
            json_error "beseech" "API_ERROR" "Authentication failed (HTTP 401). Check your DISCOVERY_SERVICE_KEY."
            ;;
        500|502|503|504)
            json_error "beseech" "API_ERROR" "Discovery service error (HTTP $http_code). Please try again later."
            ;;
        *)
            if [ -z "$http_code" ] || [ "$http_code" = "000" ]; then
                json_error "beseech" "API_ERROR" "Failed to connect to discovery service. Check your internet connection and POLIS_BESEECH_ENDPOINT."
            else
                json_error "beseech" "API_ERROR" "Unexpected response from discovery service (HTTP $http_code): $response"
            fi
            ;;
    esac
}

# Command: polis blessing beseech <hash>
# Retry or check a blessing request by content hash
# This command is RARELY needed - polis comment/republish auto-request blessings
cmd_blessing_beseech() {
    local input_hash="$1"

    # Validate input
    if [ -z "$input_hash" ]; then
        json_error "blessing-beseech" "INVALID_INPUT" \
            "Usage: polis blessing beseech <hash>"
    fi

    # Check prerequisites
    if [ -z "$POLIS_BESEECH_ENDPOINT" ]; then
        json_error "blessing-beseech" "INVALID_STATE" \
            "POLIS_BESEECH_ENDPOINT not set. See 'polis help' for configuration."
    fi

    if [ -z "$POLIS_BASE_URL" ]; then
        json_error "blessing-beseech" "INVALID_STATE" \
            "POLIS_BASE_URL not set. Export it first."
    fi

    # Resolve short hash to full comment_version
    info_human "Resolving hash..."
    local domain=$(echo "$POLIS_BASE_URL" | sed 's|https\?://||' | sed 's|/.*||')
    local comment_version

    # Check if input is already a full hash (starts with sha256:)
    if [[ "$input_hash" == sha256:* ]]; then
        comment_version="$input_hash"
    else
        comment_version=$(resolve_short_hash "$input_hash" "$domain")
    fi

    if [ -z "$comment_version" ]; then
        json_error "blessing-beseech" "NOT_FOUND" "No request found matching hash: $input_hash"
    fi

    local short_hash=$(format_short_hash "$comment_version")

    # Fetch request details
    info_human "Fetching request details for $short_hash..."
    local request_json=$(fetch_request_details "$comment_version")

    if [ -z "$request_json" ] || [ "$request_json" = "null" ]; then
        json_error "blessing-beseech" "NOT_FOUND" "Request $short_hash not found"
    fi

    # Extract request data
    local comment_url=$(echo "$request_json" | jq -r '.comment_url')
    local in_reply_to=$(echo "$request_json" | jq -r '.in_reply_to')
    local blessing_status=$(echo "$request_json" | jq -r '.blessing_status // "unknown"')

    info_human "Found request $short_hash (status: $blessing_status)"
    info_human "Comment: $comment_url"
    info_human "Reply to: $in_reply_to"

    # Display current status (if already blessed/denied)
    if [ "$blessing_status" = "blessed" ]; then
        success_human "This request is already blessed!"
        info_human "No action needed - comment is approved."
        if [ "$JSON_MODE" = true ]; then
            json_success "blessing-beseech" "$(jq -n --arg hash "$short_hash" '{status:"already_blessed",hash:$hash}')"
        fi
        return 0
    fi

    if [ "$blessing_status" = "denied" ]; then
        info_human "This request was previously denied."
        info_human "Re-submitting will create a new blessing request..."
    fi

    # Try to map comment_url to local file path
    # Example: https://example.com/comments/2025/01/my-comment.md â†’ comments/2025/01/my-comment.md
    local local_file=""
    if [ -n "$POLIS_BASE_URL" ]; then
        local_file="${comment_url#$POLIS_BASE_URL/}"
    fi

    if [ -f "$local_file" ]; then
        info_human "Found local file: $local_file"
        info_human "Re-reading file and creating new beseech request..."

        # Call the internal beseech logic with the local file
        _internal_beseech_from_file "$local_file"
    else
        info_human "Local file not found: $local_file"
        error "Cannot re-beseech without local file.

To retry this blessing request, ensure the comment file exists locally at:
  $local_file

Or set POLIS_BASE_URL to match your comment URL domain."
    fi
}

# Command: polis comment <filename>
cmd_comment() {
    # Parse command-specific flags first
    local explicit_filename=""
    local explicit_title=""
    local explicit_reply_to=""
    local positional_args=()

    while [[ $# -gt 0 ]]; do
        case $1 in
            --filename)
                explicit_filename="$2"
                shift 2
                ;;
            --title)
                explicit_title="$2"
                shift 2
                ;;
            --reply-to)
                explicit_reply_to="$2"
                shift 2
                ;;
            *)
                positional_args+=("$1")
                shift
                ;;
        esac
    done

    # Restore positional arguments
    set -- "${positional_args[@]}"

    local input_file="$1"

    if [ -z "$input_file" ]; then
        json_error "comment" "INVALID_INPUT" "Usage: polis comment <filename> [<reply-to-url>]\n       polis comment - <reply-to-url> [--filename <name>] [--title <title>]"
    fi

    if [ ! -f "$KEYS_DIR/id_ed25519" ]; then
        json_error "comment" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check for stdin mode
    local stdin_mode=false
    local temp_stdin=""

    if [ "$input_file" = "-" ]; then
        stdin_mode=true

        # Verify stdin is not a terminal (has actual content)
        if [ -t 0 ]; then
            json_error "comment" "INVALID_INPUT" "No stdin content. Use: echo 'content' | polis comment - <reply-to-url>"
        fi

        # Create temp file and read stdin
        temp_stdin=$(mktemp)
        cat > "$temp_stdin"

        # Verify content
        if [ ! -s "$temp_stdin" ]; then
            rm -f "$temp_stdin"
            json_error "comment" "INVALID_INPUT" "Stdin content is empty"
        fi

        # Point input_file to temp file
        input_file="$temp_stdin"

        info_human "Reading content from stdin..."
    else
        # Regular file mode - check file exists
        if [ ! -f "$input_file" ]; then
            json_error "comment" "FILE_NOT_FOUND" "File not found: $input_file"
        fi
    fi

    # Ensure temp file cleanup on exit or error
    cleanup_stdin() {
        if [ -n "$temp_stdin" ] && [ -f "$temp_stdin" ]; then
            rm -f "$temp_stdin"
        fi
    }
    trap cleanup_stdin EXIT ERR

    # Check if file already has frontmatter (already published)
    # Skip this check for stdin mode as stdin content is always new
    if [ "$stdin_mode" = false ] && has_frontmatter "$input_file"; then
        json_error "comment" "INVALID_STATE" "File already has frontmatter. Use a new file for comments."
    fi

    # Store original file path for cleanup later
    local original_file="$input_file"

    # Determine base filename
    local base_filename
    if [ -n "$explicit_filename" ]; then
        # Explicit filename takes precedence in all modes
        base_filename="$explicit_filename"
        # Ensure .md extension
        [[ ! "$base_filename" =~ \.md$ ]] && base_filename="${base_filename}.md"
    elif [ "$stdin_mode" = true ]; then
        # Generate synthetic filename for stdin
        local timestamp_filename=$(date +%Y%m%d-%H%M%S)
        base_filename="stdin-${timestamp_filename}.md"
    else
        # Regular file mode - convert to absolute path for comparison
        if command -v realpath > /dev/null 2>&1; then
            input_file=$(realpath "$input_file")
        elif command -v readlink > /dev/null 2>&1; then
            input_file=$(readlink -f "$input_file" 2>/dev/null || echo "$input_file")
        fi
        base_filename=$(basename "$input_file")
    fi

    if [ "$stdin_mode" = true ]; then
        info_human "Creating comment from stdin as $base_filename..."
    else
        info_human "Creating comment from $original_file..."
    fi
    if [ "$JSON_MODE" = false ]; then
        echo ""
    fi

    # Determine reply-to URL from flag or positional arg or prompt
    local reply_to_url
    if [ -n "$explicit_reply_to" ]; then
        reply_to_url="$explicit_reply_to"
        log_default "Using reply-to URL from --reply-to flag: $reply_to_url"
    elif [ "$JSON_MODE" = true ]; then
        # In JSON mode, reply-to URL must be provided as second argument
        reply_to_url="$2"
        if [ -z "$reply_to_url" ]; then
            json_error "comment" "INVALID_INPUT" "Usage: polis --json comment <filename> <reply-to-url>"
        fi
        log_default "Using reply-to URL from argument: $reply_to_url"
    elif [ "$stdin_mode" = true ]; then
        # Stdin mode requires reply-to as second positional arg
        reply_to_url="$2"
        if [ -z "$reply_to_url" ]; then
            json_error "comment" "INVALID_INPUT" "Usage: polis comment - <reply-to-url> [--filename <name>] [--title <title>]"
        fi
        log_default "Using reply-to URL from argument: $reply_to_url"
    else
        # Regular file mode - check for positional arg first, then prompt
        reply_to_url="$2"
        if [ -z "$reply_to_url" ]; then
            # No argument provided, prompt interactively
            echo "Enter the URL of the post or comment you're replying to:"
            echo "(Example: https://alice.com/posts/20251229/hello-world.md)"
            read -r reply_to_url

            if [ -z "$reply_to_url" ]; then
                error "URL is required"
            fi
        fi
    fi

    if [ "$JSON_MODE" = false ]; then
        echo ""
    fi
    info_human "In reply to: $reply_to_url"

    # Determine root_post (always the original post, even if replying to a comment)
    local root_post
    if is_comment_url "$reply_to_url"; then
        # Replying to a comment - need to fetch the root post
        info_human "Detected reply to a comment. Fetching root post..."
        # Use || true to prevent set -e from killing script on failure
        root_post=$(fetch_root_post_for_comment "$reply_to_url") || true
        if [ -z "$root_post" ]; then
            # Fallback: can't determine root_post, this might fail at beseech time
            # but allow user to continue for now
            warn_human "Could not determine root post from discovery service."
            warn_human "Using immediate parent URL as root_post (may cause issues)."
            root_post="$reply_to_url"
        else
            info_human "Root post: $root_post"
        fi
    else
        # Replying directly to a post - root_post is the same as reply_to_url
        root_post="$reply_to_url"
    fi

    # Extract or use explicit title
    local title
    if [ -n "$explicit_title" ]; then
        title="$explicit_title"
    else
        title=$(extract_title "$input_file")
        # If stdin and title is temp filename fallback, use base_filename instead
        if [ "$stdin_mode" = true ] && [[ "$title" =~ ^tmp\. ]]; then
            # Convert filename to readable title
            title=$(echo "$base_filename" | sed 's/\.md$//' | sed 's/-/ /g' | \
                    awk '{for(i=1;i<=NF;i++)sub(/./,toupper(substr($i,1,1)),$i)}1')
        fi
    fi
    info_human "Extracted title: $title"

    # Get current timestamp
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Read original content
    local content=$(cat "$input_file")

    # Hash the canonicalized content for consistent verification
    local content_hash=$(hash_content_canonical "$input_file")
    local hash_short="${content_hash:0:6}-${content_hash: -6}"

    info_human "Content hash: sha256:$content_hash"
    info_human "Short hash: $hash_short"

    # Create date-stamped subdirectory in comments/
    local date_dir="$COMMENTS_DIR/$(date +%Y%m%d)"
    mkdir -p "$date_dir"

    # Note: base_filename is already set above in the stdin/file mode section

    # Create frontmatter (without signature first)
    local frontmatter_template="---
title: $title
type: comment
published: $timestamp
generator: polis-cli/$VERSION
in-reply-to:
  url: $reply_to_url
  root-post: $root_post
current-version: sha256:$content_hash
version-history:
  - sha256:$content_hash ($timestamp)
---"

    # Create temporary file with frontmatter + content (for signing)
    local temp_file=$(mktemp)
    echo "$frontmatter_template" > "$temp_file"
    echo "" >> "$temp_file"
    cat "$input_file" >> "$temp_file"

    # Sign the file
    info_human "Signing file..."
    local signature=$(sign_file "$temp_file")

    # Create final frontmatter with signature
    local frontmatter="---
title: $title
type: comment
published: $timestamp
generator: polis-cli/$VERSION
in-reply-to:
  url: $reply_to_url
  root-post: $root_post
current-version: sha256:$content_hash
version-history:
  - sha256:$content_hash ($timestamp)
signature: $signature
---"

    # Write canonical file
    local canonical_path="$date_dir/$base_filename"
    echo "$frontmatter" > "$canonical_path"
    echo "" >> "$canonical_path"
    cat "$input_file" >> "$canonical_path"
    success_human "Created canonical comment: $canonical_path"

    # Initialize version history with full content
    initialize_version_history "$canonical_path" "$content_hash" "$timestamp" "$content"
    local versions_file=$(get_versions_file_path "$canonical_path")
    success_human "Created versions file: $versions_file"

    # Clean up temp file
    rm -f "$temp_file"

    # Handle cleanup based on mode
    if [ "$stdin_mode" = true ]; then
        # Cleanup handled by trap - just inform user
        success_human "Created comment from stdin: $canonical_path"
    else
        # Remove original file if it's not already in the comments directory
        local canonical_abs=$(realpath "$canonical_path" 2>/dev/null || readlink -f "$canonical_path" 2>/dev/null || echo "$canonical_path")
        if [ "$input_file" != "$canonical_abs" ]; then
            rm -f "$original_file"
            success_human "Moved original file into comments/"
        fi
    fi

    # Append to public.jsonl index
    append_to_index "$canonical_path" "comment"

    # Regenerate manifest.json
    generate_manifest true

    # Request blessing from discovery service with comment
    if [ "$JSON_MODE" = false ]; then
        echo ""
    fi
    info_human "Automatically requesting blessing for comment..."

    # Output results
    if [ "$JSON_MODE" = true ]; then
        # Capture beseech result (suppress its JSON output)
        local beseech_result
        beseech_result=$(_internal_beseech_from_file "$canonical_path" "true")

        local result=$(jq -n \
            --arg path "$canonical_path" \
            --arg hash "sha256:$content_hash" \
            --arg reply_to "$reply_to_url" \
            --arg timestamp "$timestamp" \
            --argjson beseech "$beseech_result" \
            '{
                file_path: $path,
                content_hash: $hash,
                in_reply_to: $reply_to,
                timestamp: $timestamp,
                beseech: $beseech
            }')
        json_success "comment" "$result"
    else
        _internal_beseech_from_file "$canonical_path"
        echo ""
        success "Comment created!"
        echo ""
        info "Canonical: $canonical_path"
        info "Versions:  $versions_file"
    fi
}

# Command: polis preview <url>
# Preview content at a URL with signature verification
cmd_preview() {
    local content_url="$1"

    # Validate input
    if [ -z "$content_url" ]; then
        json_error "preview" "INVALID_INPUT" "Usage: polis preview <url>"
    fi

    # Validate URL format (must be HTTPS)
    if [[ ! "$content_url" =~ ^https:// ]]; then
        json_error "preview" "INVALID_INPUT" "URL must use HTTPS (e.g., https://example.com/posts/hello.md)"
    fi

    info_human "Fetching content from $content_url..."

    # Fetch content
    local content=$(fetch_remote_content "$content_url")
    local actual_url="$content_url"

    # Check for frontmatter - if not found, try alternate extension
    if [ -z "$content" ] || ! echo "$content" | head -1 | grep -q '^---$'; then
        local alt_url=""
        if [[ "$content_url" =~ \.html$ ]]; then
            # Try .md instead of .html
            alt_url="${content_url%.html}.md"
        elif [[ "$content_url" =~ \.md$ ]]; then
            # Try .html instead of .md
            alt_url="${content_url%.md}.html"
        fi

        if [ -n "$alt_url" ]; then
            info_human "Trying alternate URL: $alt_url..."
            local alt_content=$(fetch_remote_content "$alt_url")
            if [ -n "$alt_content" ] && echo "$alt_content" | head -1 | grep -q '^---$'; then
                content="$alt_content"
                actual_url="$alt_url"
                info_human "Found valid content at $alt_url"
            fi
        fi
    fi

    if [ -z "$content" ]; then
        json_error "preview" "FETCH_ERROR" "Failed to fetch content from $content_url"
    fi

    # Check for frontmatter
    if ! echo "$content" | head -1 | grep -q '^---$'; then
        json_error "preview" "INVALID_CONTENT" "Content has no frontmatter (not a valid Polis post/comment)"
    fi

    # Use actual_url for the rest of the function
    content_url="$actual_url"

    # Auto-detect content type (post vs comment)
    local content_type="post"
    if echo "$content" | grep -q '^type: *comment'; then
        content_type="comment"
    elif echo "$content" | grep -q '^in-reply-to:'; then
        content_type="comment"
    fi

    info_human "Detected content type: $content_type"

    # Extract frontmatter fields
    local title=$(extract_frontmatter_field_from_content "$content" "title")
    local published=$(extract_frontmatter_field_from_content "$content" "published")
    local current_version=$(extract_frontmatter_field_from_content "$content" "current-version")
    local signature=$(extract_frontmatter_field_from_content "$content" "signature")
    local generator=$(extract_frontmatter_field_from_content "$content" "generator")

    # For comments, get in-reply-to URL
    local in_reply_to=""
    if [ "$content_type" = "comment" ]; then
        in_reply_to=$(echo "$content" | grep -A1 '^in-reply-to:' | grep 'url:' | sed 's/.*url: *//')
    fi

    # Extract base URL and fetch author info
    local base_url=$(extract_base_url "$content_url")
    info_human "Fetching author info from ${base_url}/.well-known/polis..."

    local public_key=$(fetch_remote_public_key "$base_url")
    local author_email=$(fetch_author_email_from_wellknown "$base_url" 2>/dev/null || echo "")

    # Signature verification
    local signature_status="unknown"
    local signature_message=""

    if [ -z "$public_key" ]; then
        signature_status="error"
        signature_message="Could not fetch public key from $base_url/.well-known/polis"
    elif [ -z "$signature" ]; then
        signature_status="missing"
        signature_message="Content has no signature"
    else
        # Verify signature
        if verify_remote_signature "$content" "$public_key" "$author_email"; then
            signature_status="valid"
            signature_message="Signature verified against author's public key"
        else
            signature_status="invalid"
            signature_message="SIGNATURE DOES NOT MATCH - content may have been tampered with"
        fi
    fi

    # Extract body content
    local body=$(extract_body_from_content "$content")

    # Verify content hash
    local hash_status="unknown"
    if [ -n "$current_version" ]; then
        local temp_body=$(mktemp)
        local expected_hash="${current_version#sha256:}"

        # Strip leading empty line (frontmatter adds blank line after closing ---)
        # and canonicalize for consistent verification
        local body_without_leading
        body_without_leading=$(echo "$body" | tail -n +2)
        canonicalize_content "$body_without_leading" > "$temp_body"

        local actual_hash=$(hash_content "$temp_body")
        if [ "$actual_hash" = "$expected_hash" ]; then
            hash_status="valid"
        else
            hash_status="mismatch"
        fi
        rm -f "$temp_body"
    fi

    # Collect validation issues
    local validation_issues="[]"
    local issues_array=()
    [ -z "$title" ] && issues_array+=("missing_title")
    [ -z "$published" ] && issues_array+=("missing_published")
    [ -z "$current_version" ] && issues_array+=("missing_current_version")
    [ -z "$signature" ] && issues_array+=("missing_signature")
    if [ "$content_type" = "comment" ] && [ -z "$in_reply_to" ]; then
        issues_array+=("missing_in_reply_to")
    fi
    if [ ${#issues_array[@]} -gt 0 ]; then
        validation_issues=$(printf '%s\n' "${issues_array[@]}" | jq -R . | jq -s .)
    fi

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg url "$content_url" \
            --arg type "$content_type" \
            --arg title "$title" \
            --arg published "$published" \
            --arg version "$current_version" \
            --arg generator "$generator" \
            --arg reply_to "$in_reply_to" \
            --arg author "$author_email" \
            --arg sig_status "$signature_status" \
            --arg sig_msg "$signature_message" \
            --arg hash_status "$hash_status" \
            --argjson issues "$validation_issues" \
            --arg body "$body" \
            '{
                url: $url,
                type: $type,
                title: $title,
                published: $published,
                current_version: $version,
                generator: $generator,
                in_reply_to: (if $reply_to == "" then null else $reply_to end),
                author: $author,
                signature: {
                    status: $sig_status,
                    message: $sig_msg
                },
                hash: {
                    status: $hash_status
                },
                validation_issues: $issues,
                body: $body
            }')
        json_success "preview" "$result"
    else
        # Human-readable output
        echo ""

        # Display frontmatter (dimmed)
        echo -e "${DIM}---${NC}"
        echo -e "${DIM}title: $title${NC}"
        echo -e "${DIM}type: $content_type${NC}"
        echo -e "${DIM}published: $published${NC}"
        echo -e "${DIM}current-version: $current_version${NC}"
        if [ -n "$generator" ]; then
            echo -e "${DIM}generator: $generator${NC}"
        fi
        if [ -n "$in_reply_to" ]; then
            echo -e "${DIM}in-reply-to: $in_reply_to${NC}"
        fi
        echo -e "${DIM}---${NC}"

        # Display body content
        echo "$body"

        # Light divider before verification (all dimmed)
        echo -e "${DIM}---${NC}"

        # Compact verification status (dimmed for valid, red for errors)
        case "$signature_status" in
            valid)
                echo -e "${GREEN}âœ“${DIM} Signature verified${NC}"
                ;;
            invalid)
                echo -e "${RED}âœ— Signature INVALID - content may have been tampered with${NC}"
                ;;
            missing)
                echo -e "${RED}âœ— Signature missing${NC}"
                ;;
            error)
                echo -e "${RED}! Could not verify signature${NC}"
                ;;
        esac

        case "$hash_status" in
            valid)
                echo -e "${GREEN}âœ“${DIM} Content hash verified${NC}"
                ;;
            mismatch)
                echo -e "${RED}âœ— Content hash MISMATCH - content may have been modified${NC}"
                ;;
            *)
                echo -e "${DIM}? Could not verify hash${NC}"
                ;;
        esac

        # Validation issues (if any)
        if [ "$validation_issues" != "[]" ]; then
            echo "$validation_issues" | jq -r '.[]' | while read issue; do
                echo -e "${RED}! $issue${NC}"
            done
        fi

        echo ""
    fi
}

# Command: polis republish <filename>
cmd_republish() {
    local input_file="$1"

    if [ -z "$input_file" ]; then
        json_error "republish" "INVALID_INPUT" "Usage: polis republish <filename>"
    fi

    if [ ! -f "$input_file" ]; then
        json_error "republish" "FILE_NOT_FOUND" "File not found: $input_file"
    fi

    if [ ! -f "$KEYS_DIR/id_ed25519" ]; then
        json_error "republish" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check if file has frontmatter (already published)
    if ! has_frontmatter "$input_file"; then
        json_error "republish" "INVALID_STATE" "File not published yet (no frontmatter). Use 'polis post' for new files."
    fi

    info_human "Republishing $input_file..."

    # Extract existing metadata
    local title=$(extract_frontmatter_field "$input_file" "title")
    local original_published=$(extract_frontmatter_field "$input_file" "published")

    # Auto-detect content type from path, fall back to frontmatter
    local content_type=""
    if [[ "$input_file" == "$SNIPPETS_DIR/"* ]] || [[ "$input_file" == snippets/* ]]; then
        content_type="snippet"
    elif [[ "$input_file" == "$COMMENTS_DIR/"* ]] || [[ "$input_file" == comments/* ]]; then
        content_type="comment"
    elif [[ "$input_file" == "$POSTS_DIR/"* ]] || [[ "$input_file" == posts/* ]]; then
        content_type="post"
    else
        # Fall back to frontmatter type field
        content_type=$(extract_frontmatter_field "$input_file" "type")
        [ -z "$content_type" ] && content_type="post"
    fi

    if [ "$content_type" = "snippet" ]; then
        info_human "Republishing snippet: $title"
    elif [ "$content_type" = "comment" ]; then
        info_human "Republishing comment: $title"
    else
        info_human "Republishing post: $title"
    fi

    # Get current timestamp for this version
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Get old hash (current version before update)
    local old_hash=$(extract_frontmatter_field "$input_file" "current-version")
    old_hash="${old_hash#sha256:}"

    # Extract NEW content without frontmatter (user has edited the file)
    local content_only=$(mktemp)
    extract_content_without_frontmatter "$input_file" > "$content_only"

    # Create temp file for old content (will be filled from .versions file)
    local old_content=$(mktemp)

    # Hash the new content (canonical for consistent verification)
    local new_hash=$(hash_content_canonical "$content_only")
    local hash_short="${new_hash:0:6}-${new_hash: -6}"

    info_human "New content hash: sha256:$new_hash"
    info_human "Short hash: $hash_short"

    # Check if content actually changed (comparing canonical hashes)
    if [ "$new_hash" = "$old_hash" ]; then
        rm -f "$content_only" "$old_content"
        if [ "$JSON_MODE" = true ]; then
            json_success "republish" '{"unchanged": true, "message": "No changes detected - content hash unchanged"}'
        else
            info "No changes detected. Content hash is unchanged."
        fi
        return 0
    fi

    # Extract existing version history
    local version_history=$(extract_version_history "$input_file")

    # Extract in-reply-to section if this is a comment
    local in_reply_to=""
    if [ "$content_type" = "comment" ]; then
        in_reply_to=$(extract_in_reply_to "$input_file")
        if [ -z "$in_reply_to" ]; then
            error "Comment file missing in-reply-to section"
        fi
    fi

    # Get directory and filename
    local file_dir=$(dirname "$input_file")
    local base_filename=$(basename "$input_file")

    # Build new version history (old entries + new entry)
    # Only add newline separator if there are existing entries
    local version_history_new
    if [ -z "$version_history" ]; then
        version_history_new="  - sha256:$new_hash ($timestamp)"
    else
        version_history_new="$version_history"$'\n'"  - sha256:$new_hash ($timestamp)"
    fi

    # Create frontmatter (without signature first)
    # Different structure for comments vs posts
    local frontmatter_template
    if [ "$content_type" = "comment" ]; then
        frontmatter_template="---
title: $title
type: comment
published: $original_published
generator: polis-cli/$VERSION
in-reply-to:
$in_reply_to
current-version: sha256:$new_hash
version-history:
$version_history_new
---"
    else
        frontmatter_template="---
title: $title
published: $original_published
generator: polis-cli/$VERSION
current-version: sha256:$new_hash
version-history:
$version_history_new
---"
    fi

    # Create temporary file with frontmatter + content (for signing)
    # Note: content_only already includes the blank line separator after frontmatter
    local temp_file=$(mktemp)
    echo "$frontmatter_template" > "$temp_file"
    cat "$content_only" >> "$temp_file"

    # Sign the file
    info "Signing file..."
    local signature=$(sign_file "$temp_file")

    # Create final frontmatter with signature
    # Different structure for comments vs posts
    local frontmatter
    if [ "$content_type" = "comment" ]; then
        frontmatter="---
title: $title
type: comment
published: $original_published
generator: polis-cli/$VERSION
in-reply-to:
$in_reply_to
current-version: sha256:$new_hash
version-history:
$version_history_new
signature: $signature
---"
    else
        frontmatter="---
title: $title
published: $original_published
generator: polis-cli/$VERSION
current-version: sha256:$new_hash
version-history:
$version_history_new
signature: $signature
---"
    fi

    # Generate diff before writing updated canonical
    local diff_content=""
    local versions_file=$(get_versions_file_path "$input_file")

    # Reconstruct old version from .versions file
    if [ -f "$versions_file" ]; then
        if reconstruct_version "$input_file" "sha256:$old_hash" "$old_content" 2>/dev/null; then
            diff_content=$(generate_version_diff "$content_only" "$old_content")
            info_human "Generated diff from sha256:${old_hash:0:13}... to sha256:${new_hash:0:13}..."
        else
            json_error "republish" "INVALID_STATE" "Failed to reconstruct version sha256:${old_hash:0:13}... from .versions file"
        fi
    else
        error "No .versions file found. This file may have been published with an older version of polis. Please run 'polis post' on the original file again."
    fi

    # Write updated canonical file
    # Note: content_only already includes the blank line separator after frontmatter
    # (from extract_content_without_frontmatter), so we don't add another one here
    echo "$frontmatter" > "$input_file"
    cat "$content_only" >> "$input_file"
    success_human "Updated canonical file: $input_file"

    # Append diff to version history (if we generated one)
    if [ -n "$diff_content" ]; then
        append_version_to_history "$input_file" "$old_hash" "$new_hash" "$timestamp" "$diff_content"
        success_human "Added version sha256:${new_hash:0:13}... to .versions file"
    fi

    # Clean up temp files
    rm -f "$temp_file" "$content_only" "$old_content"

    # Rebuild appropriate index based on content type
    if [ "$content_type" = "snippet" ]; then
        rebuild_snippets_index
    else
        rebuild_index
    fi

    # Request blessing from discovery service if this is a comment
    if [ "$content_type" = "comment" ]; then
        if [ "$JSON_MODE" = false ]; then
            echo ""
        fi
        info_human "Automatically requesting blessing for updated comment..."
        _internal_beseech_from_file "$input_file"
    fi

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg path "$input_file" \
            --arg old_hash "sha256:$old_hash" \
            --arg new_hash "sha256:$new_hash" \
            --arg timestamp "$timestamp" \
            --arg sig "$signature" \
            '{
                file_path: $path,
                previous_version: $old_hash,
                new_version: $new_hash,
                timestamp: $timestamp,
                signature: $sig
            }')
        json_success "republish" "$result"
    else
        echo ""
        success "Republishing complete!"
        echo ""
        info "Canonical: $input_file"
        if [ -f "$versions_file" ]; then
            info "Versions:  $versions_file"
        fi
    fi
}

# Command: polis rebuild
cmd_rebuild() {
    local do_posts=false
    local do_comments=false
    local do_notifications=false

    # Parse flags (combinable)
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --posts)
                do_posts=true
                shift
                ;;
            --comments)
                do_comments=true
                shift
                ;;
            --notifications)
                do_notifications=true
                shift
                ;;
            --all)
                do_posts=true
                do_comments=true
                do_notifications=true
                shift
                ;;
            *)
                json_error "rebuild" "INVALID_INPUT" "Unknown option: $1. Use: polis rebuild --posts|--comments|--notifications|--all"
                ;;
        esac
    done

    # Require at least one target
    if [[ "$do_posts" == false && "$do_comments" == false && "$do_notifications" == false ]]; then
        json_error "rebuild" "INVALID_INPUT" "Must specify target: --posts, --comments, --notifications, or --all"
    fi

    local posts_count=0
    local comments_count=0
    local blessed_count=0
    local notifications_reset=false

    # Rebuild posts/comments index
    if [[ "$do_posts" == true ]]; then
        info_human "Rebuilding content index..."
        rebuild_index
        # Count entries
        if [ -f "$PUBLIC_INDEX" ]; then
            posts_count=$(grep -c '"type":"post"' "$PUBLIC_INDEX" 2>/dev/null || echo "0")
            comments_count=$(grep -c '"type":"comment"' "$PUBLIC_INDEX" 2>/dev/null || echo "0")
        fi
        success_human "Rebuilt public.jsonl ($posts_count posts, $comments_count comments)"
    fi

    # Rebuild blessed comments
    if [[ "$do_comments" == true ]]; then
        info_human "Rebuilding blessed comments..."
        rebuild_blessed_comments_full
        # Count blessed
        if [ -f "$BLESSED_COMMENTS" ]; then
            blessed_count=$(jq '.comments | length' "$BLESSED_COMMENTS" 2>/dev/null || echo "0")
        fi
        success_human "Rebuilt blessed-comments.json ($blessed_count blessed comments)"
    fi

    # Reset notifications
    if [[ "$do_notifications" == true ]]; then
        info_human "Resetting notifications..."
        rm -f "$NOTIFICATIONS_FILE"
        rm -f "$NOTIFICATIONS_MANIFEST"
        # Initialize fresh notification manifest
        echo '{"version":"1.0","last_sync":null,"preferences":{}}' > "$NOTIFICATIONS_MANIFEST"
        notifications_reset=true
        success_human "Reset notification files"
    fi

    # Always regenerate manifest after any rebuild
    generate_manifest "true"
    success_human "Regenerated manifest.json"

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --argjson posts_rebuilt "$do_posts" \
            --argjson comments_rebuilt "$do_comments" \
            --argjson notifications_reset "$notifications_reset" \
            --argjson posts "$posts_count" \
            --argjson comments_indexed "$comments_count" \
            --argjson blessed "$blessed_count" \
            '{
                posts_rebuilt: $posts_rebuilt,
                comments_rebuilt: $comments_rebuilt,
                notifications_reset: $notifications_reset,
                manifest_regenerated: true,
                posts_indexed: $posts,
                comments_indexed: $comments_indexed,
                blessed_comments: $blessed
            }')
        json_success "rebuild" "$result"
    else
        success "Rebuild complete!"
    fi
}

# Command: polis index
# View the content index (JSONL by default, grouped JSON with --json)
cmd_index() {
    # Check if index exists
    if [ ! -f "$PUBLIC_INDEX" ]; then
        json_error "index" "FILE_NOT_FOUND" "Index file not found. Run 'polis rebuild' first."
    fi

    # Output based on JSON_MODE
    if [ "$JSON_MODE" = true ]; then
        # Convert JSONL to grouped JSON for readability
        jq -s --arg version "$VERSION" '{
            version: $version,
            posts: [.[] | select(.type == "post") | del(.type)],
            comments: [.[] | select(.type == "comment") | del(.type)]
        }' "$PUBLIC_INDEX"
    else
        # Output raw JSONL
        cat "$PUBLIC_INDEX"
    fi
}

# Command: polis discover
# Check followed authors for new content
cmd_discover() {
    local specific_author=""
    local since_date=""

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --author)
                specific_author="$2"
                shift 2
                ;;
            --since)
                since_date="$2"
                shift 2
                ;;
            *)
                error "Unknown option: $1. Use 'polis discover [--author <url>] [--since <date>]'"
                ;;
        esac
    done

    # Check if following.json exists
    if [ ! -f "$FOLLOWING_INDEX" ]; then
        json_error "discover" "FILE_NOT_FOUND" "following.json not found. Run 'polis init' first."
    fi

    # Get list of followed authors
    local authors
    if [ -n "$specific_author" ]; then
        # Check if we're following this specific author
        local is_following=$(jq --arg url "$specific_author" '.following[] | select(.url == $url)' "$FOLLOWING_INDEX")
        if [ -z "$is_following" ]; then
            json_error "discover" "NOT_FOLLOWING" "Not following $specific_author"
        fi
        authors=$(jq -c --arg url "$specific_author" '[.following[] | select(.url == $url)]' "$FOLLOWING_INDEX")
    else
        authors=$(jq -c '.following' "$FOLLOWING_INDEX")
    fi

    local author_count=$(echo "$authors" | jq 'length')

    if [ "$author_count" -eq 0 ]; then
        info "Not following any authors. Use 'polis follow <url>' to follow someone."
        return 0
    fi

    info "Checking $author_count followed author(s)..."
    echo ""

    local total_new_items=0
    local authors_with_new=0
    local all_new_items="[]"

    # Process each followed author
    echo "$authors" | jq -c '.[]' | while IFS= read -r author_entry; do
        local author_url=$(echo "$author_entry" | jq -r '.url')
        local last_checked=$(echo "$author_entry" | jq -r '.last_checked // empty')

        # Normalize URL (remove trailing slash)
        author_url="${author_url%/}"

        # Use since_date if provided, otherwise use last_checked
        local check_since="$since_date"
        if [ -z "$check_since" ] && [ -n "$last_checked" ]; then
            check_since="$last_checked"
        fi

        # Calculate human-readable "last checked" time
        local last_checked_human="never"
        if [ -n "$last_checked" ]; then
            local last_ts=$(date -d "$last_checked" +%s 2>/dev/null || date -j -f "%Y-%m-%dT%H:%M:%SZ" "$last_checked" +%s 2>/dev/null)
            local now_ts=$(date +%s)
            local diff_seconds=$((now_ts - last_ts))
            local diff_days=$((diff_seconds / 86400))
            if [ "$diff_days" -eq 0 ]; then
                local diff_hours=$((diff_seconds / 3600))
                if [ "$diff_hours" -eq 0 ]; then
                    last_checked_human="just now"
                else
                    last_checked_human="${diff_hours}h ago"
                fi
            else
                last_checked_human="${diff_days}d ago"
            fi
        fi

        echo -n "$author_url (last checked: $last_checked_human)"

        # Fetch manifest.json from author's site
        local manifest_url="${author_url}/metadata/manifest.json"
        local manifest_response=$(curl -s --max-time 10 "$manifest_url" 2>/dev/null)

        if [ -z "$manifest_response" ] || ! echo "$manifest_response" | jq -e '.' > /dev/null 2>&1; then
            echo " - offline or no manifest"
            continue
        fi

        local author_last_published=$(echo "$manifest_response" | jq -r '.last_published // empty')

        if [ -z "$author_last_published" ]; then
            echo " - invalid manifest"
            continue
        fi

        # Check if there's new content
        local has_new_content=false
        if [ -z "$check_since" ]; then
            has_new_content=true  # Never checked, assume new
        elif [[ "$author_last_published" > "$check_since" ]]; then
            has_new_content=true
        fi

        if [ "$has_new_content" = false ]; then
            echo " - no new content"
            # Update last_checked even if no new content
            update_last_checked "$author_url"
            continue
        fi

        # Fetch public.jsonl to get new items
        local index_url="${author_url}/metadata/public.jsonl"
        local index_response=$(curl -s --max-time 30 "$index_url" 2>/dev/null)

        if [ -z "$index_response" ]; then
            echo " - could not fetch index"
            continue
        fi

        # Filter for new items
        local new_items
        if [ -n "$check_since" ]; then
            new_items=$(echo "$index_response" | jq -s --arg since "$check_since" '[.[] | select(.published > $since)]')
        else
            # Show last 10 items if never checked
            new_items=$(echo "$index_response" | jq -s 'sort_by(.published) | reverse | .[0:10]')
        fi

        local new_count=$(echo "$new_items" | jq 'length')

        if [ "$new_count" -eq 0 ]; then
            echo " - no new content"
        else
            echo ""
            echo "  â†’ $new_count new item(s):"

            # Display each new item
            echo "$new_items" | jq -r '.[] | "  [\(.type | ascii_upcase)] \(.title) - \(.published | split("T")[0])"'

            total_new_items=$((total_new_items + new_count))
            authors_with_new=$((authors_with_new + 1))
        fi

        # Update last_checked in following.json
        update_last_checked "$author_url"

    done

    echo ""
    if [ "$total_new_items" -gt 0 ]; then
        success "Found $total_new_items new item(s) from $authors_with_new author(s)"
    else
        info "No new content from followed authors"
    fi
}

# Update last_checked timestamp for an author in following.json
update_last_checked() {
    local author_url="$1"
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    local temp_file="${FOLLOWING_INDEX}.tmp"

    jq --arg url "$author_url" --arg ts "$timestamp" \
        '.following |= map(if .url == $url then .last_checked = $ts else . end)' \
        "$FOLLOWING_INDEX" > "$temp_file"

    mv "$temp_file" "$FOLLOWING_INDEX"
}

# Command: polis version
# Print CLI version
cmd_version() {
    if [ "$JSON_MODE" = true ]; then
        jq -n --arg version "$VERSION" '{ status: "success", command: "version", data: { version: $version } }'
    else
        echo "polis $VERSION"
    fi
}

# Command: polis about
# Display complete Polis system information (consolidated from about + config)
cmd_about() {
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GATHER DATA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # Site info
    local site_url="${POLIS_BASE_URL:-}"
    local site_title=""
    if [ -f "$MANIFEST" ]; then
        site_title=$(jq -r '.site_title // empty' "$MANIFEST" 2>/dev/null)
    fi

    # Version info from metadata files
    local wellknown_version="not initialized"
    local following_version="not initialized"
    local blessings_version="not initialized"
    local manifest_version="not initialized"

    if [ -f "$WELL_KNOWN_DIR/polis" ]; then
        wellknown_version=$(jq -r '.version // "unknown"' "$WELL_KNOWN_DIR/polis" 2>/dev/null || echo "unknown")
    fi
    if [ -f "$FOLLOWING_INDEX" ]; then
        following_version=$(jq -r '.version // "unknown"' "$FOLLOWING_INDEX" 2>/dev/null || echo "unknown")
    fi
    if [ -f "$BLESSED_COMMENTS" ]; then
        blessings_version=$(jq -r '.version // "unknown"' "$BLESSED_COMMENTS" 2>/dev/null || echo "unknown")
    fi
    if [ -f "$MANIFEST" ]; then
        manifest_version=$(jq -r '.version // "unknown"' "$MANIFEST" 2>/dev/null || echo "unknown")
    fi

    # Key info
    local key_status="not initialized"
    local key_fingerprint=""
    local pub_key_file="$KEYS_DIR/id_ed25519.pub"
    if [ -f "$pub_key_file" ]; then
        key_status="initialized"
        key_fingerprint=$(ssh-keygen -lf "$pub_key_file" 2>/dev/null | awk '{print $2}' || echo "unknown")
    fi

    # Discovery service info
    local discovery_url="${DISCOVERY_SERVICE_URL:-}"
    local discovery_key_set=false
    [ -n "$DISCOVERY_SERVICE_KEY" ] && discovery_key_set=true

    # Registration status (only check if discovery is configured)
    local registration_status="not configured"
    local registry_url=""
    local registered_at=""
    if [ -n "$DISCOVERY_SERVICE_URL" ] && [ -n "$DISCOVERY_SERVICE_KEY" ] && [ -n "$POLIS_BASE_URL" ]; then
        local domain=$(extract_domain_from_url "$POLIS_BASE_URL")
        if [ -n "$domain" ]; then
            local check_endpoint="${DISCOVERY_SERVICE_URL}/sites-check?domain=$domain"
            local check_response=$(curl -s -w "\n%{http_code}" \
                --location --request GET "$check_endpoint" \
                --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
                --header 'Content-Type: application/json' 2>&1)

            local check_http_code=$(echo "$check_response" | tail -n 1)
            local check_body=$(echo "$check_response" | sed '$d')

            if [ "$check_http_code" = "200" ]; then
                local is_registered=$(echo "$check_body" | jq -r '.is_registered // false' 2>/dev/null)
                if [ "$is_registered" = "true" ]; then
                    registration_status="registered"
                    registry_url=$(echo "$check_body" | jq -r '.registry_url // ""')
                    registered_at=$(echo "$check_body" | jq -r '.registered_at // ""')
                else
                    registration_status="not registered"
                fi
            else
                registration_status="check failed"
            fi
        fi
    fi

    # Check for version updates
    local upgrade_available="false"
    local latest_version=""
    local download_url=""
    if check_version_update; then
        upgrade_available="$UPGRADE_AVAILABLE"
        latest_version="$LATEST_VERSION"
        download_url="$LATEST_DOWNLOAD_URL"
    fi

    # Check for version pending apply
    local version_pending="false"
    if check_version_pending; then
        version_pending="true"
    fi

    # Get notification count
    local notification_count=$(get_notification_count)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OUTPUT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg site_url "$site_url" \
            --arg site_title "$site_title" \
            --arg cli_version "$VERSION" \
            --arg latest_version "$latest_version" \
            --argjson upgrade_available "$upgrade_available" \
            --arg download_url "$download_url" \
            --argjson version_pending "$version_pending" \
            --argjson notification_count "$notification_count" \
            --arg wellknown_version "$wellknown_version" \
            --arg following_version "$following_version" \
            --arg blessings_version "$blessings_version" \
            --arg manifest_version "$manifest_version" \
            --arg keys_dir "$KEYS_DIR" \
            --arg posts_dir "$POSTS_DIR" \
            --arg comments_dir "$COMMENTS_DIR" \
            --arg snippets_dir "$SNIPPETS_DIR" \
            --arg versions_dir "$VERSIONS_DIR_NAME" \
            --arg public_index "$PUBLIC_INDEX" \
            --arg blessed_comments "$BLESSED_COMMENTS" \
            --arg following_index "$FOLLOWING_INDEX" \
            --arg manifest_path "$MANIFEST" \
            --arg key_status "$key_status" \
            --arg key_fingerprint "$key_fingerprint" \
            --arg pub_key_file "$pub_key_file" \
            --arg discovery_url "$discovery_url" \
            --argjson discovery_key_set "$discovery_key_set" \
            --arg registration_status "$registration_status" \
            --arg registry_url "$registry_url" \
            --arg registered_at "$registered_at" \
            '{
                site: {
                    url: (if $site_url == "" then null else $site_url end),
                    title: (if $site_title == "" then null else $site_title end)
                },
                versions: {
                    cli: $cli_version,
                    latest: (if $latest_version == "" then null else $latest_version end),
                    upgrade_available: $upgrade_available,
                    download_url: (if $download_url == "" then null else $download_url end),
                    version_pending: $version_pending,
                    well_known_polis: $wellknown_version,
                    following: $following_version,
                    blessed_comments: $blessings_version,
                    manifest: $manifest_version
                },
                notifications: {
                    unread_count: $notification_count
                },
                configuration: {
                    directories: {
                        keys: $keys_dir,
                        posts: $posts_dir,
                        comments: $comments_dir,
                        snippets: $snippets_dir,
                        versions: $versions_dir
                    },
                    files: {
                        public_index: $public_index,
                        blessed_comments: $blessed_comments,
                        following: $following_index,
                        manifest: $manifest_path
                    }
                },
                keys: {
                    status: $key_status,
                    fingerprint: (if $key_fingerprint == "" then null else $key_fingerprint end),
                    public_key_path: $pub_key_file
                },
                discovery: {
                    service_url: (if $discovery_url == "" then null else $discovery_url end),
                    api_key_set: $discovery_key_set,
                    registration: {
                        status: $registration_status,
                        registry_url: (if $registry_url == "" then null else $registry_url end),
                        registered_at: (if $registered_at == "" then null else $registered_at end)
                    }
                },
                project: {
                    repository: "https://github.com/vdibart/polis",
                    license: "AGPL-3.0"
                }
            }')
        json_success "about" "$result"
    else
        # Display branded output with sections
        echo ""
        echo -e "${BOLD}${CYAN}Polis${NC} - Decentralized Social Network"
        echo -e "${DIM}Your content, free from platform control${NC}"
        echo ""

        # SITE
        echo -e "${CYAN}SITE${NC}"
        echo -e "  URL:      ${site_url:-${DIM}[not set]${NC}}"
        echo -e "  Title:    ${site_title:-${DIM}[not set]${NC}}"
        echo ""

        # VERSIONS
        echo -e "${CYAN}VERSIONS${NC}"
        if [ "$upgrade_available" = "true" ]; then
            echo -e "  CLI:                   $VERSION ${YELLOW}â†’ $latest_version available${NC}"
        else
            echo "  CLI:                   $VERSION"
        fi
        if [ "$version_pending" = "true" ]; then
            echo -e "  ${YELLOW}! Metadata files need update. Run 'polis rebuild'${NC}"
        fi
        echo "  .well-known/polis:     $wellknown_version"
        echo "  following.json:        $following_version"
        echo "  blessed-comments.json: $blessings_version"
        echo "  manifest.json:         $manifest_version"
        echo ""

        # NOTIFICATIONS
        if [ "$notification_count" -gt 0 ]; then
            echo -e "${CYAN}NOTIFICATIONS${NC}"
            echo -e "  ${YELLOW}$notification_count unread${NC} - run 'polis notifications' to view"
            echo ""
        fi

        # CONFIGURATION
        echo -e "${CYAN}CONFIGURATION${NC}"
        echo "  Directories:"
        echo "    Keys:      $KEYS_DIR"
        echo "    Posts:     $POSTS_DIR"
        echo "    Comments:  $COMMENTS_DIR"
        echo "    Snippets:  $SNIPPETS_DIR"
        echo "    Versions:  $VERSIONS_DIR_NAME"
        echo ""
        echo "  Files:"
        echo "    Public index:      $PUBLIC_INDEX"
        echo "    Blessed comments:  $BLESSED_COMMENTS"
        echo "    Following:         $FOLLOWING_INDEX"
        echo "    Manifest:          $MANIFEST"
        echo ""

        # KEYS
        echo -e "${CYAN}KEYS${NC}"
        echo "  Status:       $key_status"
        if [ "$key_status" = "initialized" ]; then
            echo "  Fingerprint:  $key_fingerprint"
            echo "  Public key:   $pub_key_file"
        fi
        echo ""

        # DISCOVERY
        echo -e "${CYAN}DISCOVERY${NC}"
        echo -e "  Service URL:  ${discovery_url:-${DIM}[not set]${NC}}"
        if [ "$discovery_key_set" = true ]; then
            echo "  API Key:      [set]"
        else
            echo -e "  API Key:      ${DIM}[not set]${NC}"
        fi
        if [ "$registration_status" = "registered" ]; then
            echo -e "  Registration: ${GREEN}registered${NC}"
            [ -n "$registry_url" ] && echo "  Registry URL: $registry_url"
            [ -n "$registered_at" ] && echo "  Registered:   $registered_at"
        elif [ "$registration_status" = "not registered" ]; then
            echo -e "  Registration: ${YELLOW}not registered${NC}"
        elif [ "$registration_status" = "not configured" ]; then
            echo -e "  Registration: ${DIM}not configured${NC}"
        else
            echo -e "  Registration: ${RED}check failed${NC}"
        fi
        echo ""

        # PROJECT
        echo -e "${CYAN}PROJECT${NC}"
        echo "  Repository:   https://github.com/vdibart/polis"
        echo "  License:      AGPL-3.0"
        echo ""
    fi
}

# Command: polis rotate-key [--delete-old-key]
# Generate new keypair and re-sign all posts and comments
cmd_rotate_key() {
    local delete_old=false

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --delete-old-key)
                delete_old=true
                shift
                ;;
            *)
                json_error "rotate-key" "INVALID_INPUT" "Unknown option: $1. Usage: polis rotate-key [--delete-old-key]"
                ;;
        esac
    done

    # Verify initialized
    if [ ! -f "$KEYS_DIR/id_ed25519" ]; then
        json_error "rotate-key" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "rotate-key" "INVALID_STATE" ".well-known/polis not found. Run 'polis init' first."
    fi

    info_human "Starting key rotation..."
    info_human ""

    # 1. Generate new keypair
    info_human "Generating new Ed25519 keypair..."
    ssh-keygen -t ed25519 -f "$KEYS_DIR/id_ed25519.new" -N "" -C "polis@$(hostname)" > /dev/null 2>&1
    if [ $? -ne 0 ]; then
        json_error "rotate-key" "KEY_GENERATION_FAILED" "Failed to generate new keypair"
    fi
    success_human "Generated new keypair"

    # 2. Backup old key
    mv "$KEYS_DIR/id_ed25519" "$KEYS_DIR/id_ed25519.old"
    mv "$KEYS_DIR/id_ed25519.pub" "$KEYS_DIR/id_ed25519.old.pub"

    # 3. Install new key
    mv "$KEYS_DIR/id_ed25519.new" "$KEYS_DIR/id_ed25519"
    mv "$KEYS_DIR/id_ed25519.new.pub" "$KEYS_DIR/id_ed25519.pub"
    success_human "Installed new keypair"

    # 4. Re-sign all posts
    local posts_count=0
    local posts_failed=0
    info_human ""
    info_human "Re-signing posts..."

    if [ -d "$POSTS_DIR" ]; then
        while IFS= read -r -d '' file; do
            if resign_file "$file"; then
                ((posts_count++))
            else
                ((posts_failed++))
                warn_human "  Failed to re-sign: $file"
            fi
        done < <(find "$POSTS_DIR" -name "*.md" -type f -print0 2>/dev/null)
    fi
    success_human "Re-signed $posts_count posts"

    # 5. Re-sign all comments
    local comments_count=0
    local comments_failed=0
    info_human ""
    info_human "Re-signing comments..."

    if [ -d "$COMMENTS_DIR" ]; then
        while IFS= read -r -d '' file; do
            if resign_file "$file"; then
                ((comments_count++))
            else
                ((comments_failed++))
                warn_human "  Failed to re-sign: $file"
            fi
        done < <(find "$COMMENTS_DIR" -name "*.md" -type f -print0 2>/dev/null)
    fi
    success_human "Re-signed $comments_count comments"

    # 6. Update .well-known/polis
    info_human ""
    info_human "Updating .well-known/polis..."
    if update_wellknown_pubkey; then
        success_human "Updated public key in .well-known/polis"
    else
        warn_human "Failed to update .well-known/polis"
    fi

    # 7. Rebuild index
    info_human ""
    info_human "Rebuilding index..."
    cmd_rebuild --posts > /dev/null 2>&1
    success_human "Rebuilt public.jsonl index"

    # 8. Handle old key
    local old_key_status
    if [ "$delete_old" = true ]; then
        rm -f "$KEYS_DIR/id_ed25519.old" "$KEYS_DIR/id_ed25519.old.pub"
        old_key_status="deleted"
        info_human ""
        info_human "Deleted old keypair"
    else
        old_key_status="archived"
        info_human ""
        info_human "Old keypair archived at $KEYS_DIR/id_ed25519.old"
    fi

    # Get new key fingerprint
    local new_fingerprint=$(ssh-keygen -lf "$KEYS_DIR/id_ed25519.pub" 2>/dev/null | awk '{print $2}')

    # Output results
    info_human ""
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --argjson posts "$posts_count" \
            --argjson posts_failed "$posts_failed" \
            --argjson comments "$comments_count" \
            --argjson comments_failed "$comments_failed" \
            --arg old_key_status "$old_key_status" \
            --arg fingerprint "$new_fingerprint" \
            '{
                posts_resigned: $posts,
                posts_failed: $posts_failed,
                comments_resigned: $comments,
                comments_failed: $comments_failed,
                old_key: $old_key_status,
                new_key_fingerprint: $fingerprint
            }')
        json_success "rotate-key" "$result"
    else
        success "Key rotation complete!"
        info "  Posts re-signed: $posts_count"
        info "  Comments re-signed: $comments_count"
        info "  New key fingerprint: $new_fingerprint"
        if [ "$old_key_status" = "archived" ]; then
            info "  Old key: archived at $KEYS_DIR/id_ed25519.old"
        else
            info "  Old key: deleted"
        fi
    fi
}

# Command: polis extract <file> <hash>
cmd_get_version() {
    local file="$1"
    local target_hash="$2"

    if [ -z "$file" ] || [ -z "$target_hash" ]; then
        error "Usage: polis extract <file> <hash>"
    fi

    if [ ! -f "$file" ]; then
        error "File not found: $file"
    fi

    # Ensure hash has sha256: prefix
    if [[ ! "$target_hash" =~ ^sha256: ]]; then
        target_hash="sha256:$target_hash"
    fi

    info "Reconstructing version $target_hash..."

    # Create temporary output file
    local output=$(mktemp)

    # Reconstruct the version
    reconstruct_version "$file" "$target_hash" "$output"

    # Output to stdout
    cat "$output"

    # Clean up
    rm -f "$output"
}

# ============================================================================
# BLESSING COMMANDS
# ============================================================================

# Command: polis blessing requests
cmd_blessing_requests() {
    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "blessing-requests" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Sync blessed comments first (catches auto-blessed comments from server)
    if [ -n "$POLIS_BASE_URL" ]; then
        local synced=$(sync_blessed_comments)
        if [ "$synced" -gt 0 ]; then
            info_human "Synced $synced auto-blessed comment(s) to blessed-comments.json"
        fi
    fi

    # Extract author and domain
    local author=$(extract_author_from_wellknown)
    local domain=$(extract_domain_from_url "$POLIS_BASE_URL")

    # Construct endpoint URL
    local endpoint="${POLIS_BLESSING_REQUESTS_ENDPOINT}"

    info_human "Fetching pending blessing requests for ${author} from ${endpoint} ..."

    # Fetch requests
    local response=$(curl -s \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        "${endpoint}?in_reply_to_domain=${domain}")

    if [ $? -ne 0 ]; then
        json_error "blessing-requests" "API_ERROR" "Failed to connect to discovery service. Check your internet connection and POLIS_BESEECH_ENDPOINT."
    fi

    # Check if jq is available
    if ! command -v jq > /dev/null 2>&1; then
        json_error "blessing-requests" "MISSING_DEPENDENCY" "jq is required but not installed. Please install jq to continue."
    fi

    # Check for API errors
    local error_msg=$(echo "$response" | jq -r '.error // empty' 2>/dev/null)
    if [ -n "$error_msg" ]; then
        json_error "blessing-requests" "API_ERROR" "API error: $error_msg"
    fi

    # In JSON mode, return the API response directly
    if [ "$JSON_MODE" = true ]; then
        # Extract requests array and count
        local requests=$(echo "$response" | jq -c '.requests // []')
        local count=$(echo "$response" | jq -r '.count // 0')

        local result=$(jq -n \
            --argjson count "$count" \
            --argjson requests "$requests" \
            '{
                count: $count,
                requests: $requests
            }')
        json_success "blessing-requests" "$result"
    else
        # Format and display table
        format_blessing_table "$response"
    fi
}

# Command: polis blessing grant <hash>
cmd_blessing_grant() {
    local input_hash="$1"

    # Validate arguments
    if [ -z "$input_hash" ]; then
        json_error "blessing-grant" "INVALID_INPUT" "Usage: polis blessing grant <hash>"
    fi

    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "blessing-grant" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check POLIS_BASE_URL is set (needed for domain extraction)
    if [ -z "$POLIS_BASE_URL" ]; then
        json_error "blessing-grant" "INVALID_STATE" "POLIS_BASE_URL not set. Export it first."
    fi

    # Resolve short hash to full comment_version
    info_human "Resolving hash..."
    local domain=$(echo "$POLIS_BASE_URL" | sed 's|https\?://||' | sed 's|/.*||')
    local comment_version

    # Check if input is already a full hash (starts with sha256:)
    if [[ "$input_hash" == sha256:* ]]; then
        comment_version="$input_hash"
    else
        comment_version=$(resolve_short_hash "$input_hash" "$domain")
    fi

    if [ -z "$comment_version" ]; then
        json_error "blessing-grant" "NOT_FOUND" "No pending request found matching hash: $input_hash"
    fi

    local short_hash=$(format_short_hash "$comment_version")

    # Fetch request details
    info_human "Fetching request details..."
    local request_json=$(fetch_request_details "$comment_version")

    if [ -z "$request_json" ] || [ "$request_json" = "null" ]; then
        json_error "blessing-grant" "NOT_FOUND" "Request $short_hash not found"
    fi

    # Display request details in human mode
    if [ "$JSON_MODE" = false ]; then
        display_request_details "$short_hash" "$request_json"
    fi

    # Validate comment URL is reachable before blessing
    local comment_url=$(echo "$request_json" | jq -r '.comment_url')
    if [ -n "$comment_url" ] && [ "$comment_url" != "null" ]; then
        local url_status=$(curl -s -o /dev/null -w "%{http_code}" "$comment_url")
        if [ "$url_status" = "404" ]; then
            json_error "blessing-grant" "COMMENT_NOT_FOUND" "Comment URL returns 404. The comment may have been deleted: $comment_url"
        elif [ "$url_status" != "200" ]; then
            warn_human "Warning: Comment URL returned HTTP $url_status (expected 200)"
        fi
    fi

    # Create signed payload for authentication
    # The signature proves the requester controls the post author's domain
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local canonical_payload=$(jq -n -c \
        --arg action "grant" \
        --arg version "$comment_version" \
        --arg ts "$timestamp" \
        '{action: $action, comment_version: $version, timestamp: $ts}')

    # Sign the payload
    local temp_file=$(mktemp)
    echo -n "$canonical_payload" > "$temp_file"
    local keyfile="$KEYS_DIR/id_ed25519"
    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1
    local signature=$(cat "$temp_file.sig")
    rm -f "$temp_file" "$temp_file.sig"

    # Prepare POST payload with signature
    local payload=$(jq -n \
        --arg version "$comment_version" \
        --arg action "grant" \
        --arg ts "$timestamp" \
        --arg sig "$signature" \
        '{comment_version: $version, action: $action, timestamp: $ts, signature: $sig}')

    # Call bless endpoint
    local response=$(curl -s -w "\n%{http_code}" \
        --location --request POST "$POLIS_BLESS_ENDPOINT" \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        --header 'Content-Type: application/json' \
        --data "$payload")

    # Extract HTTP status code
    local http_code=$(echo "$response" | tail -n 1)
    local body=$(echo "$response" | sed '$d')

    # Handle response
    case "$http_code" in
        200)
            # Extract comment details from response
            local comment_url=$(echo "$body" | jq -r '.request.comment_url')
            local resp_version=$(echo "$body" | jq -r '.request.comment_version')
            local in_reply_to=$(echo "$body" | jq -r '.request.in_reply_to')
            local blessed_at=$(echo "$body" | jq -r '.request.blessed_at')
            local author=$(echo "$body" | jq -r '.request.author')

            # Update blessed-comments.json
            update_blessed_comments_json "$comment_url" "$resp_version" "$in_reply_to" "$blessed_at"

            # Extract blessed_by from server response (server determines this from verified domain)
            local blessed_by=$(echo "$body" | jq -r '.request.blessed_by // empty')

            if [ "$JSON_MODE" = true ]; then
                local result=$(jq -n \
                    --arg version "$comment_version" \
                    --arg url "$comment_url" \
                    --arg blessed_at "$blessed_at" \
                    --arg blessed_by "$blessed_by" \
                    '{
                        comment_version: $version,
                        comment_url: $url,
                        blessed_at: $blessed_at,
                        blessed_by: $blessed_by
                    }')
                json_success "blessing-grant" "$result"
            else
                success "Blessing granted for request $short_hash"
                success "Updated blessed-comments.json"
                info "Comment from $author is now blessed"
            fi
            ;;
        403)
            json_error "blessing-grant" "PERMISSION_ERROR" "Signature verification failed: You can only bless comments on your own posts. Response: $body"
            ;;
        404)
            json_error "blessing-grant" "INVALID_INPUT" "Request $short_hash not found. Response: $body"
            ;;
        400)
            json_error "blessing-grant" "INVALID_INPUT" "Invalid request. Response: $body"
            ;;
        *)
            json_error "blessing-grant" "API_ERROR" "Failed to grant blessing (HTTP $http_code). Response: $body"
            ;;
    esac
}

# Command: polis blessing deny <hash>
cmd_blessing_deny() {
    local input_hash="$1"

    # Validate arguments
    if [ -z "$input_hash" ]; then
        json_error "blessing-deny" "INVALID_INPUT" "Usage: polis blessing deny <hash>"
    fi

    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "blessing-deny" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check POLIS_BASE_URL is set (needed for domain extraction)
    if [ -z "$POLIS_BASE_URL" ]; then
        json_error "blessing-deny" "INVALID_STATE" "POLIS_BASE_URL not set. Export it first."
    fi

    # Resolve short hash to full comment_version
    info_human "Resolving hash..."
    local domain=$(echo "$POLIS_BASE_URL" | sed 's|https\?://||' | sed 's|/.*||')
    local comment_version

    # Check if input is already a full hash (starts with sha256:)
    if [[ "$input_hash" == sha256:* ]]; then
        comment_version="$input_hash"
    else
        comment_version=$(resolve_short_hash "$input_hash" "$domain")
    fi

    if [ -z "$comment_version" ]; then
        json_error "blessing-deny" "NOT_FOUND" "No pending request found matching hash: $input_hash"
    fi

    local short_hash=$(format_short_hash "$comment_version")

    # Fetch request details
    info_human "Fetching request details..."
    local request_json=$(fetch_request_details "$comment_version")

    if [ -z "$request_json" ] || [ "$request_json" = "null" ]; then
        json_error "blessing-deny" "NOT_FOUND" "Request $short_hash not found"
    fi

    # Display request details in human mode
    if [ "$JSON_MODE" = false ]; then
        display_request_details "$short_hash" "$request_json"
    fi

    # Check if comment URL is reachable (warn only, don't block deny)
    local comment_url=$(echo "$request_json" | jq -r '.comment_url')
    if [ -n "$comment_url" ] && [ "$comment_url" != "null" ]; then
        local url_status=$(curl -s -o /dev/null -w "%{http_code}" "$comment_url")
        if [ "$url_status" = "404" ]; then
            warn_human "Note: Comment URL returns 404 (may have been deleted)"
        fi
    fi

    # Create signed payload for authentication
    # The signature proves the requester controls the post author's domain
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local canonical_payload=$(jq -n -c \
        --arg action "deny" \
        --arg version "$comment_version" \
        --arg ts "$timestamp" \
        '{action: $action, comment_version: $version, timestamp: $ts}')

    # Sign the payload
    local temp_file=$(mktemp)
    echo -n "$canonical_payload" > "$temp_file"
    local keyfile="$KEYS_DIR/id_ed25519"
    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1
    local signature=$(cat "$temp_file.sig")
    rm -f "$temp_file" "$temp_file.sig"

    # Prepare POST payload with signature
    local payload=$(jq -n \
        --arg version "$comment_version" \
        --arg action "deny" \
        --arg ts "$timestamp" \
        --arg sig "$signature" \
        '{comment_version: $version, action: $action, timestamp: $ts, signature: $sig}')

    # Call deny endpoint
    local response=$(curl -s -w "\n%{http_code}" \
        --location --request POST "$POLIS_DENY_ENDPOINT" \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        --header 'Content-Type: application/json' \
        --data "$payload")

    # Extract HTTP status code
    local http_code=$(echo "$response" | tail -n 1)
    local body=$(echo "$response" | sed '$d')

    # Handle response
    case "$http_code" in
        200)
            # Extract comment details from response
            local comment_url=$(echo "$body" | jq -r '.request.comment_url')
            local in_reply_to=$(echo "$body" | jq -r '.request.in_reply_to')
            local denied_at=$(echo "$body" | jq -r '.request.denied_at // .request.blessed_at // ""')
            local author=$(echo "$body" | jq -r '.request.author')

            # Remove from blessed-comments.json if it was previously blessed
            remove_from_blessed_comments_json "$comment_url" "$in_reply_to"

            # Extract denied_by from server response (server determines this from verified domain)
            local denied_by=$(echo "$body" | jq -r '.request.blessed_by // empty')

            if [ "$JSON_MODE" = true ]; then
                local result=$(jq -n \
                    --arg version "$comment_version" \
                    --arg url "$comment_url" \
                    --arg denied_at "$denied_at" \
                    --arg denied_by "$denied_by" \
                    '{
                        comment_version: $version,
                        comment_url: $url,
                        denied_at: $denied_at,
                        denied_by: $denied_by
                    }')
                json_success "blessing-deny" "$result"
            else
                success "Blessing denied for request $short_hash"
                info "Removed from blessed-comments.json (if present)"
                info "Comment from $author has been denied"
            fi
            ;;
        403)
            json_error "blessing-deny" "PERMISSION_ERROR" "Signature verification failed: You can only deny comments on your own posts. Response: $body"
            ;;
        404)
            json_error "blessing-deny" "INVALID_INPUT" "Request $short_hash not found. Response: $body"
            ;;
        400)
            json_error "blessing-deny" "INVALID_INPUT" "Invalid request. Response: $body"
            ;;
        *)
            json_error "blessing-deny" "API_ERROR" "Failed to deny blessing (HTTP $http_code). Response: $body"
            ;;
    esac
}

# Command: polis blessing sync
# Synchronize blessed comments from discovery service to local blessed-comments.json
cmd_blessing_sync() {
    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "blessing-sync" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check POLIS_BASE_URL is set
    if [ -z "$POLIS_BASE_URL" ]; then
        json_error "blessing-sync" "INVALID_STATE" "POLIS_BASE_URL not set. Export it first: export POLIS_BASE_URL=https://yourdomain.com"
    fi

    info_human "Syncing blessed comments from discovery service..."

    local synced=$(sync_blessed_comments)

    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --argjson synced_count "$synced" \
            '{synced_count: $synced_count}')
        json_success "blessing-sync" "$result"
    else
        if [ "$synced" -gt 0 ]; then
            success "Synced $synced comment(s) to blessed-comments.json"
        else
            info "Already in sync - no new comments to add"
        fi
    fi
}

# Command: polis follow <author-url>
cmd_follow() {
    local author_url="$1"

    # Validate author_url
    if [ -z "$author_url" ]; then
        json_error "follow" "INVALID_INPUT" "Usage: polis follow <author-url>"
    fi

    # Validate URL format (must be HTTPS)
    if [[ ! "$author_url" =~ ^https:// ]]; then
        json_error "follow" "INVALID_INPUT" "Author URL must use HTTPS (e.g., https://example.com)"
    fi

    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "follow" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Extract blessed_by (current user's email)
    local blessed_by=$(extract_author_from_wellknown)

    # Fetch author email from their .well-known/polis
    info_human "Fetching author information from $author_url..."
    local author_email=$(fetch_author_email_from_wellknown "$author_url")

    if [ -z "$author_email" ]; then
        json_error "follow" "API_ERROR" "Failed to fetch author email from $author_url"
    fi

    info_human "Author email: $author_email"

    # Fetch unblessed comments from this author
    info_human "Fetching comments from $author_email..."
    local pending_comments=$(fetch_comments_by_author "$author_email" "pending")
    local denied_comments=$(fetch_comments_by_author "$author_email" "denied")

    # Combine pending and denied into one array
    local unblessed_comments=$(jq -s 'add' <(echo "$pending_comments") <(echo "$denied_comments"))
    local comment_count=$(echo "$unblessed_comments" | jq 'length')

    # Display summary in human mode
    if [ "$JSON_MODE" = false ]; then
        echo ""
        info "Following: $author_url ($author_email)"

        if [ "$comment_count" -gt 0 ]; then
            echo "Found $comment_count unblessed comment(s) from this author on your posts:"
            echo ""

            # Show first 5 comments as preview
            local preview_count=$comment_count
            if [ "$comment_count" -gt 5 ]; then
                preview_count=5
            fi

            echo "$unblessed_comments" | jq -r --arg count "$preview_count" \
                'limit($count | tonumber; .[]) | "  - Request #\(.id): \(.comment_url | split("/")[-1]) (\(.timestamp[:10]))"'

            if [ "$comment_count" -gt 5 ]; then
                echo "  ... and $((comment_count - 5)) more"
            fi

            echo ""
            echo "All these comments will be blessed."
        else
            echo "No unblessed comments found from this author."
            echo "Future comments from this author will be automatically blessed."
        fi
        echo ""
    fi

    # Bless all unblessed comments
    local blessed_count=0
    local failed_count=0

    if [ "$comment_count" -gt 0 ]; then
        info_human "Blessing $comment_count comment(s)..."

        # Loop through each comment
        while IFS= read -r comment_id; do
            if [ -z "$comment_id" ] || [ "$comment_id" = "null" ]; then
                continue
            fi

            # Prepare POST payload
            local payload=$(jq -n \
                --argjson id "$comment_id" \
                --arg by "$blessed_by" \
                '{comment_id: $id, blessed_by: $by}')

            # Call bless endpoint
            local response=$(curl -s -w "\n%{http_code}" \
                --location --request POST "$POLIS_BLESS_ENDPOINT" \
                --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
                --header 'Content-Type: application/json' \
                --data "$payload")

            # Extract HTTP status code
            local http_code=$(echo "$response" | tail -n 1)
            local body=$(echo "$response" | sed '$d')

            # Handle response
            if [ "$http_code" = "200" ]; then
                # Extract comment details from response
                local comment_url=$(echo "$body" | jq -r '.request.comment_url')
                local comment_version=$(echo "$body" | jq -r '.request.comment_version')
                local in_reply_to=$(echo "$body" | jq -r '.request.in_reply_to')
                local blessed_at=$(echo "$body" | jq -r '.request.blessed_at')

                # Update blessed-comments.json
                update_blessed_comments_json "$comment_url" "$comment_version" "$in_reply_to" "$blessed_at"

                blessed_count=$((blessed_count + 1))
            else
                failed_count=$((failed_count + 1))
                info_human "Warning: Failed to bless request #$comment_id (HTTP $http_code)"
            fi
        done < <(echo "$unblessed_comments" | jq -r '.[].id')
    fi

    # Add to following.json
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    add_to_following_json "$author_url" "$timestamp"

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg url "$author_url" \
            --arg email "$author_email" \
            --argjson found "$comment_count" \
            --argjson blessed "$blessed_count" \
            '{
                author_url: $url,
                author_email: $email,
                comments_found: $found,
                comments_blessed: $blessed,
                added_to_following: true
            }')
        json_success "follow" "$result"
    else
        # Display success summary
        echo ""
        success "Successfully followed $author_url"
        echo "  - Added to following.json"

        if [ "$comment_count" -gt 0 ]; then
            if [ "$failed_count" -eq 0 ]; then
                echo "  - Blessed $blessed_count comment(s)"
            else
                echo "  - Blessed $blessed_count/$comment_count comment(s) ($failed_count failed)"
            fi
        fi
    fi
}

# Command: polis unfollow <author-url>
cmd_unfollow() {
    local author_url="$1"

    # Validate author_url
    if [ -z "$author_url" ]; then
        json_error "unfollow" "INVALID_INPUT" "Usage: polis unfollow <author-url>"
    fi

    # Validate URL format (must be HTTPS)
    if [[ ! "$author_url" =~ ^https:// ]]; then
        json_error "unfollow" "INVALID_INPUT" "Author URL must use HTTPS (e.g., https://example.com)"
    fi

    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "unfollow" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Extract blessed_by (current user's email)
    local blessed_by=$(extract_author_from_wellknown)

    # Get blessed comment URLs from this author
    # Check both local blessed-comments.json AND server (for unsynced auto-blessed)
    info_human "Finding blessed comments from $author_url..."

    # 1. Get local blessed URLs
    local local_blessed_urls=$(get_blessed_comment_urls_by_author "$author_url")
    local local_urls_list=$(echo "$local_blessed_urls" | jq -r '.[]' 2>/dev/null || echo "")

    # 2. Also fetch from server (catches unsynced auto-blessed comments)
    local author_email=""
    local server_urls_list=""
    author_email=$(fetch_author_email_from_wellknown "$author_url" 2>/dev/null) || true

    if [ -n "$author_email" ]; then
        local server_blessed=$(fetch_comments_by_author "$author_email" "blessed" 2>/dev/null) || true
        if [ -n "$server_blessed" ] && [ "$server_blessed" != "[]" ] && [ "$server_blessed" != "null" ]; then
            server_urls_list=$(echo "$server_blessed" | jq -r '.[].comment_url' 2>/dev/null || echo "")
        fi
    fi

    # 3. Combine and deduplicate URLs
    local all_urls_list=$(echo -e "$local_urls_list\n$server_urls_list" | sort -u | grep -v '^$')
    local blessed_urls=$(echo "$all_urls_list" | jq -R . | jq -s .)
    local url_count=$(echo "$blessed_urls" | jq 'length')

    if [ "$url_count" -eq 0 ]; then
        remove_from_following_json "$author_url"

        if [ "$JSON_MODE" = true ]; then
            local result=$(jq -n \
                --arg url "$author_url" \
                '{
                    author_url: $url,
                    comments_found: 0,
                    comments_denied: 0,
                    removed_from_following: true
                }')
            json_success "unfollow" "$result"
        else
            info "No blessed comments found from this author"
            success "Successfully unfollowed $author_url"
        fi
        exit 0
    fi

    info_human "Found $url_count blessed comment(s), looking up IDs..."

    # Lookup comment ID for each blessed comment URL
    local comment_ids=()
    local lookup_failures=0

    while IFS= read -r comment_url; do
        if [ -z "$comment_url" ] || [ "$comment_url" = "null" ]; then
            continue
        fi

        local comment_id=$(get_comment_id_by_url "$comment_url")
        if [ -n "$comment_id" ] && [ "$comment_id" != "null" ]; then
            comment_ids+=("$comment_id")
        else
            lookup_failures=$((lookup_failures + 1))
            info_human "Warning: Could not find ID for $comment_url"
        fi
    done < <(echo "$blessed_urls" | jq -r '.[]')

    local comment_count=${#comment_ids[@]}

    # Display summary in human mode
    if [ "$JSON_MODE" = false ]; then
        echo ""
        info "Unfollowing: $author_url"
        echo "Found $comment_count blessed comment(s) to deny"
        if [ $lookup_failures -gt 0 ]; then
            echo "Warning: $lookup_failures comment(s) could not be looked up"
        fi
        echo ""
    fi

    # Deny each comment
    local denied_count=0
    local failed_count=0

    if [ $comment_count -gt 0 ]; then
        info_human "Denying $comment_count blessed comment(s)..."

        for comment_id in "${comment_ids[@]}"; do
            # Prepare POST payload
            local payload=$(jq -n \
                --argjson id "$comment_id" \
                --arg by "$blessed_by" \
                '{comment_id: $id, blessed_by: $by}')

            # Call deny endpoint
            local response=$(curl -s -w "\n%{http_code}" \
                --location --request POST "$POLIS_DENY_ENDPOINT" \
                --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
                --header 'Content-Type: application/json' \
                --data "$payload")

            local http_code=$(echo "$response" | tail -n 1)
            local body=$(echo "$response" | sed '$d')

            if [ "$http_code" = "200" ]; then
                local comment_url=$(echo "$body" | jq -r '.request.comment_url')
                local in_reply_to=$(echo "$body" | jq -r '.request.in_reply_to')

                # Remove from blessed-comments.json
                remove_from_blessed_comments_json "$comment_url" "$in_reply_to"

                denied_count=$((denied_count + 1))
            else
                failed_count=$((failed_count + 1))
                info_human "Warning: Failed to deny comment #$comment_id (HTTP $http_code)"
            fi
        done
    fi

    # Remove from following.json
    remove_from_following_json "$author_url"

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg url "$author_url" \
            --argjson found "$url_count" \
            --argjson denied "$denied_count" \
            '{
                author_url: $url,
                comments_found: $found,
                comments_denied: $denied,
                removed_from_following: true
            }')
        json_success "unfollow" "$result"
    else
        # Display success summary
        echo ""
        success "Successfully unfollowed $author_url"
        echo "  - Removed from following.json"

        if [ $comment_count -gt 0 ]; then
            if [ $failed_count -eq 0 ]; then
                echo "  - Denied $denied_count blessed comment(s)"
            else
                echo "  - Denied $denied_count/$comment_count comment(s) ($failed_count failed)"
            fi
        fi
    fi
}

# Command: polis blessing <subcommand>
cmd_blessing() {
    local subcommand="$1"
    shift

    case "$subcommand" in
        requests)
            cmd_blessing_requests "$@"
            ;;
        grant)
            cmd_blessing_grant "$@"
            ;;
        deny)
            cmd_blessing_deny "$@"
            ;;
        beseech)
            cmd_blessing_beseech "$@"
            ;;
        sync)
            cmd_blessing_sync "$@"
            ;;
        *)
            error "Unknown blessing subcommand: $subcommand

Usage: polis blessing requests
       polis blessing grant <hash>
       polis blessing deny <hash>
       polis blessing beseech <hash>
       polis blessing sync"
            ;;
    esac
}

# Command: polis post <filename>
cmd_post() {
    # Parse command-specific flags first
    local explicit_filename=""
    local explicit_title=""
    local positional_args=()

    while [[ $# -gt 0 ]]; do
        case $1 in
            --filename)
                explicit_filename="$2"
                shift 2
                ;;
            --title)
                explicit_title="$2"
                shift 2
                ;;
            *)
                positional_args+=("$1")
                shift
                ;;
        esac
    done

    # Restore positional arguments
    set -- "${positional_args[@]}"

    local input_file="$1"

    if [ -z "$input_file" ]; then
        json_error "post" "INVALID_INPUT" "Usage: polis post <filename>\n       polis post - [--filename <name>] [--title <title>]"
    fi

    if [ ! -f "$KEYS_DIR/id_ed25519" ]; then
        json_error "post" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check for stdin mode
    local stdin_mode=false
    local temp_stdin=""

    if [ "$input_file" = "-" ]; then
        stdin_mode=true

        # Verify stdin is not a terminal (has actual content)
        if [ -t 0 ]; then
            json_error "post" "INVALID_INPUT" "No stdin content. Use: echo 'content' | polis post -"
        fi

        # Create temp file and read stdin
        temp_stdin=$(mktemp)
        cat > "$temp_stdin"

        # Verify content
        if [ ! -s "$temp_stdin" ]; then
            rm -f "$temp_stdin"
            json_error "post" "INVALID_INPUT" "Stdin content is empty"
        fi

        # Point input_file to temp file
        input_file="$temp_stdin"

        info_human "Reading content from stdin..."
    else
        # Regular file mode - check file exists
        if [ ! -f "$input_file" ]; then
            json_error "post" "FILE_NOT_FOUND" "File not found: $input_file"
        fi
    fi

    # Ensure temp file cleanup on exit or error
    cleanup_stdin() {
        if [ -n "$temp_stdin" ] && [ -f "$temp_stdin" ]; then
            rm -f "$temp_stdin"
        fi
    }
    trap cleanup_stdin EXIT ERR

    # Check if file already has frontmatter (already published)
    # Skip this check for stdin mode as stdin content is always new
    if [ "$stdin_mode" = false ] && has_frontmatter "$input_file"; then
        json_error "post" "INVALID_STATE" "File already published (has frontmatter). Use 'polis republish' to update it."
    fi

    # Store original file path for cleanup later
    local original_file="$input_file"

    # Determine base filename
    local base_filename
    if [ -n "$explicit_filename" ]; then
        # Explicit filename takes precedence in all modes
        base_filename="$explicit_filename"
        # Ensure .md extension
        [[ ! "$base_filename" =~ \.md$ ]] && base_filename="${base_filename}.md"
    elif [ "$stdin_mode" = true ]; then
        # Generate synthetic filename for stdin
        local timestamp_filename=$(date +%Y%m%d-%H%M%S)
        base_filename="stdin-${timestamp_filename}.md"
    else
        # Regular file mode - convert to absolute path for comparison
        if command -v realpath > /dev/null 2>&1; then
            input_file=$(realpath "$input_file")
        elif command -v readlink > /dev/null 2>&1; then
            input_file=$(readlink -f "$input_file" 2>/dev/null || echo "$input_file")
        fi
        base_filename=$(basename "$input_file")
    fi

    if [ "$stdin_mode" = true ]; then
        info_human "Publishing from stdin as $base_filename..."
    else
        info_human "Publishing $original_file..."
    fi

    # Extract or use explicit title
    local title
    if [ -n "$explicit_title" ]; then
        title="$explicit_title"
    else
        title=$(extract_title "$input_file")
        # If stdin and title is temp filename fallback, use base_filename instead
        if [ "$stdin_mode" = true ] && [[ "$title" =~ ^tmp\. ]]; then
            # Convert filename to readable title
            title=$(echo "$base_filename" | sed 's/\.md$//' | sed 's/-/ /g' | \
                    awk '{for(i=1;i<=NF;i++)sub(/./,toupper(substr($i,1,1)),$i)}1')
        fi
    fi
    info_human "Extracted title: $title"

    # Get current timestamp
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Read original content
    local content=$(cat "$input_file")

    # Hash the canonicalized content for consistent verification
    local content_hash=$(hash_content_canonical "$input_file")
    local hash_short="${content_hash:0:6}-${content_hash: -6}"

    info_human "Content hash: sha256:$content_hash"
    info_human "Short hash: $hash_short"

    # Create date-stamped subdirectory
    local date_dir="$POSTS_DIR/$(date +%Y%m%d)"
    mkdir -p "$date_dir"

    # Note: base_filename is already set above in the stdin/file mode section

    # Create frontmatter (without signature first)
    local frontmatter_template="---
title: $title
published: $timestamp
generator: polis-cli/$VERSION
current-version: sha256:$content_hash
version-history:
  - sha256:$content_hash ($timestamp)
---"

    # Create temporary file with frontmatter + content (for signing)
    local temp_file=$(mktemp)
    echo "$frontmatter_template" > "$temp_file"
    echo "" >> "$temp_file"
    cat "$input_file" >> "$temp_file"

    # Sign the file
    info_human "Signing file..."
    local signature=$(sign_file "$temp_file")

    # Create final frontmatter with signature
    local frontmatter="---
title: $title
published: $timestamp
generator: polis-cli/$VERSION
current-version: sha256:$content_hash
version-history:
  - sha256:$content_hash ($timestamp)
signature: $signature
---"

    # Write canonical file
    local canonical_path="$date_dir/$base_filename"
    echo "$frontmatter" > "$canonical_path"
    echo "" >> "$canonical_path"
    cat "$input_file" >> "$canonical_path"
    success_human "Created canonical file: $canonical_path"

    # Initialize version history with full content
    initialize_version_history "$canonical_path" "$content_hash" "$timestamp" "$content"
    local versions_file=$(get_versions_file_path "$canonical_path")
    success_human "Created versions file: $versions_file"

    # Clean up temp file
    rm -f "$temp_file"

    # Handle cleanup based on mode
    if [ "$stdin_mode" = true ]; then
        # Cleanup handled by trap - just inform user
        success_human "Published content from stdin to $canonical_path"
    else
        # Remove original file if it's not already in the posts directory
        # (we've now moved it into posts with frontmatter added)
        local canonical_abs=$(realpath "$canonical_path" 2>/dev/null || readlink -f "$canonical_path" 2>/dev/null || echo "$canonical_path")
        if [ "$input_file" != "$canonical_abs" ]; then
            rm -f "$original_file"
            success_human "Moved original file into posts/"
        fi
    fi

    # Append to public.jsonl index
    append_to_index "$canonical_path" "post"

    # Regenerate manifest.json
    generate_manifest true

    # Output results
    if [ "$JSON_MODE" = true ]; then
        # Build canonical URL
        local canonical_url=""
        if [ -n "$POLIS_BASE_URL" ]; then
            canonical_url="$POLIS_BASE_URL/$canonical_path"
        fi

        local result=$(jq -n \
            --arg path "$canonical_path" \
            --arg hash "sha256:$content_hash" \
            --arg timestamp "$timestamp" \
            --arg sig "$signature" \
            --arg url "$canonical_url" \
            '{
                file_path: $path,
                content_hash: $hash,
                timestamp: $timestamp,
                signature: $sig,
                canonical_url: $url
            }')
        json_success "post" "$result"
    else
        success "Publishing complete!"
        echo ""
        info "Canonical: $canonical_path"
        info "Versions:  $versions_file"
    fi
}

# ============================================================================
# SNIPPET COMMAND
# ============================================================================

# Command: polis snippet <file>
# Publishes a snippet (signed composable content fragment)
cmd_snippet() {
    # Parse command-specific flags first
    local explicit_filename=""
    local explicit_title=""
    local positional_args=()

    while [[ $# -gt 0 ]]; do
        case $1 in
            --filename)
                explicit_filename="$2"
                shift 2
                ;;
            --title)
                explicit_title="$2"
                shift 2
                ;;
            *)
                positional_args+=("$1")
                shift
                ;;
        esac
    done

    # Restore positional arguments
    set -- "${positional_args[@]}"

    local input_file="$1"

    if [ -z "$input_file" ]; then
        json_error "snippet" "INVALID_INPUT" "Usage: polis snippet <filename>\n       polis snippet - [--filename <name>] [--title <title>]"
    fi

    if [ ! -f "$KEYS_DIR/id_ed25519" ]; then
        json_error "snippet" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check for stdin mode
    local stdin_mode=false
    local temp_stdin=""

    if [ "$input_file" = "-" ]; then
        stdin_mode=true

        # Verify stdin is not a terminal (has actual content)
        if [ -t 0 ]; then
            json_error "snippet" "INVALID_INPUT" "No stdin content. Use: echo 'content' | polis snippet -"
        fi

        # Create temp file and read stdin
        temp_stdin=$(mktemp)
        cat > "$temp_stdin"

        # Verify content
        if [ ! -s "$temp_stdin" ]; then
            rm -f "$temp_stdin"
            json_error "snippet" "INVALID_INPUT" "Stdin content is empty"
        fi

        # Point input_file to temp file
        input_file="$temp_stdin"

        info_human "Reading content from stdin..."
    else
        # Regular file mode - check file exists
        if [ ! -f "$input_file" ]; then
            json_error "snippet" "FILE_NOT_FOUND" "File not found: $input_file"
        fi
    fi

    # Ensure temp file cleanup on exit or error
    cleanup_stdin() {
        if [ -n "$temp_stdin" ] && [ -f "$temp_stdin" ]; then
            rm -f "$temp_stdin"
        fi
    }
    trap cleanup_stdin EXIT ERR

    # Check if file already has frontmatter (already published)
    if [ "$stdin_mode" = false ] && has_frontmatter "$input_file"; then
        json_error "snippet" "INVALID_STATE" "File already published (has frontmatter). Use 'polis republish' to update it."
    fi

    # Store original file path for cleanup later
    local original_file="$input_file"

    # Determine target path within snippets directory
    local target_path
    if [ -n "$explicit_filename" ]; then
        # Explicit filename takes precedence
        target_path="$SNIPPETS_DIR/$explicit_filename"
        # Ensure .md or .html extension
        if [[ ! "$target_path" =~ \.(md|html)$ ]]; then
            target_path="${target_path}.md"
        fi
    elif [ "$stdin_mode" = true ]; then
        # Generate synthetic filename for stdin
        local timestamp_filename=$(date +%Y%m%d-%H%M%S)
        target_path="$SNIPPETS_DIR/stdin-${timestamp_filename}.md"
    else
        # Check if input is already under snippets directory
        if [[ "$input_file" == "$SNIPPETS_DIR/"* ]]; then
            target_path="$input_file"
        else
            # Use basename under snippets/
            target_path="$SNIPPETS_DIR/$(basename "$input_file")"
        fi
    fi

    # Create parent directories if needed
    mkdir -p "$(dirname "$target_path")"

    if [ "$stdin_mode" = true ]; then
        info_human "Publishing snippet from stdin as $target_path..."
    else
        info_human "Publishing snippet $original_file..."
    fi

    # Extract or use explicit title
    local title
    if [ -n "$explicit_title" ]; then
        title="$explicit_title"
    else
        title=$(extract_title "$input_file")
        # If stdin and title is temp filename fallback, use target_path instead
        if [ "$stdin_mode" = true ] && [[ "$title" =~ ^tmp\. ]]; then
            title=$(basename "$target_path" | sed 's/\.[^.]*$//' | sed 's/-/ /g' | \
                    awk '{for(i=1;i<=NF;i++)sub(/./,toupper(substr($i,1,1)),$i)}1')
        fi
    fi
    info_human "Extracted title: $title"

    # Get current timestamp
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Read original content
    local content=$(cat "$input_file")

    # Hash the canonicalized content for consistent verification
    local content_hash=$(hash_content_canonical "$input_file")
    local hash_short="${content_hash:0:6}-${content_hash: -6}"

    info_human "Content hash: sha256:$content_hash"
    info_human "Short hash: $hash_short"

    # Create frontmatter (without signature first)
    local frontmatter_template="---
title: $title
published: $timestamp
generator: polis-cli/$VERSION
current-version: sha256:$content_hash
version-history:
  - sha256:$content_hash ($timestamp)
---"

    # Create temporary file with frontmatter + content (for signing)
    local temp_file=$(mktemp)
    echo "$frontmatter_template" > "$temp_file"
    echo "" >> "$temp_file"
    cat "$input_file" >> "$temp_file"

    # Sign the file
    info_human "Signing file..."
    local signature=$(sign_file "$temp_file")

    # Create final frontmatter with signature
    local frontmatter="---
title: $title
published: $timestamp
generator: polis-cli/$VERSION
current-version: sha256:$content_hash
version-history:
  - sha256:$content_hash ($timestamp)
signature: $signature
---"

    # Write canonical file
    echo "$frontmatter" > "$target_path"
    echo "" >> "$target_path"
    cat "$input_file" >> "$target_path"
    success_human "Created snippet: $target_path"

    # Initialize version history with full content
    initialize_version_history "$target_path" "$content_hash" "$timestamp" "$content"
    local versions_file=$(get_versions_file_path "$target_path")
    success_human "Created versions file: $versions_file"

    # Clean up temp file
    rm -f "$temp_file"

    # Handle cleanup based on mode
    if [ "$stdin_mode" = true ]; then
        success_human "Published snippet from stdin to $target_path"
    else
        # Remove original file if it's not already in the snippets directory
        local target_abs=$(realpath "$target_path" 2>/dev/null || readlink -f "$target_path" 2>/dev/null || echo "$target_path")
        local input_abs=$(realpath "$input_file" 2>/dev/null || readlink -f "$input_file" 2>/dev/null || echo "$input_file")
        if [ "$input_abs" != "$target_abs" ]; then
            rm -f "$original_file"
            success_human "Moved original file into snippets/"
        fi
    fi

    # Append to snippets.jsonl index
    append_to_index "$target_path" "snippet"

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg path "$target_path" \
            --arg hash "sha256:$content_hash" \
            --arg timestamp "$timestamp" \
            --arg sig "$signature" \
            '{
                file_path: $path,
                content_hash: $hash,
                timestamp: $timestamp,
                signature: $sig
            }')
        json_success "snippet" "$result"
    else
        success "Snippet published!"
        echo ""
        info "Canonical: $target_path"
        info "Versions:  $versions_file"
    fi
}

# ============================================================================
# DOMAIN MIGRATION COMMAND
# ============================================================================

# Detect current domain from existing published files
detect_current_domain() {
    # Check posts first
    local file
    for file in $(find "$POSTS_DIR" -name "*.md" -type f 2>/dev/null | head -5); do
        local url=$(extract_frontmatter_field "$file" "canonical_url")
        if [ -n "$url" ]; then
            extract_domain_from_url "$url"
            return 0
        fi
    done

    # Check comments
    for file in $(find "$COMMENTS_DIR" -name "*.md" -type f 2>/dev/null | head -5); do
        local url=$(extract_frontmatter_field "$file" "canonical_url")
        if [ -n "$url" ]; then
            extract_domain_from_url "$url"
            return 0
        fi
    done

    # Fallback: check .well-known/polis endpoints
    if [ -f "$WELL_KNOWN_DIR/polis" ]; then
        local posts_url=$(jq -r '.endpoints.posts // empty' "$WELL_KNOWN_DIR/polis" 2>/dev/null)
        if [ -n "$posts_url" ]; then
            extract_domain_from_url "$posts_url"
            return 0
        fi
    fi

    return 1
}

# Migrate a single post file (update canonical_url, re-sign)
migrate_post_file() {
    local file="$1"
    local old_domain="$2"
    local new_domain="$3"

    # Read current canonical_url
    local current_url=$(extract_frontmatter_field "$file" "canonical_url")
    if [ -z "$current_url" ]; then
        return 1  # No canonical_url, skip
    fi

    # Check if this file is from the old domain
    local file_domain=$(extract_domain_from_url "$current_url")
    if [ "$file_domain" != "$old_domain" ]; then
        return 1  # Not from old domain, skip
    fi

    # Replace domain in canonical_url
    local new_url="${current_url/https:\/\/$old_domain\//https:\/\/$new_domain\/}"

    # Update frontmatter using sed (portable)
    sed -i.bak "s|canonical_url: $current_url|canonical_url: $new_url|" "$file"
    rm -f "$file.bak"

    # Re-sign the file
    local temp_file=$(mktemp)
    cat "$file" > "$temp_file"
    local signature=$(sign_file "$temp_file")
    rm -f "$temp_file" "$temp_file.sig"

    # Update signature in file
    sed -i.bak "s|^signature: .*|signature: $signature|" "$file"
    rm -f "$file.bak"

    return 0
}

# Migrate a single comment file (update URLs, re-sign)
migrate_comment_file() {
    local file="$1"
    local old_domain="$2"
    local new_domain="$3"

    # Read current canonical_url
    local canonical_url=$(extract_frontmatter_field "$file" "canonical_url")
    if [ -z "$canonical_url" ]; then
        return 1  # No canonical_url, skip
    fi

    # Check if this file is from the old domain
    local file_domain=$(extract_domain_from_url "$canonical_url")
    if [ "$file_domain" != "$old_domain" ]; then
        return 1  # Not from old domain, skip
    fi

    # Replace domain in canonical_url (always)
    local new_canonical="${canonical_url/https:\/\/$old_domain\//https:\/\/$new_domain\/}"
    sed -i.bak "s|canonical_url: $canonical_url|canonical_url: $new_canonical|" "$file"
    rm -f "$file.bak"

    # Extract in-reply-to section
    local in_reply_to=$(extract_in_reply_to "$file")
    local reply_url=$(echo "$in_reply_to" | grep 'url:' | sed 's/.*url: *//')
    local root_post=$(echo "$in_reply_to" | grep 'root-post:' | sed 's/.*root-post: *//')

    # Update in_reply_to URL only if pointing to own domain
    if [ -n "$reply_url" ]; then
        local reply_domain=$(extract_domain_from_url "$reply_url")
        if [ "$reply_domain" = "$old_domain" ]; then
            local new_reply="${reply_url/https:\/\/$old_domain\//https:\/\/$new_domain\/}"
            sed -i.bak "s|url: $reply_url|url: $new_reply|" "$file"
            rm -f "$file.bak"
        fi
    fi

    # Update root_post URL only if pointing to own domain
    if [ -n "$root_post" ]; then
        local root_domain=$(extract_domain_from_url "$root_post")
        if [ "$root_domain" = "$old_domain" ]; then
            local new_root="${root_post/https:\/\/$old_domain\//https:\/\/$new_domain\/}"
            sed -i.bak "s|root-post: $root_post|root-post: $new_root|" "$file"
            rm -f "$file.bak"
        fi
    fi

    # CRITICAL: Re-sign the comment with new canonical payload
    # Comments include comment_url in signed payload, so this is mandatory
    resign_comment_for_migration "$file" "$new_domain"

    return 0
}

# Re-sign a comment file after migration (creates new signature for beseech payload)
resign_comment_for_migration() {
    local file="$1"
    local new_domain="$2"

    # Extract all fields needed for signing
    local canonical_url=$(extract_frontmatter_field "$file" "canonical_url")
    local version=$(extract_frontmatter_field "$file" "current-version")
    local published=$(extract_frontmatter_field "$file" "published")

    # Extract in-reply-to section
    local in_reply_to=$(extract_in_reply_to "$file")
    local reply_url=$(echo "$in_reply_to" | grep 'url:' | sed 's/.*url: *//')
    local reply_version=$(echo "$in_reply_to" | grep 'version:' | sed 's/.*version: *//')
    local root_post=$(echo "$in_reply_to" | grep 'root-post:' | sed 's/.*root-post: *//')

    # Get author from .well-known/polis
    local author=""
    if [ -f "$WELL_KNOWN_DIR/polis" ]; then
        author=$(jq -r '.author.email // empty' "$WELL_KNOWN_DIR/polis" 2>/dev/null)
    fi

    if [ -z "$author" ]; then
        warn_human "Could not determine author email for re-signing"
        return 1
    fi

    # Build canonical JSON payload (matches _internal_beseech_from_file format exactly)
    local canonical_payload
    if [ -n "$reply_version" ]; then
        canonical_payload=$(printf '{"comment_url":"%s","comment_version":"%s","in_reply_to":"%s","in_reply_to_version":"%s","root_post":"%s","author":"%s","timestamp":"%s"}' \
            "$canonical_url" "$version" "$reply_url" "$reply_version" "$root_post" "$author" "$published")
    else
        canonical_payload=$(printf '{"comment_url":"%s","comment_version":"%s","in_reply_to":"%s","root_post":"%s","author":"%s","timestamp":"%s"}' \
            "$canonical_url" "$version" "$reply_url" "$root_post" "$author" "$published")
    fi

    # Sign the payload
    local temp_file=$(mktemp)
    echo -n "$canonical_payload" > "$temp_file"

    local keyfile="$KEYS_DIR/id_ed25519"
    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1

    local new_signature=$(grep -v '^-----' "$temp_file.sig" | tr -d '\n')
    rm -f "$temp_file" "$temp_file.sig"

    # Update signature in file
    sed -i.bak "s|^signature: .*|signature: $new_signature|" "$file"
    rm -f "$file.bak"

    return 0
}

# Update blessed-comments.json with new domain
update_blessed_comments_urls() {
    local old_domain="$1"
    local new_domain="$2"
    local blessed_file="$BLESSED_COMMENTS"

    if [ ! -f "$blessed_file" ]; then
        return 0
    fi

    # Use jq to update post URLs that match old domain
    local temp_file="${blessed_file}.tmp"

    jq --arg old "https://$old_domain/" \
       --arg new "https://$new_domain/" \
       '
       .comments |= map(
         if .post | startswith($old) then
           .post |= sub($old; $new)
         else . end
       )
       ' "$blessed_file" > "$temp_file"

    mv "$temp_file" "$blessed_file"
}

# Update .well-known/polis endpoints with new domain
update_wellknown_endpoints() {
    local old_domain="$1"
    local new_domain="$2"
    local wellknown_file="$WELL_KNOWN_DIR/polis"

    if [ ! -f "$wellknown_file" ]; then
        return 0
    fi

    # Update endpoints URLs
    local temp_file="${wellknown_file}.tmp"

    jq --arg old "https://$old_domain/" \
       --arg new "https://$new_domain/" \
       '
       .endpoints.posts |= (if . then sub($old; $new) else . end) |
       .endpoints.blessed_comments |= (if . then sub($old; $new) else . end)
       ' "$wellknown_file" > "$temp_file"

    mv "$temp_file" "$wellknown_file"
}

# Main migrate command
cmd_migrate() {
    local new_domain="$1"

    # Validate input
    if [ -z "$new_domain" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "migrate" "INVALID_INPUT" "Usage: polis migrate <new-domain>"
        else
            error "Usage: polis migrate <new-domain>"
        fi
    fi

    # Validate new domain format (must not include protocol)
    if [[ "$new_domain" =~ ^https?:// ]]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "migrate" "INVALID_INPUT" "Domain should not include protocol (use: example.com not https://example.com)"
        else
            error "Domain should not include protocol (use: example.com not https://example.com)"
        fi
    fi

    # Auto-detect old domain from existing files
    local old_domain=$(detect_current_domain)
    if [ -z "$old_domain" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "migrate" "NO_CONTENT" "No published content found. Nothing to migrate."
        else
            error "No published content found. Nothing to migrate."
        fi
    fi

    # Check if domains are the same
    if [ "$old_domain" = "$new_domain" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "migrate" "INVALID_INPUT" "New domain is the same as current domain: $old_domain"
        else
            error "New domain is the same as current domain: $old_domain"
        fi
    fi

    # Confirm with user (unless --json mode)
    if [ "$JSON_MODE" = false ]; then
        info "Detected current domain: $old_domain"
        info "New domain: $new_domain"
        echo ""
        read -p "Continue with migration? (y/N) " confirm
        if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
            error "Migration cancelled"
        fi
    fi

    # Track statistics
    local posts_updated=0
    local comments_updated=0
    local errors=()

    # Update posts
    info_human "Updating posts..."
    local file
    for file in $(find "$POSTS_DIR" -name "*.md" -type f 2>/dev/null); do
        if migrate_post_file "$file" "$old_domain" "$new_domain"; then
            ((posts_updated++))
        fi
    done

    # Update comments
    info_human "Updating comments..."
    for file in $(find "$COMMENTS_DIR" -name "*.md" -type f 2>/dev/null); do
        if migrate_comment_file "$file" "$old_domain" "$new_domain"; then
            ((comments_updated++))
        fi
    done

    # Update blessed-comments.json
    info_human "Updating blessed-comments.json..."
    update_blessed_comments_urls "$old_domain" "$new_domain"

    # Update .well-known/polis
    info_human "Updating .well-known/polis..."
    update_wellknown_endpoints "$old_domain" "$new_domain"

    # Rebuild public.jsonl index
    info_human "Rebuilding public.jsonl index..."
    cmd_rebuild > /dev/null 2>&1

    # Update discovery service database (if endpoint is configured)
    local db_updated=false
    local db_rows=0
    if [ -n "$DISCOVERY_SERVICE_URL" ] && [ -n "$DISCOVERY_SERVICE_KEY" ]; then
        info_human "Updating discovery service database..."

        # Create payload
        local migrate_payload=$(jq -n \
            --arg old "$old_domain" \
            --arg new "$new_domain" \
            '{old_domain: $old, new_domain: $new}')

        # Sign the payload
        local temp_file=$(mktemp)
        echo -n "$migrate_payload" > "$temp_file"
        local keyfile="$KEYS_DIR/id_ed25519"
        ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1
        local signature=$(cat "$temp_file.sig")
        rm -f "$temp_file" "$temp_file.sig"

        # Create final payload with signature
        local final_payload=$(jq -n \
            --arg old "$old_domain" \
            --arg new "$new_domain" \
            --arg sig "$signature" \
            '{old_domain: $old, new_domain: $new, signature: $sig}')

        # Call edge function
        local migrate_endpoint="${DISCOVERY_SERVICE_URL}/migrations"
        local response=$(curl -s -w "\n%{http_code}" \
            --location --request POST "$migrate_endpoint" \
            --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
            --header 'Content-Type: application/json' \
            --data "$final_payload" 2>&1)

        local http_code=$(echo "$response" | tail -n 1)
        local response_body=$(echo "$response" | sed '$d')

        if [ "$http_code" = "200" ]; then
            db_updated=true
            db_rows=$(echo "$response_body" | jq -r '.rows_updated // 0' 2>/dev/null || echo "0")
            success_human "Database migration complete ($db_rows rows updated)"
        else
            warn_human "Database migration returned HTTP $http_code. You may need to re-beseech comments."
        fi
    else
        info_human "Discovery service not configured - skipping database migration"
    fi

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg old "$old_domain" \
            --arg new "$new_domain" \
            --argjson posts "$posts_updated" \
            --argjson comments "$comments_updated" \
            --argjson db_updated "$db_updated" \
            --argjson db_rows "$db_rows" \
            '{
                old_domain: $old,
                new_domain: $new,
                posts_updated: $posts,
                comments_updated: $comments,
                database_updated: $db_updated,
                database_rows: $db_rows
            }')
        json_success "migrate" "$result"
    else
        echo ""
        success "Migration complete!"
        echo ""
        info "Old domain: $old_domain"
        info "New domain: $new_domain"
        info "Posts updated: $posts_updated"
        info "Comments updated: $comments_updated"
        if [ "$db_updated" = true ]; then
            info "Database rows updated: $db_rows"
        fi
        echo ""
        info "Next steps:"
        info "1. Deploy to new domain"
        info "2. Set up redirect from old domain (recommended)"
        info "3. Update POLIS_BASE_URL environment variable"
    fi
}

# ============================================================================
# SITE REGISTRATION COMMANDS
# ============================================================================

cmd_register() {
    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "register" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
        else
            error "Polis not initialized. Run 'polis init' first."
        fi
    fi

    # Check POLIS_BASE_URL is set
    if [ -z "$POLIS_BASE_URL" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "register" "INVALID_INPUT" "POLIS_BASE_URL not set. Export it first."
        else
            error "POLIS_BASE_URL not set. Set it with: export POLIS_BASE_URL=https://yourdomain.com"
        fi
    fi

    # Check discovery service is configured
    if [ -z "$DISCOVERY_SERVICE_URL" ] || [ -z "$DISCOVERY_SERVICE_KEY" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "register" "INVALID_STATE" "Discovery service not configured. Set DISCOVERY_SERVICE_URL and DISCOVERY_SERVICE_KEY."
        else
            error "Discovery service not configured. Set DISCOVERY_SERVICE_URL and DISCOVERY_SERVICE_KEY."
        fi
    fi

    # Extract domain from POLIS_BASE_URL
    local domain=$(extract_domain_from_url "$POLIS_BASE_URL")
    if [ -z "$domain" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "register" "INVALID_INPUT" "Could not extract domain from POLIS_BASE_URL"
        else
            error "Could not extract domain from POLIS_BASE_URL"
        fi
    fi

    info_human "Checking registration status for $domain..."

    # Check if already registered via sites-check endpoint
    local check_endpoint="${DISCOVERY_SERVICE_URL}/sites-check?domain=$domain"
    local check_response=$(curl -s -w "\n%{http_code}" \
        --location --request GET "$check_endpoint" \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        --header 'Content-Type: application/json' 2>&1)

    local check_http_code=$(echo "$check_response" | tail -n 1)
    local check_body=$(echo "$check_response" | sed '$d')

    if [ "$check_http_code" != "200" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "register" "SERVICE_ERROR" "Failed to check registration status: HTTP $check_http_code"
        else
            error "Failed to check registration status: HTTP $check_http_code"
        fi
    fi

    local is_registered=$(echo "$check_body" | jq -r '.is_registered // false' 2>/dev/null)

    if [ "$is_registered" = "true" ]; then
        # Site is already registered - show status and verify attestation
        local registry_url=$(echo "$check_body" | jq -r '.registry_url // "unknown"')
        local registered_at=$(echo "$check_body" | jq -r '.registered_at // "unknown"')
        local registration_version=$(echo "$check_body" | jq -r '.registration_version // 1')
        local service_attestation=$(echo "$check_body" | jq -r '.service_attestation // ""')

        # Verify attestation if available
        local attestation_verified="unknown"
        if [ -n "$service_attestation" ] && [ "$service_attestation" != "null" ]; then
            # Fetch discovery service public key
            local pubkey_endpoint="${DISCOVERY_SERVICE_URL}/sites-public-key"
            local pubkey_response=$(curl -s -w "\n%{http_code}" \
                --location --request GET "$pubkey_endpoint" \
                --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" 2>&1)

            local pubkey_http_code=$(echo "$pubkey_response" | tail -n 1)
            local pubkey_body=$(echo "$pubkey_response" | sed '$d')

            if [ "$pubkey_http_code" = "200" ]; then
                local ds_public_key=$(echo "$pubkey_body" | jq -r '.public_key // ""')
                if [ -n "$ds_public_key" ]; then
                    # Reconstruct canonical payload (must be compact JSON)
                    local canonical_payload=$(jq -cn \
                        --argjson ver "$registration_version" \
                        --arg act "register" \
                        --arg dom "$domain" \
                        '{version: $ver, action: $act, domain: $dom}')

                    # Verify attestation signature
                    local temp_payload=$(mktemp)
                    local temp_sig=$(mktemp)
                    local temp_allowed_signers=$(mktemp)
                    echo -n "$canonical_payload" > "$temp_payload"
                    echo "$service_attestation" > "$temp_sig"
                    # allowed_signers file format: <principal> <key-type> <key>
                    echo "discovery-service $ds_public_key" > "$temp_allowed_signers"

                    if ssh-keygen -Y verify -f "$temp_allowed_signers" -I discovery-service -n file -s "$temp_sig" < "$temp_payload" 2>/dev/null; then
                        attestation_verified="valid"
                    else
                        attestation_verified="failed"
                    fi
                    rm -f "$temp_payload" "$temp_sig" "$temp_allowed_signers"
                fi
            fi
        fi

        if [ "$JSON_MODE" = true ]; then
            local result=$(jq -n \
                --arg domain "$domain" \
                --arg registry_url "$registry_url" \
                --arg registered_at "$registered_at" \
                --argjson version "$registration_version" \
                --arg attestation_verified "$attestation_verified" \
                '{
                    already_registered: true,
                    domain: $domain,
                    registry_url: $registry_url,
                    registered_at: $registered_at,
                    registration_version: $version,
                    attestation_verified: $attestation_verified
                }')
            json_success "register" "$result"
        else
            echo ""
            success "Site already registered."
            echo ""
            info "Registration Details:"
            info "  Domain: $domain"
            info "  Registry: $registry_url"
            info "  Registered: $registered_at"
            echo ""
            if [ "$attestation_verified" = "valid" ]; then
                success "Attestation Verification: Valid"
                info "  (Server signature verified against locally reconstructed payload)"
            elif [ "$attestation_verified" = "failed" ]; then
                warn "Attestation Verification: FAILED"
                warn "  Warning: Server attestation does not match expected payload."
            else
                info "Attestation Verification: Not checked"
            fi
        fi
        exit 0
    fi

    # Not registered - proceed with registration
    info_human "Registering $domain with discovery service..."

    # Build canonical payload (must be compact JSON to match server-side verification)
    local register_payload=$(jq -cn \
        --argjson ver 1 \
        --arg act "register" \
        --arg dom "$domain" \
        '{version: $ver, action: $act, domain: $dom}')

    # Sign the payload
    local temp_file=$(mktemp)
    echo -n "$register_payload" > "$temp_file"
    local keyfile="$KEYS_DIR/id_ed25519"

    if [ ! -f "$keyfile" ]; then
        rm -f "$temp_file"
        if [ "$JSON_MODE" = true ]; then
            json_error "register" "INVALID_STATE" "Private key not found. Run 'polis init' first."
        else
            error "Private key not found. Run 'polis init' first."
        fi
    fi

    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1
    local signature=$(cat "$temp_file.sig")
    rm -f "$temp_file" "$temp_file.sig"

    # Get optional metadata from .well-known/polis
    local email=$(jq -r '.email // empty' "$WELL_KNOWN_DIR/polis" 2>/dev/null || true)
    local author_name=$(jq -r '.author_name // empty' "$WELL_KNOWN_DIR/polis" 2>/dev/null || true)

    # Create final payload with signature and optional fields
    local final_payload=$(jq -n \
        --argjson ver 1 \
        --arg act "register" \
        --arg dom "$domain" \
        --arg sig "$signature" \
        --arg email "$email" \
        --arg author "$author_name" \
        '{version: $ver, action: $act, domain: $dom, owner_signature: $sig} +
         (if $email != "" then {email: $email} else {} end) +
         (if $author != "" then {author_name: $author} else {} end)')

    # Call sites-register endpoint
    local register_endpoint="${DISCOVERY_SERVICE_URL}/sites-register"
    local response=$(curl -s -w "\n%{http_code}" \
        --location --request POST "$register_endpoint" \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        --header 'Content-Type: application/json' \
        --data "$final_payload" 2>&1)

    local http_code=$(echo "$response" | tail -n 1)
    local response_body=$(echo "$response" | sed '$d')

    if [ "$http_code" = "201" ] || [ "$http_code" = "200" ]; then
        # Success
        local registry_url=$(echo "$response_body" | jq -r '.registry_url // "unknown"')
        local registered_at=$(echo "$response_body" | jq -r '.registered_at // "now"')
        local service_attestation=$(echo "$response_body" | jq -r '.service_attestation // ""')

        if [ "$JSON_MODE" = true ]; then
            local result=$(jq -n \
                --arg domain "$domain" \
                --arg registry_url "$registry_url" \
                --arg registered_at "$registered_at" \
                --arg service_attestation "$service_attestation" \
                '{
                    success: true,
                    domain: $domain,
                    registry_url: $registry_url,
                    registered_at: $registered_at,
                    service_attestation: $service_attestation
                }')
            json_success "register" "$result"
        else
            echo ""
            success "Site registered successfully!"
            echo ""
            info "Registration Details:"
            info "  Domain: $domain"
            info "  Registry: $registry_url"
            info "  Registered: $registered_at"
            echo ""
            info "Your site is now listed in the public directory."
            info "Other authors can now discover your content and engage with your posts."
        fi
    else
        # Error
        local error_msg=$(echo "$response_body" | jq -r '.error // "Unknown error"' 2>/dev/null || echo "Unknown error")
        local error_code=$(echo "$response_body" | jq -r '.code // "UNKNOWN"' 2>/dev/null || echo "UNKNOWN")

        if [ "$JSON_MODE" = true ]; then
            json_error "register" "$error_code" "$error_msg"
        else
            error "Registration failed: $error_msg (HTTP $http_code)"
        fi
    fi
}

cmd_unregister() {
    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
        else
            error "Polis not initialized. Run 'polis init' first."
        fi
    fi

    # Check POLIS_BASE_URL is set
    if [ -z "$POLIS_BASE_URL" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "INVALID_INPUT" "POLIS_BASE_URL not set. Export it first."
        else
            error "POLIS_BASE_URL not set. Set it with: export POLIS_BASE_URL=https://yourdomain.com"
        fi
    fi

    # Check discovery service is configured
    if [ -z "$DISCOVERY_SERVICE_URL" ] || [ -z "$DISCOVERY_SERVICE_KEY" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "INVALID_STATE" "Discovery service not configured. Set DISCOVERY_SERVICE_URL and DISCOVERY_SERVICE_KEY."
        else
            error "Discovery service not configured. Set DISCOVERY_SERVICE_URL and DISCOVERY_SERVICE_KEY."
        fi
    fi

    # Extract domain from POLIS_BASE_URL
    local domain=$(extract_domain_from_url "$POLIS_BASE_URL")
    if [ -z "$domain" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "INVALID_INPUT" "Could not extract domain from POLIS_BASE_URL"
        else
            error "Could not extract domain from POLIS_BASE_URL"
        fi
    fi

    # Check --force flag
    local force=false
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --force|-f)
                force=true
                shift
                ;;
            *)
                shift
                ;;
        esac
    done

    # Check if registered
    info_human "Checking registration status for $domain..."

    local check_endpoint="${DISCOVERY_SERVICE_URL}/sites-check?domain=$domain"
    local check_response=$(curl -s -w "\n%{http_code}" \
        --location --request GET "$check_endpoint" \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        --header 'Content-Type: application/json' 2>&1)

    local check_http_code=$(echo "$check_response" | tail -n 1)
    local check_body=$(echo "$check_response" | sed '$d')

    if [ "$check_http_code" != "200" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "SERVICE_ERROR" "Failed to check registration status: HTTP $check_http_code"
        else
            error "Failed to check registration status: HTTP $check_http_code"
        fi
    fi

    local is_registered=$(echo "$check_body" | jq -r '.is_registered // false' 2>/dev/null)

    if [ "$is_registered" != "true" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "NOT_REGISTERED" "Site $domain is not registered"
        else
            error "Site $domain is not registered"
        fi
    fi

    # Show warning and confirm (unless --force or --json mode)
    if [ "$JSON_MODE" = false ] && [ "$force" = false ]; then
        echo ""
        warn "WARNING: Unregistering will remove your site from the public directory."
        echo ""
        echo "This means:"
        echo "  - Your site will no longer be publicly listed or discoverable"
        echo "  - Other authors cannot find or interact with your content through the network"
        echo "  - You can re-register anytime to rejoin the community"
        echo ""
        read -p "Are you sure you want to unregister $domain? (type 'yes' to confirm) " confirm
        if [ "$confirm" != "yes" ]; then
            echo ""
            info "Unregistration cancelled."
            exit 0
        fi
    fi

    info_human "Unregistering $domain..."

    # Build canonical payload (must be compact JSON to match server-side verification)
    local unregister_payload=$(jq -cn \
        --argjson ver 1 \
        --arg act "unregister" \
        --arg dom "$domain" \
        '{version: $ver, action: $act, domain: $dom}')

    # Sign the payload
    local temp_file=$(mktemp)
    echo -n "$unregister_payload" > "$temp_file"
    local keyfile="$KEYS_DIR/id_ed25519"

    if [ ! -f "$keyfile" ]; then
        rm -f "$temp_file"
        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "INVALID_STATE" "Private key not found. Run 'polis init' first."
        else
            error "Private key not found. Run 'polis init' first."
        fi
    fi

    ssh-keygen -Y sign -f "$keyfile" -n file "$temp_file" > /dev/null 2>&1
    local signature=$(cat "$temp_file.sig")
    rm -f "$temp_file" "$temp_file.sig"

    # Create final payload with signature
    local final_payload=$(jq -n \
        --argjson ver 1 \
        --arg act "unregister" \
        --arg dom "$domain" \
        --arg sig "$signature" \
        '{version: $ver, action: $act, domain: $dom, owner_signature: $sig}')

    # Call sites-unregister endpoint
    local unregister_endpoint="${DISCOVERY_SERVICE_URL}/sites-unregister"
    local response=$(curl -s -w "\n%{http_code}" \
        --location --request POST "$unregister_endpoint" \
        --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
        --header 'Content-Type: application/json' \
        --data "$final_payload" 2>&1)

    local http_code=$(echo "$response" | tail -n 1)
    local response_body=$(echo "$response" | sed '$d')

    if [ "$http_code" = "200" ]; then
        # Success
        if [ "$JSON_MODE" = true ]; then
            local result=$(jq -n \
                --arg domain "$domain" \
                '{
                    success: true,
                    domain: $domain,
                    message: "Site unregistered successfully"
                }')
            json_success "unregister" "$result"
        else
            echo ""
            success "Site unregistered successfully."
            echo ""
            info "Your site $domain has been removed from the discovery service."
            info "You can re-register at any time with: polis register"
        fi
    else
        # Error
        local error_msg=$(echo "$response_body" | jq -r '.error // "Unknown error"' 2>/dev/null || echo "Unknown error")
        local error_code=$(echo "$response_body" | jq -r '.code // "UNKNOWN"' 2>/dev/null || echo "UNKNOWN")

        if [ "$JSON_MODE" = true ]; then
            json_error "unregister" "$error_code" "$error_msg"
        else
            error "Unregistration failed: $error_msg (HTTP $http_code)"
        fi
    fi
}

# ============================================================================
# NOTIFICATIONS COMMAND
# ============================================================================

# List notifications (default subcommand)
cmd_notifications_list() {
    local show_all=false
    local type_filter=""

    # Parse options
    while [ $# -gt 0 ]; do
        case "$1" in
            --all|-a)
                show_all=true
                shift
                ;;
            --type|-t)
                type_filter="$2"
                shift 2
                ;;
            *)
                shift
                ;;
        esac
    done

    # Initialize notifications manifest if needed
    init_notifications_manifest

    # Get local notifications
    local notif_count=$(get_notification_count)
    local notifications="[]"

    if [ "$notif_count" -gt 0 ]; then
        # Convert JSONL to JSON array
        notifications=$(get_notifications | jq -s '.')

        # Apply type filter if specified
        if [ -n "$type_filter" ]; then
            local types_array=$(echo "$type_filter" | tr ',' '\n' | jq -R . | jq -s .)
            notifications=$(echo "$notifications" | jq --argjson types "$types_array" \
                '[.[] | select(.type as $t | $types | index($t) != null)]')
            notif_count=$(echo "$notifications" | jq 'length')
        fi
    fi

    # Also get pending blessings and migrations (legacy notifications)
    local pending_blessings="[]"
    local pending_count=0
    local migrations="[]"
    local migration_count=0

    if [ -n "$DISCOVERY_SERVICE_URL" ] && [ -n "$DISCOVERY_SERVICE_KEY" ]; then
        local domain=$(extract_domain_from_url "$POLIS_BASE_URL")
        if [ -n "$domain" ]; then
            local blessing_response=$(curl -s --max-time 30 \
                --header "Authorization: Bearer $DISCOVERY_SERVICE_KEY" \
                "${POLIS_BLESSING_REQUESTS_ENDPOINT}?in_reply_to_domain=${domain}" 2>/dev/null)

            if [ -n "$blessing_response" ]; then
                pending_count=$(echo "$blessing_response" | jq -r '.count // 0' 2>/dev/null)
                if [ "$pending_count" -gt 0 ]; then
                    pending_blessings=$(echo "$blessing_response" | jq -c '.requests // []' 2>/dev/null)
                fi
            fi
        fi

        local relevant_domains=$(collect_relevant_domains | paste -sd ',' -)
        if [ -n "$relevant_domains" ]; then
            local migration_response=$(query_domain_migrations "$relevant_domains")
            migration_count=$(echo "$migration_response" | jq -r '.count // 0' 2>/dev/null)
            if [ "$migration_count" -gt 0 ]; then
                migrations=$(echo "$migration_response" | jq -c '.migrations // []' 2>/dev/null)
            fi
        fi
    fi

    # Output
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --argjson notifications "$notifications" \
            --argjson blessings "$pending_blessings" \
            --argjson migrations "$migrations" \
            '{
                notifications: $notifications,
                pending_blessings: $blessings,
                domain_migrations: $migrations
            }')
        json_success "notifications" "$result"
    else
        local total_count=$((notif_count + pending_count + migration_count))

        if [ "$total_count" -eq 0 ]; then
            info "No notifications"
            return
        fi

        echo ""

        # Display local notifications
        if [ "$notif_count" -gt 0 ]; then
            info "=== Notifications ($notif_count) ==="
            echo "$notifications" | jq -r '.[] | "  [\(.type)] \(.payload | tostring | .[0:60])... (\(.created_at[:10]))"' 2>/dev/null
            echo ""
        fi

        # Display pending blessings
        if [ "$pending_count" -gt 0 ]; then
            info "=== Pending Blessing Requests ($pending_count) ==="
            echo "$pending_blessings" | jq -r '.[] | "  #\(.id): \(.author) on \(.in_reply_to | split("/")[-1])"' 2>/dev/null
            echo ""
            info "Run 'polis blessing requests' for details, or 'polis blessing grant <id>' to approve."
            echo ""
        fi

        # Display migrations
        if [ "$migration_count" -gt 0 ]; then
            info "=== Domain Migrations ($migration_count) ==="
            echo "$migrations" | jq -r '.[] | "  \(.old_domain) -> \(.new_domain) (\(.migrated_at[:10]))"' 2>/dev/null
            echo ""
            info "Run 'polis migrations apply' to update local references."
        fi
    fi
}

# Read/dismiss notifications
cmd_notifications_read() {
    local id="$1"
    local all=false

    if [ "$id" = "--all" ] || [ "$id" = "-a" ]; then
        all=true
    fi

    if [ "$all" = true ]; then
        remove_all_notifications
        if [ "$JSON_MODE" = true ]; then
            json_success "notifications-read" '{"removed": "all"}'
        else
            success "All notifications marked as read"
        fi
    elif [ -n "$id" ]; then
        remove_notification "$id"
        if [ "$JSON_MODE" = true ]; then
            json_success "notifications-read" "{\"removed\": \"$id\"}"
        else
            success "Notification $id marked as read"
        fi
    else
        if [ "$JSON_MODE" = true ]; then
            json_error "notifications-read" "INVALID_INPUT" "Notification ID required. Use --all to mark all as read."
        else
            error "Notification ID required. Use --all to mark all as read."
        fi
    fi
}

# Dismiss notifications (same as read, but named differently for UX)
cmd_notifications_dismiss() {
    local id="$1"
    shift || true

    # Check for --older-than option
    while [ $# -gt 0 ]; do
        case "$1" in
            --older-than)
                local days="${2%d}"  # Remove 'd' suffix if present
                shift 2
                local removed=$(remove_old_notifications "$days")
                if [ "$JSON_MODE" = true ]; then
                    json_success "notifications-dismiss" "{\"removed\": $removed, \"older_than_days\": $days}"
                else
                    success "Dismissed $removed notifications older than $days days"
                fi
                return
                ;;
            *)
                shift
                ;;
        esac
    done

    # If no --older-than, behave like read
    cmd_notifications_read "$id"
}

# Sync notifications from discovery service (placeholder for Phase 2+)
cmd_notifications_sync() {
    local reset=false

    while [ $# -gt 0 ]; do
        case "$1" in
            --reset)
                reset=true
                shift
                ;;
            *)
                shift
                ;;
        esac
    done

    # Initialize manifest
    init_notifications_manifest

    if [ "$reset" = true ]; then
        update_notifications_watermark "1970-01-01T00:00:00Z"
        info_human "Reset watermark. Next sync will fetch all notifications."
    fi

    local last_ts=$(get_notifications_watermark)
    local new_ts=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Check for version updates (Phase 1)
    local version_notification_added=false
    if [ -n "$DISCOVERY_SERVICE_URL" ]; then
        local version_endpoint="${DISCOVERY_SERVICE_URL}/polis-version"
        local version_response=$(curl -s --max-time 10 \
            "${version_endpoint}?current=${VERSION}" 2>/dev/null)

        if [ -n "$version_response" ]; then
            local latest=$(echo "$version_response" | jq -r '.latest // empty')
            local upgrade=$(echo "$version_response" | jq -r '.upgrade_available // false')

            if [ "$upgrade" = "true" ] && [ -n "$latest" ]; then
                # Check if we should add this notification
                if is_notification_type_enabled "version_available"; then
                    local payload=$(echo "$version_response" | jq -c \
                        --arg current "$VERSION" \
                        '{current_version: $current, latest_version: .latest, released_at: .released_at, download_url: .download_url}')
                    add_notification "version_available" "discovery" "$payload" "version_available:$latest" > /dev/null
                    version_notification_added=true
                fi
            fi
        fi
    fi

    # Update watermark
    update_notifications_watermark "$new_ts"

    # Output
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg last "$last_ts" \
            --arg new "$new_ts" \
            --argjson version_added "$version_notification_added" \
            '{
                synced_from: $last,
                synced_to: $new,
                version_notification_added: $version_added
            }')
        json_success "notifications-sync" "$result"
    else
        success "Synced notifications"
        if [ "$version_notification_added" = true ]; then
            info "New version available notification added"
        fi
    fi
}

# Configure notification preferences
cmd_notifications_config() {
    local action=""
    local value=""

    while [ $# -gt 0 ]; do
        case "$1" in
            --poll-interval)
                action="poll_interval"
                value="$2"
                shift 2
                ;;
            --enable)
                action="enable"
                value="$2"
                shift 2
                ;;
            --disable)
                action="disable"
                value="$2"
                shift 2
                ;;
            --mute)
                action="mute"
                value="$2"
                shift 2
                ;;
            --unmute)
                action="unmute"
                value="$2"
                shift 2
                ;;
            *)
                shift
                ;;
        esac
    done

    # Initialize manifest
    init_notifications_manifest

    if [ -z "$action" ]; then
        # Show current config
        local prefs=$(get_notification_preferences)
        if [ "$JSON_MODE" = true ]; then
            json_success "notifications-config" "$prefs"
        else
            echo ""
            info "Notification Preferences:"
            echo "$prefs" | jq -r '
                "  Poll interval: \(.poll_interval_minutes // 60) minutes",
                "  Enabled types: \(.enabled_types // [] | join(", "))",
                "  Muted domains: \(.muted_domains // [] | if length == 0 then "(none)" else join(", ") end)"
            '
            echo ""
        fi
        return
    fi

    local manifest="$NOTIFICATIONS_MANIFEST"
    local temp_file="${manifest}.tmp"

    case "$action" in
        poll_interval)
            # Parse interval (e.g., "30m" -> 30)
            local minutes="${value%m}"
            if [ "$minutes" -lt 15 ]; then
                minutes=15
                info_human "Minimum poll interval is 15 minutes. Setting to 15."
            fi
            jq --argjson mins "$minutes" '.preferences.poll_interval_minutes = $mins' "$manifest" > "$temp_file"
            mv "$temp_file" "$manifest"
            success_human "Poll interval set to $minutes minutes"
            ;;
        enable)
            jq --arg t "$value" '.preferences.enabled_types |= (. + [$t] | unique)' "$manifest" > "$temp_file"
            mv "$temp_file" "$manifest"
            success_human "Enabled notification type: $value"
            ;;
        disable)
            jq --arg t "$value" '.preferences.enabled_types |= (. - [$t])' "$manifest" > "$temp_file"
            mv "$temp_file" "$manifest"
            success_human "Disabled notification type: $value"
            ;;
        mute)
            jq --arg d "$value" '.preferences.muted_domains |= (. + [$d] | unique)' "$manifest" > "$temp_file"
            mv "$temp_file" "$manifest"
            success_human "Muted domain: $value"
            ;;
        unmute)
            jq --arg d "$value" '.preferences.muted_domains |= (. - [$d])' "$manifest" > "$temp_file"
            mv "$temp_file" "$manifest"
            success_human "Unmuted domain: $value"
            ;;
    esac

    if [ "$JSON_MODE" = true ]; then
        local prefs=$(get_notification_preferences)
        json_success "notifications-config" "$prefs"
    fi
}

# Main notifications command dispatcher
cmd_notifications() {
    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "notifications" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    local subcommand="${1:-}"

    case "$subcommand" in
        read)
            shift
            cmd_notifications_read "$@"
            ;;
        dismiss)
            shift
            cmd_notifications_dismiss "$@"
            ;;
        sync)
            shift
            cmd_notifications_sync "$@"
            ;;
        config)
            shift
            cmd_notifications_config "$@"
            ;;
        list|"")
            shift 2>/dev/null || true
            cmd_notifications_list "$@"
            ;;
        *)
            # Treat unknown as list with options
            cmd_notifications_list "$@"
            ;;
    esac
}

# ============================================================================
# CLONE COMMAND
# ============================================================================

# Full clone: download all content from remote polis site
clone_full() {
    local server_url="$1"
    local target_dir="$2"

    # Create target directory
    mkdir -p "$target_dir"

    # Fetch and save .well-known/polis
    info_human "Fetching author metadata..."
    local wellknown_content=$(fetch_remote_content "${server_url}/.well-known/polis")
    if [ -z "$wellknown_content" ]; then
        json_error "clone" "FETCH_ERROR" "Failed to fetch .well-known/polis from $server_url"
    fi
    mkdir -p "$target_dir/.well-known"
    echo "$wellknown_content" > "$target_dir/.well-known/polis"

    # Get config paths from .well-known/polis
    local public_index_path=$(echo "$wellknown_content" | jq -r '.config.files.public_index // "metadata/public.jsonl"')
    local blessed_comments_path=$(echo "$wellknown_content" | jq -r '.config.files.blessed_comments // "metadata/blessed-comments.json"')
    local following_path=$(echo "$wellknown_content" | jq -r '.config.files.following // "metadata/following.json"')

    # Fetch public.jsonl manifest
    info_human "Fetching content manifest..."
    local manifest_content=$(fetch_remote_content "${server_url}/${public_index_path}")

    if [ -z "$manifest_content" ]; then
        json_error "clone" "FETCH_ERROR" "Failed to fetch manifest from $server_url/$public_index_path"
    fi

    mkdir -p "$target_dir/metadata"
    echo "$manifest_content" > "$target_dir/${public_index_path}"

    # Track statistics
    local posts_downloaded=0
    local comments_downloaded=0
    local versions_downloaded=0
    local html_downloaded=0
    local errors=0
    local state_entries="[]"

    # Process each entry in manifest (JSONL format)
    info_human "Downloading content files..."
    while IFS= read -r entry; do
        [ -z "$entry" ] && continue

        local entry_type=$(echo "$entry" | jq -r '.type // "post"')
        local entry_path=$(echo "$entry" | jq -r '.path // empty')
        local entry_version=$(echo "$entry" | jq -r '.current_version // empty')

        if [ -z "$entry_path" ]; then
            continue
        fi

        # Download content file
        if clone_single_file "$server_url" "$target_dir" "$entry_path"; then
            if [ "$entry_type" = "post" ]; then
                posts_downloaded=$((posts_downloaded + 1))
            else
                comments_downloaded=$((comments_downloaded + 1))
            fi

            # Track state entry
            state_entries=$(echo "$state_entries" | jq --arg path "$entry_path" --arg version "$entry_version" \
                '. + [{path: $path, version: $version}]')

            # Download version history (optional, don't fail if missing)
            local versions_path=$(get_versions_path_for_clone "$entry_path")
            if clone_single_file "$server_url" "$target_dir" "$versions_path" 2>/dev/null; then
                versions_downloaded=$((versions_downloaded + 1))
            fi

            # Try to download HTML version (optional)
            local html_path="${entry_path%.md}.html"
            if clone_single_file "$server_url" "$target_dir" "$html_path" 2>/dev/null; then
                html_downloaded=$((html_downloaded + 1))
            fi
        else
            errors=$((errors + 1))
            warn_human "Failed to download: $entry_path"
        fi
    done <<< "$manifest_content"

    # Fetch following.json (optional)
    local following_content=$(fetch_remote_content "${server_url}/${following_path}")
    if [ -n "$following_content" ] && [ "$following_content" != "null" ]; then
        echo "$following_content" > "$target_dir/${following_path}"
    fi

    # Fetch blessed-comments.json
    info_human "Fetching blessed comments..."
    local blessed_content=$(fetch_remote_content "${server_url}/${blessed_comments_path}")
    local blessed_comments_downloaded=0
    local blessed_urls="[]"

    if [ -n "$blessed_content" ] && [ "$blessed_content" != "null" ]; then
        echo "$blessed_content" > "$target_dir/${blessed_comments_path}"

        # Download blessed comments from other authors
        blessed_comments_downloaded=$(clone_blessed_comments "$target_dir" "$blessed_content")

        # Get cached URLs for state
        if [ -f "$target_dir/.blessed-urls-temp.json" ]; then
            blessed_urls=$(cat "$target_dir/.blessed-urls-temp.json")
            rm -f "$target_dir/.blessed-urls-temp.json"
        fi
    fi

    # Write state file
    write_clone_state "$target_dir" "$server_url" "$state_entries" "$blessed_urls"

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg mode "full" \
            --arg server "$server_url" \
            --arg target "$target_dir" \
            --argjson posts "$posts_downloaded" \
            --argjson comments "$comments_downloaded" \
            --argjson versions "$versions_downloaded" \
            --argjson html "$html_downloaded" \
            --argjson blessed "$blessed_comments_downloaded" \
            --argjson errors "$errors" \
            '{
                mode: $mode,
                server_url: $server,
                target_dir: $target,
                posts_downloaded: $posts,
                comments_downloaded: $comments,
                versions_downloaded: $versions,
                html_downloaded: $html,
                blessed_comments_cached: $blessed,
                errors: $errors
            }')
        json_success "clone" "$result"
    else
        success "Clone complete!"
        info "  Posts downloaded: $posts_downloaded"
        info "  Comments downloaded: $comments_downloaded"
        info "  Version histories: $versions_downloaded"
        info "  HTML files: $html_downloaded"
        info "  Blessed comments cached: $blessed_comments_downloaded"
        [ "$errors" -gt 0 ] && warn "  Errors: $errors"
        info "  Target directory: $target_dir"
    fi
}

# Incremental clone: only download new/changed content
clone_diff() {
    local server_url="$1"
    local target_dir="$2"

    # Load existing state
    local state_file="$target_dir/.polis-clone-state.json"
    if [ ! -f "$state_file" ]; then
        warn_human "No state file found, falling back to full clone"
        clone_full "$server_url" "$target_dir"
        return
    fi

    local old_state=$(cat "$state_file")

    # Fetch current manifest
    info_human "Fetching current manifest..."
    local wellknown_content=$(fetch_remote_content "${server_url}/.well-known/polis")
    if [ -z "$wellknown_content" ]; then
        json_error "clone" "FETCH_ERROR" "Failed to fetch .well-known/polis from $server_url"
    fi

    local public_index_path=$(echo "$wellknown_content" | jq -r '.config.files.public_index // "metadata/public.jsonl"')
    local blessed_comments_path=$(echo "$wellknown_content" | jq -r '.config.files.blessed_comments // "metadata/blessed-comments.json"')

    local manifest_content=$(fetch_remote_content "${server_url}/${public_index_path}")
    if [ -z "$manifest_content" ]; then
        json_error "clone" "FETCH_ERROR" "Failed to fetch manifest from $server_url/$public_index_path"
    fi

    # Track statistics
    local new_files=0
    local updated_files=0
    local unchanged_files=0
    local versions_downloaded=0
    local html_downloaded=0
    local errors=0
    local state_entries="[]"

    # Process each entry
    info_human "Checking for changes..."
    while IFS= read -r entry; do
        [ -z "$entry" ] && continue

        local entry_path=$(echo "$entry" | jq -r '.path // empty')
        local entry_version=$(echo "$entry" | jq -r '.current_version // empty')
        local entry_type=$(echo "$entry" | jq -r '.type // "post"')

        [ -z "$entry_path" ] && continue

        # Check if file exists in old state
        local old_version=$(echo "$old_state" | jq -r --arg path "$entry_path" \
            '.entries[] | select(.path == $path) | .version // empty')

        local should_download=false
        local is_new=false

        if [ -z "$old_version" ]; then
            # New file
            should_download=true
            is_new=true
        elif [ "$old_version" != "$entry_version" ]; then
            # Version changed - verify with local hash if file exists
            if [ -f "$target_dir/$entry_path" ]; then
                local local_hash=$(hash_content_canonical "$target_dir/$entry_path")
                local remote_hash="${entry_version#sha256:}"

                if [ "$local_hash" != "$remote_hash" ]; then
                    should_download=true
                fi
            else
                should_download=true
                is_new=true
            fi
        fi

        if [ "$should_download" = true ]; then
            if clone_single_file "$server_url" "$target_dir" "$entry_path"; then
                if [ "$is_new" = true ]; then
                    new_files=$((new_files + 1))
                else
                    updated_files=$((updated_files + 1))
                fi

                # Download version history and HTML
                local versions_path=$(get_versions_path_for_clone "$entry_path")
                if clone_single_file "$server_url" "$target_dir" "$versions_path" 2>/dev/null; then
                    versions_downloaded=$((versions_downloaded + 1))
                fi

                local html_path="${entry_path%.md}.html"
                if clone_single_file "$server_url" "$target_dir" "$html_path" 2>/dev/null; then
                    html_downloaded=$((html_downloaded + 1))
                fi
            else
                errors=$((errors + 1))
            fi
        else
            unchanged_files=$((unchanged_files + 1))
        fi

        # Track state entry
        state_entries=$(echo "$state_entries" | jq --arg path "$entry_path" --arg version "$entry_version" \
            '. + [{path: $path, version: $version}]')
    done <<< "$manifest_content"

    # Update metadata files
    mkdir -p "$target_dir/.well-known" "$target_dir/metadata"
    echo "$wellknown_content" > "$target_dir/.well-known/polis"
    echo "$manifest_content" > "$target_dir/${public_index_path}"

    # Update blessed comments
    info_human "Syncing blessed comments..."
    local blessed_content=$(fetch_remote_content "${server_url}/${blessed_comments_path}")
    local blessed_updated=0
    local blessed_urls="[]"

    if [ -n "$blessed_content" ] && [ "$blessed_content" != "null" ]; then
        echo "$blessed_content" > "$target_dir/${blessed_comments_path}"

        # Get previously cached URLs
        local old_cached=$(echo "$old_state" | jq -r '.blessed_comments_cached // []')

        # Check each blessed comment
        local cache_dir="$target_dir/.blessed-comments-cache"
        mkdir -p "$cache_dir"
        local cached_urls=()

        while IFS= read -r comment_entry; do
            [ -z "$comment_entry" ] && continue

            local comment_url=$(echo "$comment_entry" | jq -r '.url // empty')
            local comment_version=$(echo "$comment_entry" | jq -r '.version // empty')

            [ -z "$comment_url" ] && continue

            # Check if already cached
            local is_cached=$(echo "$old_cached" | jq -r --arg url "$comment_url" \
                'if . | type == "array" then (. | index($url) != null) else false end')

            if [ "$is_cached" != "true" ]; then
                # New comment, download it
                local comment_content=$(fetch_remote_content "$comment_url")
                if [ -n "$comment_content" ]; then
                    local url_hash=$(echo -n "$comment_url" | sha256sum | cut -c1-16)
                    echo "$comment_content" > "$cache_dir/${url_hash}.md"
                    jq -nc --arg url "$comment_url" --arg version "$comment_version" \
                        --arg cached_at "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
                        '{url: $url, version: $version, cached_at: $cached_at}' \
                        > "$cache_dir/${url_hash}.json"
                    blessed_updated=$((blessed_updated + 1))
                fi
            fi
            cached_urls+=("$comment_url")
        done < <(echo "$blessed_content" | jq -c '.comments[].blessed[]' 2>/dev/null)

        blessed_urls=$(printf '%s\n' "${cached_urls[@]}" | jq -R . | jq -s .)
    fi

    # Update state file
    write_clone_state "$target_dir" "$server_url" "$state_entries" "$blessed_urls"

    # Output results
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --arg mode "diff" \
            --arg server "$server_url" \
            --arg target "$target_dir" \
            --argjson new "$new_files" \
            --argjson updated "$updated_files" \
            --argjson unchanged "$unchanged_files" \
            --argjson versions "$versions_downloaded" \
            --argjson html "$html_downloaded" \
            --argjson blessed "$blessed_updated" \
            --argjson errors "$errors" \
            '{
                mode: $mode,
                server_url: $server,
                target_dir: $target,
                new_files: $new,
                updated_files: $updated,
                unchanged_files: $unchanged,
                versions_downloaded: $versions,
                html_downloaded: $html,
                blessed_comments_synced: $blessed,
                errors: $errors
            }')
        json_success "clone" "$result"
    else
        success "Incremental sync complete!"
        info "  New files: $new_files"
        info "  Updated files: $updated_files"
        info "  Unchanged: $unchanged_files"
        info "  Version histories: $versions_downloaded"
        info "  HTML files: $html_downloaded"
        info "  Blessed comments synced: $blessed_updated"
        [ "$errors" -gt 0 ] && warn "  Errors: $errors"
        info "  Target directory: $target_dir"
    fi
}

# Main clone command
cmd_clone() {
    # Parse arguments
    local server_url=""
    local target_dir=""
    local mode="auto"  # auto, full, diff
    local positional_args=()

    while [[ $# -gt 0 ]]; do
        case $1 in
            --full)
                mode="full"
                shift
                ;;
            --diff)
                mode="diff"
                shift
                ;;
            *)
                positional_args+=("$1")
                shift
                ;;
        esac
    done

    server_url="${positional_args[0]:-}"
    target_dir="${positional_args[1]:-}"

    # Validation
    if [ -z "$server_url" ]; then
        json_error "clone" "INVALID_INPUT" "Usage: polis clone <server-url> [target-dir] [--full|--diff]"
    fi

    # Normalize server URL (ensure https, remove trailing slash)
    server_url=$(normalize_server_url "$server_url")

    # Derive target directory from domain if not specified
    if [ -z "$target_dir" ]; then
        target_dir=$(extract_domain_for_clone "$server_url")
    fi

    # Determine mode: if state file exists, default to diff; otherwise full
    if [ "$mode" = "auto" ]; then
        if [ -f "$target_dir/.polis-clone-state.json" ]; then
            mode="diff"
            info_human "Previous clone found, using incremental mode (use --full to re-download all)"
        else
            mode="full"
        fi
    fi

    info_human "Cloning $server_url to $target_dir (mode: $mode)..."

    # Execute clone
    if [ "$mode" = "full" ]; then
        clone_full "$server_url" "$target_dir"
    else
        clone_diff "$server_url" "$target_dir"
    fi
}

# ============================================================================
# MIGRATIONS APPLY COMMAND
# ============================================================================

cmd_migrations_apply() {
    local specific_migration="$1"  # Optional: old_domain to apply

    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "migrations-apply" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Collect relevant domains and query migrations
    local relevant_domains=$(collect_relevant_domains | paste -sd ',' -)

    if [ -z "$relevant_domains" ]; then
        if [ "$JSON_MODE" = true ]; then
            json_success "migrations-apply" '{"migrations_applied":0,"files_updated":[],"message":"No relevant domains found in local files."}'
        else
            info "No relevant domains found in local files."
        fi
        return
    fi

    local migration_response=$(query_domain_migrations "$relevant_domains")
    local migration_count=$(echo "$migration_response" | jq -r '.count // 0' 2>/dev/null)

    if [ "$migration_count" -eq 0 ]; then
        if [ "$JSON_MODE" = true ]; then
            json_success "migrations-apply" '{"migrations_applied":0,"files_updated":[],"message":"No pending migrations found."}'
        else
            info "No pending migrations found."
        fi
        return
    fi

    local applied_count=0
    local all_updated_files=()

    # Process each migration
    while IFS= read -r migration; do
        [ -z "$migration" ] && continue

        local old_domain=$(echo "$migration" | jq -r '.old_domain')
        local new_domain=$(echo "$migration" | jq -r '.new_domain')
        local migrated_at=$(echo "$migration" | jq -r '.migrated_at')
        local stored_public_key=$(echo "$migration" | jq -r '.public_key')

        # Skip if specific migration requested and doesn't match
        if [ -n "$specific_migration" ] && [ "$old_domain" != "$specific_migration" ]; then
            continue
        fi

        if [ "$JSON_MODE" = false ]; then
            echo ""
            info "Migration: $old_domain -> $new_domain (${migrated_at:0:10})"
        fi

        # === KEY CONTINUITY CHECK ===
        # Verify the new domain has the same public key as stored in migration
        local current_public_key=$(fetch_domain_public_key "$new_domain")

        if [ -z "$current_public_key" ]; then
            if [ "$JSON_MODE" = false ]; then
                warn "  Cannot verify migration - new domain unreachable: $new_domain"
                read -p "  Apply anyway? (y/N) " confirm
                if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
                    info "  Skipped."
                    continue
                fi
            else
                # In JSON mode, skip unverifiable migrations
                continue
            fi
        elif [ "$current_public_key" != "$stored_public_key" ]; then
            if [ "$JSON_MODE" = false ]; then
                warn "  WARNING: Public key mismatch!"
                warn "  The new domain may be controlled by a different entity."
                warn "  Stored key:  ${stored_public_key:0:40}..."
                warn "  Current key: ${current_public_key:0:40}..."
                info "  Skipping for safety."
            fi
            continue
        else
            if [ "$JSON_MODE" = false ]; then
                success_human "  Key verification passed"
            fi
        fi

        # Find affected files
        local affected_files=()

        # Check following.json
        if [ -f "$FOLLOWING_INDEX" ]; then
            if jq -e ".following[] | select(.url | contains(\"$old_domain\"))" "$FOLLOWING_INDEX" > /dev/null 2>&1; then
                affected_files+=("$FOLLOWING_INDEX")
            fi
        fi

        # Check blessed-comments.json
        if [ -f "$BLESSED_COMMENTS" ]; then
            if jq -e ".posts[] | select(.url | contains(\"$old_domain\"))" "$BLESSED_COMMENTS" > /dev/null 2>&1; then
                affected_files+=("$BLESSED_COMMENTS")
            elif jq -e ".posts[].blessed[] | select(.url | contains(\"$old_domain\"))" "$BLESSED_COMMENTS" > /dev/null 2>&1; then
                affected_files+=("$BLESSED_COMMENTS")
            fi
        fi

        # Check comment frontmatter
        if [ -d "$COMMENTS_DIR" ]; then
            for file in $(find "$COMMENTS_DIR" -name "*.md" -type f 2>/dev/null); do
                if grep -q "https://$old_domain/" "$file" 2>/dev/null; then
                    affected_files+=("$file")
                fi
            done
        fi

        if [ ${#affected_files[@]} -eq 0 ]; then
            if [ "$JSON_MODE" = false ]; then
                info "  No local references to $old_domain found."
            fi
            continue
        fi

        # Display affected files (human mode)
        if [ "$JSON_MODE" = false ]; then
            info "  Affected files (${#affected_files[@]}):"
            for f in "${affected_files[@]}"; do
                echo "    - $f"
            done
            echo ""

            # Confirm
            read -p "  Apply this migration? (y/N) " confirm
            if [ "$confirm" != "y" ] && [ "$confirm" != "Y" ]; then
                info "  Skipped."
                continue
            fi
        fi

        # Apply updates
        local updated_count=0

        for file in "${affected_files[@]}"; do
            if [ "$file" = "$FOLLOWING_INDEX" ]; then
                update_domain_in_following "$old_domain" "$new_domain"
                ((updated_count++))
                all_updated_files+=("$file")
            elif [ "$file" = "$BLESSED_COMMENTS" ]; then
                update_domain_in_blessed_comments "$old_domain" "$new_domain"
                ((updated_count++))
                all_updated_files+=("$file")
            elif [[ "$file" == *.md ]]; then
                update_domain_in_comment_file "$file" "$old_domain" "$new_domain"
                ((updated_count++))
                all_updated_files+=("$file")
            fi
        done

        ((applied_count++))

        if [ "$JSON_MODE" = false ]; then
            success "  Applied: $updated_count file(s) updated."
        fi

    done < <(echo "$migration_response" | jq -c '.migrations[]' 2>/dev/null)

    # Final output
    if [ "$JSON_MODE" = true ]; then
        # Deduplicate files
        local unique_files=$(printf '%s\n' "${all_updated_files[@]}" | sort -u | jq -R . | jq -s .)
        local result=$(jq -n \
            --argjson applied "$applied_count" \
            --argjson files "$unique_files" \
            '{migrations_applied: $applied, files_updated: $files}')
        json_success "migrations-apply" "$result"
    else
        echo ""
        if [ "$applied_count" -gt 0 ]; then
            success "Applied $applied_count migration(s)."
        else
            info "No migrations applied."
        fi
    fi
}

# ============================================================================
# RENDER COMMAND - HTML THEMING
# ============================================================================

# Active theme name (set by load_theme or select_theme)
ACTIVE_THEME=""

# Template storage (associative array)
declare -A TEMPLATES

# Get list of available themes
get_available_themes() {
    local themes=()
    if [ -d "$THEMES_DIR" ]; then
        for theme_path in "$THEMES_DIR"/*; do
            if [ -d "$theme_path" ] && [ -f "$theme_path/index.html" ]; then
                themes+=("$(basename "$theme_path")")
            fi
        done
    fi
    printf '%s\n' "${themes[@]}"
}

# Select and save active theme (if not already set)
select_theme() {
    local available_themes
    available_themes=($(get_available_themes))

    if [ ${#available_themes[@]} -eq 0 ]; then
        json_error "render" "INVALID_STATE" "No themes found in $THEMES_DIR. Run 'polis init' to install default themes."
    fi

    # Check if active_theme is already set in manifest
    if [ -f "$MANIFEST" ]; then
        local saved_theme
        saved_theme=$(jq -r '.active_theme // empty' "$MANIFEST" 2>/dev/null)
        if [ -n "$saved_theme" ] && [ "$saved_theme" != "null" ]; then
            # Verify theme exists
            if [ -d "$THEMES_DIR/$saved_theme" ]; then
                ACTIVE_THEME="$saved_theme"
                return 0
            else
                json_error "render" "INVALID_STATE" "Active theme '$saved_theme' not found in $THEMES_DIR"
            fi
        fi
    fi

    # Randomly select a theme
    local random_index=$((RANDOM % ${#available_themes[@]}))
    ACTIVE_THEME="${available_themes[$random_index]}"

    # Save to manifest
    if [ -f "$MANIFEST" ]; then
        local tmp_manifest
        tmp_manifest=$(mktemp)
        if jq --arg theme "$ACTIVE_THEME" '. + {active_theme: $theme}' "$MANIFEST" > "$tmp_manifest" 2>/dev/null; then
            mv "$tmp_manifest" "$MANIFEST"
            info_human "Selected theme: $ACTIVE_THEME (saved to manifest)"
        else
            rm -f "$tmp_manifest"
            warn "Failed to save theme to manifest"
            info_human "Selected theme: $ACTIVE_THEME (not saved)"
        fi
    else
        warn "No manifest file found at $MANIFEST"
        info_human "Selected theme: $ACTIVE_THEME (not saved)"
    fi
}

# Load theme templates from .polis/themes/<name>/
load_theme() {
    local theme_name="$1"

    if [ -z "$theme_name" ]; then
        # Try to get from manifest
        if [ -f "$MANIFEST" ]; then
            theme_name=$(jq -r '.active_theme // empty' "$MANIFEST" 2>/dev/null)
        fi
    fi

    if [ -z "$theme_name" ] || [ "$theme_name" = "null" ]; then
        json_error "render" "INVALID_STATE" "No active theme set. This should not happen on first render."
    fi

    local theme_dir="$THEMES_DIR/$theme_name"

    if [ ! -d "$theme_dir" ]; then
        json_error "render" "INVALID_STATE" "Theme '$theme_name' not found in $THEMES_DIR"
    fi

    # Load required templates
    if [ -f "$theme_dir/post.html" ]; then
        TEMPLATES[post]=$(cat "$theme_dir/post.html")
    else
        json_error "render" "INVALID_STATE" "Theme '$theme_name' missing post.html"
    fi

    if [ -f "$theme_dir/comment.html" ]; then
        TEMPLATES[comment]=$(cat "$theme_dir/comment.html")
    else
        json_error "render" "INVALID_STATE" "Theme '$theme_name' missing comment.html"
    fi

    if [ -f "$theme_dir/comment-inline.html" ]; then
        TEMPLATES[comment_inline]=$(cat "$theme_dir/comment-inline.html")
    else
        # Fall back to blessed-comment snippet if comment-inline doesn't exist
        TEMPLATES[comment_inline]=""
    fi

    if [ -f "$theme_dir/index.html" ]; then
        TEMPLATES[index]=$(cat "$theme_dir/index.html")
    else
        json_error "render" "INVALID_STATE" "Theme '$theme_name' missing index.html"
    fi

    ACTIVE_THEME="$theme_name"

    # Copy theme CSS to styles.css
    local css_file="$theme_dir/$theme_name.css"
    if [ -f "$css_file" ]; then
        cp "$css_file" "styles.css"
        info_human "Copied $theme_name.css to styles.css"
    fi
}

# Format date for human display
format_date_human() {
    local iso_date="$1"
    # Convert ISO date to human-readable format
    if [[ "$OSTYPE" == "darwin"* ]]; then
        date -j -f "%Y-%m-%dT%H:%M:%SZ" "$iso_date" "+%B %d, %Y" 2>/dev/null || echo "$iso_date"
    else
        date -d "$iso_date" "+%B %d, %Y" 2>/dev/null || echo "$iso_date"
    fi
}

# Escape special characters for bash pattern replacement
# In ${var//pattern/replacement}, & and \ are special in the replacement string
escape_for_replacement() {
    local str="$1"
    # Escape backslashes first, then ampersands
    str="${str//\\/\\\\}"
    str="${str//&/\\&}"
    printf '%s' "$str"
}

# Substitute template variables
substitute_template() {
    local template="$1"
    local -n vars=$2  # nameref to associative array

    local result="$template"
    for key in "${!vars[@]}"; do
        local value="${vars[$key]}"
        # Escape special characters in value for sed
        value=$(printf '%s' "$value" | sed 's/[&/\]/\\&/g')
        result=$(echo "$result" | sed "s|{{${key}}}|${value}|g")
    done
    echo "$result"
}

# Extract body from a file (not content string)
extract_body_from_file() {
    local file="$1"
    awk '/^---$/{if(++count==2){skip=0; getline; print; next} skip=1; next} !skip' "$file"
}

# Render blessed comments for a post
# Returns HTML string via stdout; stdout is captured by caller
render_blessed_comments() {
    local post_url="$1"
    local blessed_html=""
    local count=0

    # Check if blessed-comments.json exists
    if [ ! -f "$BLESSED_COMMENTS" ]; then
        echo ""
        return
    fi

    # Get blessed comments for this post
    # Use -c for compact output (one JSON object per line)
    # Try both .md and .html extensions since blessed-comments.json might have either
    local comments_json
    local post_url_md="${post_url%.html}.md"
    local post_url_html="${post_url%.md}.html"
    comments_json=$(jq -c --arg url "$post_url" --arg url_md "$post_url_md" --arg url_html "$post_url_html" \
        '.comments[] | select(.post == $url or .post == $url_md or .post == $url_html) | .blessed[]' "$BLESSED_COMMENTS" 2>/dev/null)

    if [ -z "$comments_json" ]; then
        echo ""
        return
    fi

    # Process each blessed comment (one JSON object per line)
    while IFS= read -r comment_data; do
        [ -z "$comment_data" ] && continue

        local comment_url=$(echo "$comment_data" | jq -r '.url // empty')
        [ -z "$comment_url" ] && continue

        # Try to fetch/find the comment content
        local comment_content=""
        local comment_file=""

        # Check if it's a local comment (same domain)
        local base_url="${POLIS_BASE_URL%/}"  # Remove trailing slash
        if [[ "$comment_url" == "${base_url}"* ]]; then
            # Extract path from URL and find local file
            local url_path="${comment_url#${base_url}}"
            url_path="${url_path#/}"  # Remove leading slash(es)
            url_path="${url_path#/}"  # Handle double slash case
            if [ -f "$url_path" ]; then
                comment_file="$url_path"
                comment_content=$(cat "$comment_file")
            fi
        fi

        # If not found locally, try to fetch remotely
        if [ -z "$comment_content" ]; then
            comment_content=$(curl -sL "$comment_url" 2>/dev/null)
        fi

        # If we found content, render it
        if [ -n "$comment_content" ]; then
            local c_title=$(echo "$comment_content" | grep '^title:' | head -1 | sed 's/^title: *//')
            local c_published=$(echo "$comment_content" | grep '^published:' | head -1 | sed 's/^published: *//')
            local c_body=$(extract_body_from_content "$comment_content")
            # Strip leading blank lines
            c_body=$(echo "$c_body" | sed '/./,$!d')
            local c_html=$(echo "$c_body" | pandoc -f markdown -t html 2>/dev/null || echo "$c_body")

            # Get author info from URL
            local author_domain=$(echo "$comment_url" | sed 's|https\?://||' | cut -d'/' -f1)
            local author_name="$author_domain"

            # Try to get site_title from author's manifest.json
            if [[ "$comment_url" == "${base_url}"* ]]; then
                # Local comment - use our manifest
                if [ -f "$MANIFEST" ]; then
                    local local_title=$(jq -r '.site_title // empty' "$MANIFEST" 2>/dev/null)
                    [ -n "$local_title" ] && author_name="$local_title"
                fi
            else
                # Remote comment - try to fetch their manifest.json
                local remote_manifest=$(curl -sL "https://$author_domain/metadata/manifest.json" 2>/dev/null)
                if [ -n "$remote_manifest" ]; then
                    local remote_title=$(echo "$remote_manifest" | jq -r '.site_title // empty' 2>/dev/null)
                    [ -n "$remote_title" ] && author_name="$remote_title"
                fi
            fi

            declare -A comment_vars=(
                [author_name]="$author_name"
                [author_url]="https://$author_domain"
                [published]="$c_published"
                [published_human]="$(format_date_human "$c_published")"
                [content]="$c_html"
                [url]="$comment_url"
            )

            local comment_html="${TEMPLATES[comment_inline]}"
            for key in "${!comment_vars[@]}"; do
                local escaped_val=$(escape_for_replacement "${comment_vars[$key]}")
                comment_html="${comment_html//\{\{$key\}\}/$escaped_val}"
            done

            blessed_html+="$comment_html"
            ((++count))  # Pre-increment to avoid set -e exit when count=0
        fi
    done <<< "$comments_json"

    echo "$blessed_html"
}

# Load a snippet by path and render it
# Returns rendered HTML content
# Lookup order: theme snippets -> global snippets
load_snippet() {
    local snippet_path="$1"
    local context="$2"  # Optional JSON context for variable substitution

    # Try to find the snippet file
    # 1. First check theme snippets
    # 2. Then check global snippets
    local snippet_file=""
    local theme_snippets_dir="$THEMES_DIR/$ACTIVE_THEME/snippets"

    # Check theme snippets first
    if [ -n "$ACTIVE_THEME" ] && [ -d "$theme_snippets_dir" ]; then
        if [ -f "$theme_snippets_dir/$snippet_path.md" ]; then
            snippet_file="$theme_snippets_dir/$snippet_path.md"
        elif [ -f "$theme_snippets_dir/$snippet_path.html" ]; then
            snippet_file="$theme_snippets_dir/$snippet_path.html"
        elif [ -f "$theme_snippets_dir/$snippet_path" ]; then
            snippet_file="$theme_snippets_dir/$snippet_path"
        fi
    fi

    # Fall back to global snippets
    if [ -z "$snippet_file" ]; then
        if [ -f "$SNIPPETS_DIR/$snippet_path.md" ]; then
            snippet_file="$SNIPPETS_DIR/$snippet_path.md"
        elif [ -f "$SNIPPETS_DIR/$snippet_path.html" ]; then
            snippet_file="$SNIPPETS_DIR/$snippet_path.html"
        elif [ -f "$SNIPPETS_DIR/$snippet_path" ]; then
            snippet_file="$SNIPPETS_DIR/$snippet_path"
        fi
    fi

    local content=""

    if [ -n "$snippet_file" ] && [ -f "$snippet_file" ]; then
        # Extract content without frontmatter
        if has_frontmatter "$snippet_file"; then
            content=$(extract_content_without_frontmatter "$snippet_file")
        else
            content=$(cat "$snippet_file")
        fi

        # Process based on file extension
        if [[ "$snippet_file" == *.md ]]; then
            # Remove leading blank lines, render markdown to HTML
            content=$(echo "$content" | sed '/./,$!d')
            content=$(echo "$content" | pandoc -f markdown -t html 2>/dev/null)
        fi
        # .html files are used as-is
    fi
    # If no snippet found, content is empty

    echo "$content"
}

# Render all {{> path}} partial includes in content
# Recursively processes snippets that include other snippets
# Arguments:
#   $1 - Content containing {{> path}} patterns
#   $2 - Optional context JSON for variable substitution
#   $3 - Depth counter (for recursion limit)
render_partials() {
    local content="$1"
    local context="${2:-}"
    local depth="${3:-0}"

    # Prevent infinite recursion
    if [ "$depth" -gt 10 ]; then
        warn "Maximum snippet nesting depth (10) exceeded"
        echo "$content"
        return
    fi

    # Find all {{> path}} patterns and replace them
    # Pattern: {{> some/path}} or {{> some/path.html}}
    local result="$content"
    local pattern='\{\{>\s*([^}]+)\s*\}\}'

    # Use grep to find all matches, process each one
    while [[ "$result" =~ $pattern ]]; do
        local full_match="${BASH_REMATCH[0]}"
        local snippet_path="${BASH_REMATCH[1]}"

        # Trim whitespace from path
        snippet_path=$(echo "$snippet_path" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')

        # Load and render the snippet
        local snippet_content
        snippet_content=$(load_snippet "$snippet_path" "$context")

        # Recursively render any partials in the loaded snippet
        if [ -n "$snippet_content" ]; then
            snippet_content=$(render_partials "$snippet_content" "$context" $((depth + 1)))
        fi

        # Escape the snippet content for bash replacement
        local escaped_snippet
        escaped_snippet=$(escape_for_replacement "$snippet_content")

        # Replace the first occurrence of this partial
        result="${result//"$full_match"/$escaped_snippet}"
    done

    echo "$result"
}

# Render {{#section}}...{{/section}} loop blocks
# Supports: {{#posts}}, {{#comments}}, {{#blessed_comments}}
# Arguments:
#   $1 - Content containing section blocks
#   $2 - Optional context (e.g., post URL for blessed_comments)
render_sections() {
    local content="$1"
    local context="${2:-}"
    local result="$content"

    # Process {{#posts}}...{{/posts}} blocks
    if echo "$result" | grep -q '{{#posts}}'; then
        # Extract inner template using perl (handles multiline)
        local inner_template
        inner_template=$(echo "$result" | perl -0777 -ne 'print $1 if /\{\{#posts\}\}(.*?)\{\{\/posts\}\}/s')
        local posts_html=""

        if [ -f "$PUBLIC_INDEX" ]; then
            local sorted_posts
            sorted_posts=$(jq -s '[.[] | select(.type == "post" or .type == null)] | sort_by(.published) | reverse' "$PUBLIC_INDEX" 2>/dev/null)

            local num_posts
            num_posts=$(echo "$sorted_posts" | jq 'length')

            for ((i=0; i<num_posts; i++)); do
                local path=$(echo "$sorted_posts" | jq -r ".[$i].path // empty")
                local title=$(echo "$sorted_posts" | jq -r ".[$i].title // \"Untitled\"")
                local published=$(echo "$sorted_posts" | jq -r ".[$i].published // empty")

                [ -z "$path" ] && continue

                local url="${path%.md}.html"
                local published_human=$(format_date_human "$published")

                # Count blessed comments for this post
                local comment_count=0
                if [ -f "$BLESSED_COMMENTS" ]; then
                    local post_url_full="$POLIS_BASE_URL/$url"
                    comment_count=$(jq --arg url "$post_url_full" '[.[] | select(.post_url == $url)] | length' "$BLESSED_COMMENTS" 2>/dev/null || echo 0)
                fi

                # Render inner template with item variables
                local item_html="$inner_template"

                # Process any partials in the inner template
                item_html=$(render_partials "$item_html")

                # Substitute item-level variables
                item_html="${item_html//\{\{url\}\}/$(escape_for_replacement "$url")}"
                item_html="${item_html//\{\{title\}\}/$(escape_for_replacement "$title")}"
                item_html="${item_html//\{\{published\}\}/$(escape_for_replacement "$published")}"
                item_html="${item_html//\{\{published_human\}\}/$(escape_for_replacement "$published_human")}"
                item_html="${item_html//\{\{comment_count\}\}/$(escape_for_replacement "$comment_count")}"

                posts_html+="$item_html"
            done
        fi

        # Replace the entire section with rendered posts (use temp file to avoid escaping issues)
        local tmp_replacement=$(mktemp)
        echo -n "$posts_html" > "$tmp_replacement"
        result=$(echo "$result" | perl -0777 -pe '
            BEGIN { local $/; open my $fh, "<", "'"$tmp_replacement"'"; $repl = <$fh>; close $fh; }
            s/\{\{#posts\}\}.*?\{\{\/posts\}\}/$repl/s;
        ')
        rm -f "$tmp_replacement"
    fi

    # Process {{#comments}}...{{/comments}} blocks (outgoing comments)
    if echo "$result" | grep -q '{{#comments}}'; then
        # Extract inner template using perl (handles multiline)
        local inner_template
        inner_template=$(echo "$result" | perl -0777 -ne 'print $1 if /\{\{#comments\}\}(.*?)\{\{\/comments\}\}/s')
        local comments_html=""

        if [ -f "$PUBLIC_INDEX" ]; then
            local sorted_comments
            sorted_comments=$(jq -s '[.[] | select(.type == "comment")] | sort_by(.published) | reverse' "$PUBLIC_INDEX" 2>/dev/null)

            local num_comments
            num_comments=$(echo "$sorted_comments" | jq 'length')

            for ((i=0; i<num_comments; i++)); do
                local path=$(echo "$sorted_comments" | jq -r ".[$i].path // empty")
                local published=$(echo "$sorted_comments" | jq -r ".[$i].published // empty")
                local in_reply_to=$(echo "$sorted_comments" | jq -r ".[$i].in_reply_to // empty")

                [ -z "$path" ] && continue

                local url="${path%.md}.html"
                local published_human=$(format_date_human "$published")

                # Extract target author from in_reply_to URL
                local target_author=""
                if [ -n "$in_reply_to" ]; then
                    target_author=$(echo "$in_reply_to" | sed -E 's|https?://([^/]+).*|\1|')
                fi

                # Get preview from file body
                local preview=""
                if [ -f "$path" ]; then
                    preview=$(extract_body_from_file "$path" | head -c 100 | tr '\n' ' ')
                    [ ${#preview} -ge 100 ] && preview="${preview}..."
                fi

                # Render inner template with item variables
                local item_html="$inner_template"

                # Process any partials in the inner template
                item_html=$(render_partials "$item_html")

                # Substitute item-level variables
                item_html="${item_html//\{\{url\}\}/$(escape_for_replacement "$url")}"
                item_html="${item_html//\{\{published\}\}/$(escape_for_replacement "$published")}"
                item_html="${item_html//\{\{published_human\}\}/$(escape_for_replacement "$published_human")}"
                item_html="${item_html//\{\{target_author\}\}/$(escape_for_replacement "$target_author")}"
                item_html="${item_html//\{\{preview\}\}/$(escape_for_replacement "$preview")}"

                comments_html+="$item_html"
            done
        fi

        # Replace the entire section with rendered comments (use temp file to avoid escaping issues)
        local tmp_replacement=$(mktemp)
        echo -n "$comments_html" > "$tmp_replacement"
        result=$(echo "$result" | perl -0777 -pe '
            BEGIN { local $/; open my $fh, "<", "'"$tmp_replacement"'"; $repl = <$fh>; close $fh; }
            s/\{\{#comments\}\}.*?\{\{\/comments\}\}/$repl/s;
        ')
        rm -f "$tmp_replacement"
    fi

    # Process {{#blessed_comments}}...{{/blessed_comments}} blocks
    if echo "$result" | grep -q '{{#blessed_comments}}'; then
        # Extract inner template using perl (handles multiline)
        local inner_template
        inner_template=$(echo "$result" | perl -0777 -ne 'print $1 if /\{\{#blessed_comments\}\}(.*?)\{\{\/blessed_comments\}\}/s')
        local blessed_html=""
        local post_url="$context"  # The post URL we're rendering blessed comments for

        if [ -f "$BLESSED_COMMENTS" ] && [ -n "$post_url" ]; then
            local post_url_md="${post_url%.html}.md"
            local comments_json
            comments_json=$(jq -c --arg url "$post_url" --arg url_md "$post_url_md" \
                '.[] | select(.post_url == $url or .post_url == $url_md)' "$BLESSED_COMMENTS" 2>/dev/null)

            while IFS= read -r comment_entry; do
                [ -z "$comment_entry" ] && continue

                local comment_url=$(echo "$comment_entry" | jq -r '.comment_url // empty')
                local author_name=$(echo "$comment_entry" | jq -r '.author // "Anonymous"')
                local published=$(echo "$comment_entry" | jq -r '.published // empty')

                [ -z "$comment_url" ] && continue

                local published_human=$(format_date_human "$published")

                # Fetch comment content from the comment URL
                local comment_content=""
                # Try to extract body from local cache or fetch remotely
                # For now, use the body field if available, otherwise empty
                comment_content=$(echo "$comment_entry" | jq -r '.body // empty')

                # Render inner template with item variables
                local item_html="$inner_template"

                # Process any partials in the inner template
                item_html=$(render_partials "$item_html")

                # Substitute item-level variables
                item_html="${item_html//\{\{url\}\}/$(escape_for_replacement "$comment_url")}"
                item_html="${item_html//\{\{author_name\}\}/$(escape_for_replacement "$author_name")}"
                item_html="${item_html//\{\{published\}\}/$(escape_for_replacement "$published")}"
                item_html="${item_html//\{\{published_human\}\}/$(escape_for_replacement "$published_human")}"
                item_html="${item_html//\{\{content\}\}/$(escape_for_replacement "$comment_content")}"

                blessed_html+="$item_html"
            done <<< "$comments_json"
        fi

        # Replace the entire section with rendered blessed comments (use temp file to avoid escaping issues)
        local tmp_replacement=$(mktemp)
        echo -n "$blessed_html" > "$tmp_replacement"
        result=$(echo "$result" | perl -0777 -pe '
            BEGIN { local $/; open my $fh, "<", "'"$tmp_replacement"'"; $repl = <$fh>; close $fh; }
            s/\{\{#blessed_comments\}\}.*?\{\{\/blessed_comments\}\}/$repl/s;
        ')
        rm -f "$tmp_replacement"
    fi

    echo "$result"
}

# Render a single file to HTML
render_file() {
    local input_file="$1"
    local type="$2"  # "post" or "comment"
    local force="$3"

    local output_file="${input_file%.md}.html"

    # Skip if output is newer than input (unless force)
    if [ "$force" != "true" ] && [ -f "$output_file" ] && [ "$output_file" -nt "$input_file" ]; then
        # For posts, also check if blessed-comments.json is newer (new comments to render)
        if [ "$type" = "post" ] && [ -f "$BLESSED_COMMENTS" ] && [ "$BLESSED_COMMENTS" -nt "$output_file" ]; then
            : # Don't skip - blessed comments may have changed
        else
            return 1  # Skipped
        fi
    fi

    # Check pandoc availability
    if ! command -v pandoc &>/dev/null; then
        error "pandoc is required for rendering. Install with: apt install pandoc (Linux) or brew install pandoc (macOS)"
    fi

    # Read file content
    local content=$(cat "$input_file")

    # Extract frontmatter fields
    local title=$(echo "$content" | grep '^title:' | head -1 | sed 's/^title: *//')
    local published=$(echo "$content" | grep '^published:' | head -1 | sed 's/^published: *//')
    local version=$(echo "$content" | grep '^current-version:' | head -1 | sed 's/^current-version: *//')
    local signature=$(echo "$content" | grep '^signature:' | head -1 | sed 's/^signature: *//')
    local signature_short="${signature:0:20}..."

    # Extract body and convert to HTML
    local body=$(extract_body_from_content "$content")
    # Strip leading blank lines
    body=$(echo "$body" | sed '/./,$!d')
    local html_content=$(echo "$body" | pandoc -f markdown -t html 2>/dev/null || echo "$body")

    # Build canonical URL (normalize to avoid double slashes)
    local base_url="${POLIS_BASE_URL%/}"  # Remove trailing slash if present
    local url="${base_url}/${input_file}"
    info_human "  [url] Canonical URL: $url"

    # Get site info - prefer manifest.json, fallback to domain
    local site_title=""
    if [ -f "$MANIFEST" ]; then
        site_title=$(jq -r '.site_title // empty' "$MANIFEST" 2>/dev/null)
    fi
    if [ -z "$site_title" ]; then
        site_title="${POLIS_BASE_URL#https://}"
        site_title="${site_title#http://}"
    fi

    # Get author info from .well-known/polis
    local author_name="$site_title"
    if [ -f "$WELL_KNOWN_DIR/polis" ]; then
        local wk_name=$(jq -r '.name // empty' "$WELL_KNOWN_DIR/polis" 2>/dev/null)
        [ -n "$wk_name" ] && author_name="$wk_name"
    fi

    # Calculate relative path to root and CSS (count directory depth)
    local dir_path=$(dirname "$input_file")
    local root_path=""
    local css_path=""
    local home_path=""
    if [ "$dir_path" = "." ]; then
        root_path="./"
        css_path="styles.css"
        home_path="index.html"
    else
        # Count slashes to determine depth
        local depth=$(echo "$dir_path" | tr -cd '/' | wc -c)
        depth=$((depth + 1))  # Add 1 for the directory itself
        for ((i=0; i<depth; i++)); do
            root_path+="../"
        done
        css_path="${root_path}styles.css"
        home_path="${root_path}index.html"
    fi

    # Choose template
    local template="${TEMPLATES[$type]}"
    [ -z "$template" ] && template="${TEMPLATES[post]}"

    # Handle blessed comments for posts
    local blessed_comments=""
    local blessed_count=0
    if [ "$type" = "post" ]; then
        blessed_comments=$(render_blessed_comments "$url")
        # Count comments (rough count by counting </article> tags)
        # Note: || must be outside subshell to avoid capturing both grep output AND fallback
        blessed_count=$(echo "$blessed_comments" | grep -c '</article>' 2>/dev/null) || blessed_count=0
    fi

    # Comment-specific fields
    local in_reply_to_url=""
    local root_post_url=""
    if [ "$type" = "comment" ]; then
        in_reply_to_url=$(echo "$content" | grep -A1 '^in-reply-to:' | grep 'url:' | sed 's/.*url: *//')
        root_post_url=$(echo "$content" | grep -A2 '^in-reply-to:' | grep 'root-post:' | sed 's/.*root-post: *//')
    fi

    # Substitute all variables
    # Note: Values containing HTML must be escaped for bash pattern replacement
    local result="$template"

    # Process {{> partial}} includes first
    result=$(render_partials "$result")

    # Process {{#section}}...{{/section}} loops
    # Pass full post URL as context for blessed_comments lookup
    result=$(render_sections "$result" "$POLIS_BASE_URL/$url")

    result="${result//\{\{title\}\}/$(escape_for_replacement "$title")}"
    result="${result//\{\{content\}\}/$(escape_for_replacement "$html_content")}"
    result="${result//\{\{published\}\}/$(escape_for_replacement "$(format_date_human "$published")")}"
    result="${result//\{\{published_human\}\}/$(escape_for_replacement "$(format_date_human "$published")")}"
    result="${result//\{\{url\}\}/$(escape_for_replacement "$url")}"
    result="${result//\{\{version\}\}/$(escape_for_replacement "$version")}"
    result="${result//\{\{signature_short\}\}/$(escape_for_replacement "$signature_short")}"
    result="${result//\{\{site_url\}\}/$(escape_for_replacement "$POLIS_BASE_URL")}"
    result="${result//\{\{site_title\}\}/$(escape_for_replacement "$site_title")}"
    result="${result//\{\{css_path\}\}/$(escape_for_replacement "$css_path")}"
    result="${result//\{\{home_path\}\}/$(escape_for_replacement "$home_path")}"
    result="${result//\{\{author_name\}\}/$(escape_for_replacement "$author_name")}"
    result="${result//\{\{author_url\}\}/$(escape_for_replacement "$POLIS_BASE_URL")}"
    result="${result//\{\{year\}\}/$(escape_for_replacement "$(date +%Y)")}"
    result="${result//\{\{blessed_comments\}\}/$(escape_for_replacement "$blessed_comments")}"
    result="${result//\{\{blessed_count\}\}/$(escape_for_replacement "$blessed_count")}"
    result="${result//\{\{in_reply_to_url\}\}/$(escape_for_replacement "$in_reply_to_url")}"
    result="${result//\{\{root_post_url\}\}/$(escape_for_replacement "$root_post_url")}"

    # Append frontmatter as HTML comment (not full content to avoid duplication)
    # Extract frontmatter fields only (between --- lines, excluding the delimiters)
    local frontmatter_fields=$(echo "$content" | awk '/^---$/{if(++count==2) exit; next} count==1{print}')
    result+="
<!--
=== POLIS SOURCE ===
Source: ${url}
${frontmatter_fields}
=== END POLIS SOURCE ===
-->"

    # Write output
    echo "$result" > "$output_file"
    return 0  # Rendered
}

# Render index page
render_index() {
    local posts_list=""
    local post_count=0

    # Read public.jsonl, filter posts, sort by published date descending (latest first)
    if [ -f "$PUBLIC_INDEX" ]; then
        local sorted_posts
        sorted_posts=$(jq -s '[.[] | select(.type == "post" or .type == null)] | sort_by(.published) | reverse' "$PUBLIC_INDEX")

        local num_posts
        num_posts=$(echo "$sorted_posts" | jq 'length')

        for ((i=0; i<num_posts; i++)); do
            local path=$(echo "$sorted_posts" | jq -r ".[$i].path // empty")
            local title=$(echo "$sorted_posts" | jq -r ".[$i].title // \"Untitled\"")
            local published=$(echo "$sorted_posts" | jq -r ".[$i].published // empty")

            [ -z "$path" ] && continue

            local html_path="${path%.md}.html"
            local published_human=$(format_date_human "$published")

            posts_list+="            <li><a href=\"$html_path\">$title</a> <time>$published_human</time></li>
"
            ((++post_count))
        done
    fi

    # Get site info - prefer manifest.json, fallback to domain
    local site_title=""
    if [ -f "$MANIFEST" ]; then
        site_title=$(jq -r '.site_title // empty' "$MANIFEST" 2>/dev/null)
    fi
    if [ -z "$site_title" ]; then
        site_title="${POLIS_BASE_URL#https://}"
        site_title="${site_title#http://}"
    fi

    # Substitute template
    local result="${TEMPLATES[index]}"
    if [ -z "$result" ]; then
        error "Index template is empty. Check $THEMES_DIR/$ACTIVE_THEME/index.html or set active_theme in manifest.json"
    fi

    # Process {{> partial}} includes first
    result=$(render_partials "$result")

    # Process {{#section}}...{{/section}} loops (posts, comments)
    result=$(render_sections "$result")

    result="${result//\{\{site_title\}\}/$(escape_for_replacement "$site_title")}"
    result="${result//\{\{site_url\}\}/$(escape_for_replacement "$POLIS_BASE_URL")}"
    result="${result//\{\{posts_list\}\}/$(escape_for_replacement "$posts_list")}"
    result="${result//\{\{post_count\}\}/$(escape_for_replacement "$post_count")}"
    result="${result//\{\{year\}\}/$(escape_for_replacement "$(date +%Y)")}"

    echo "$result" > "index.html"
    info_human "  Written: index.html"
}

# Command: polis render
cmd_render() {
    local force=false

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --force)
                force=true
                shift
                ;;
            *)
                json_error "render" "INVALID_INPUT" "Unknown option: $1. Use: polis render [--force]"
                ;;
        esac
    done

    # Check initialization
    if [ ! -f "$WELL_KNOWN_DIR/polis" ]; then
        json_error "render" "INVALID_STATE" "Polis not initialized. Run 'polis init' first."
    fi

    # Check pandoc
    if ! command -v pandoc &>/dev/null; then
        json_error "render" "MISSING_DEPENDENCY" "pandoc is required for rendering. Install with: apt install pandoc (Linux) or brew install pandoc (macOS)"
    fi

    # Ensure active theme is set (select one if not)
    if [ -f "$MANIFEST" ]; then
        local saved_theme
        saved_theme=$(jq -r '.active_theme // empty' "$MANIFEST" 2>/dev/null)
        if [ -z "$saved_theme" ] || [ "$saved_theme" = "null" ]; then
            info_human "No active theme set - selecting theme..."
            select_theme
        fi
    else
        info_human "No manifest found - selecting theme..."
        select_theme
    fi

    # Load theme templates
    load_theme

    info_human "=== Render Configuration ==="
    info_human "Working directory: $(pwd)"
    info_human "POLIS_BASE_URL: $POLIS_BASE_URL"
    info_human "Posts dir: $POSTS_DIR"
    info_human "Comments dir: $COMMENTS_DIR"
    info_human "Blessed comments file: $BLESSED_COMMENTS"
    info_human "Active theme: $ACTIVE_THEME"

    # Show blessed-comments.json summary
    if [ -f "$BLESSED_COMMENTS" ]; then
        local bc_posts=$(jq -r '.comments | length' "$BLESSED_COMMENTS" 2>/dev/null || echo "0")
        info_human "Blessed comments: $bc_posts post(s) with blessed comments"
        if [ "$bc_posts" -gt 0 ]; then
            info_human "Posts with blessed comments:"
            jq -r '.comments[].post' "$BLESSED_COMMENTS" 2>/dev/null | while read -r p; do
                info_human "  - $p"
            done
        fi
    else
        info_human "Blessed comments: file not found"
    fi

    info_human "Theme loaded: $ACTIVE_THEME"

    local posts_rendered=0
    local posts_skipped=0
    local comments_rendered=0
    local comments_skipped=0

    info_human ""
    info_human "=== Rendering Posts ==="

    # Render posts
    if [ -d "$POSTS_DIR" ]; then
        while IFS= read -r post_file; do
            [ -z "$post_file" ] && continue
            info_human "Processing: $post_file"
            if render_file "$post_file" "post" "$force"; then
                ((++posts_rendered))
                info_human "  -> Rendered: ${post_file%.md}.html"
            else
                ((++posts_skipped))
                info_human "  -> Skipped (up to date)"
            fi
        done < <(find "$POSTS_DIR" -name "*.md" -not -path "*/.versions/*" -type f 2>/dev/null)
    else
        info_human "Posts directory not found: $POSTS_DIR"
    fi

    info_human ""
    info_human "=== Rendering Comments ==="

    # Render comments
    if [ -d "$COMMENTS_DIR" ]; then
        while IFS= read -r comment_file; do
            [ -z "$comment_file" ] && continue
            info_human "Processing: $comment_file"
            if render_file "$comment_file" "comment" "$force"; then
                ((++comments_rendered))
                info_human "  -> Rendered: ${comment_file%.md}.html"
            else
                ((++comments_skipped))
                info_human "  -> Skipped (up to date)"
            fi
        done < <(find "$COMMENTS_DIR" -name "*.md" -not -path "*/.versions/*" -type f 2>/dev/null)
    else
        info_human "Comments directory not found: $COMMENTS_DIR"
    fi

    info_human ""
    info_human "=== Generating Index ==="

    # Generate index
    render_index
    info_human "Generated: index.html"

    # Regenerate manifest.json
    generate_manifest true

    # Output
    if [ "$JSON_MODE" = true ]; then
        local result=$(jq -n \
            --argjson pr "$posts_rendered" \
            --argjson ps "$posts_skipped" \
            --argjson cr "$comments_rendered" \
            --argjson cs "$comments_skipped" \
            '{posts_rendered: $pr, posts_skipped: $ps, comments_rendered: $cr, comments_skipped: $cs, index_generated: true}')
        json_success "render" "$result"
    else
        echo ""
        success "Rendering complete!"
        info "  Posts rendered: $posts_rendered (skipped: $posts_skipped)"
        info "  Comments rendered: $comments_rendered (skipped: $comments_skipped)"
        info "  Index: index.html"
    fi
}

# Main command router
main() {
    # Parse global --json flag from start OR end of arguments
    # This allows both: polis --json <cmd> AND polis <cmd> [args] --json
    local args=("$@")
    local arg_count=${#args[@]}

    # Check for --json at start
    if [[ $arg_count -gt 0 && "${args[0]}" == "--json" ]]; then
        JSON_MODE=true
        args=("${args[@]:1}")  # Remove first element
        arg_count=${#args[@]}
    fi

    # Check for --json at end (if not already found and array not empty)
    if [[ "$JSON_MODE" != true && $arg_count -gt 0 ]]; then
        local last_idx=$((arg_count - 1))
        if [[ "${args[$last_idx]}" == "--json" ]]; then
            JSON_MODE=true
            unset 'args[last_idx]'  # Remove last element
        fi
    fi

    # Apply JSON mode settings
    if [[ "$JSON_MODE" == true ]]; then
        # Disable colors in JSON mode
        GREEN=''
        BLUE=''
        RED=''
        NC=''
    fi

    # Reconstruct positional parameters
    set -- "${args[@]}"

    local command="${1:-}"
    shift 2>/dev/null || true

    case "$command" in
        init)
            cmd_init "$@"
            ;;
        post)
            cmd_post "$@"
            ;;
        comment)
            cmd_comment "$@"
            ;;
        snippet)
            cmd_snippet "$@"
            ;;
        preview)
            cmd_preview "$@"
            ;;
        republish)
            cmd_republish "$@"
            ;;
        rebuild)
            cmd_rebuild "$@"
            ;;
        index)
            cmd_index "$@"
            ;;
        discover)
            cmd_discover "$@"
            ;;
        version)
            cmd_version "$@"
            ;;
        about)
            cmd_about "$@"
            ;;
        rotate-key)
            cmd_rotate_key "$@"
            ;;
        extract)
            cmd_get_version "$@"
            ;;
        blessing)
            cmd_blessing "$@"
            ;;
        follow)
            cmd_follow "$@"
            ;;
        unfollow)
            cmd_unfollow "$@"
            ;;
        migrate)
            cmd_migrate "$@"
            ;;
        register)
            cmd_register "$@"
            ;;
        unregister)
            cmd_unregister "$@"
            ;;
        notifications)
            cmd_notifications "$@"
            ;;
        migrations)
            case "$1" in
                apply)
                    shift
                    cmd_migrations_apply "$@"
                    ;;
                *)
                    error "Unknown migrations subcommand: $1. Use: polis migrations apply"
                    ;;
            esac
            ;;
        render)
            cmd_render "$@"
            ;;
        clone)
            cmd_clone "$@"
            ;;
        *)
            echo "Polis - Decentralized Social Network CLI"
            echo ""
            echo "Usage:"
            echo "  polis [--json] <command> [options]"
            echo ""
            echo "Global Flags:"
            echo "  --json                          Output results in JSON format (for scripting).  Supported by most but not all commands below."
            echo ""
            echo "Commands related to creating or viewing content:"
            echo "  polis post <file>               Create a new post"
            echo "  polis post -                    Post from stdin (use --filename, --title for options)"
            echo "  polis comment <file> [url]      Create a comment on a post"
            echo "  polis comment - <url>           Comment from stdin (use --filename, --title for options)"
            echo "  polis snippet <file>            Publish a reusable template snippet"
            echo "  polis snippet -                 Snippet from stdin (use --filename, --title for options)"
            echo "  polis republish <file>          Update an already-published file (auto-detects type)"
            echo "  polis preview <url>             Preview a post or comment at a URL with signature verification"
            echo "  polis extract <file> <hash>     Reconstruct a specific version of a file"
            echo ""
            echo "Commands related to requesting, reviewing, or granting blessings on comments:"
            echo "  polis blessing requests         List pending blessing requests; use 'polis preview' to see details"
            echo "  polis blessing grant <hash>     Grant a blessing request by content hash"
            echo "  polis blessing deny <hash>      Deny a blessing request by content hash"
            echo "  polis blessing beseech <hash>   Re-request blessing by content hash"
            echo "  polis blessing sync             Sync auto-blessed comments from discovery service"
            echo ""
            echo "Commands related to following or unfollowing an author:"
            echo "  polis follow <author-url>       Follow an author (auto-bless their comments)"
            echo "  polis unfollow <author-url>     Unfollow an author"
            echo ""
            echo "Commands related to content discovery:"
            echo "  polis discover                  Check followed authors for new content"
            echo "  polis discover --author <url>   Check a specific author"
            echo "  polis discover --since <date>   Show items since date (ignores last_checked)"
            echo ""
            echo "Commands related to notifications:"
            echo "  polis notifications             List unread notifications"
            echo "  polis notifications list        List notifications (--type <types>, --all)"
            echo "  polis notifications read <id>   Mark notification as read (--all for all)"
            echo "  polis notifications dismiss <id>"
            echo "                                  Dismiss notification (--older-than 30d for old ones)"
            echo "  polis notifications sync        Sync notifications from discovery service (--reset for full)"
            echo "  polis notifications config      Configure preferences (--poll-interval, --enable, --disable, --mute)"
            echo ""
            echo "Commands related to site administration:"
            echo "  polis register                  List your site in the public directory (makes content discoverable)"
            echo "  polis unregister [--force]      Unregister site (hard delete, requires confirmation)"
            echo "  polis render [--force]          Render markdown posts and comments to HTML"
            echo "  polis migrate <new-domain>      Migrate all content to a new domain (re-signs files, updates DB)"
            echo "  polis migrations apply          Apply discovered domain migrations to local files"
            echo ""
            echo "Commands related to cloning remote polis sites:"
            echo "  polis clone <url> [dir]         Clone a public polis site for local analysis"
            echo "  polis clone <url> --full        Re-download all content (ignore cached state)"
            echo "  polis clone <url> --diff        Only download new/changed content (default if previously cloned)"
            echo ""
            echo "Commands related to local configuration management:"
            echo "  polis init [options]            Initialize Polis directory structure"
            echo "    --site-title <title>          Site display name (stored in manifest.json)"
            echo "    --register                    Auto-register with discovery service after init"
            echo "    --keys-dir <path>             Custom keys directory (default: .polis/keys)"
            echo "    --posts-dir <path>            Custom posts directory (default: posts)"
            echo "    --comments-dir <path>         Custom comments directory (default: comments)"
            echo "    --snippets-dir <path>         Custom snippets directory (default: snippets)"
            echo "    --versions-dir <path>         Custom versions directory (default: .versions)"
            echo "  polis rebuild --posts|--comments|--notifications|--all"
            echo "                                  Rebuild indexes and reset state (auto-regenerates manifest)"
            echo "  polis index                     View index (JSONL; use --json for grouped)"
            echo "  polis version                   Print CLI version"
            echo "  polis about                     Show site, versions, config, keys, discovery info"
            echo "  polis rotate-key [--delete-old-key]"
            echo "                                  Generate new keypair and re-sign all content"
            echo ""
            echo "Polis includes support for stdin:"
            echo "  Pipe content directly without creating temporary files:"
            echo "    echo '# My Post' | polis post -"
            echo "    echo '# Reply' | polis comment - https://example.com/post.md"
            echo "    curl -s https://example.com/draft.md | polis post - --filename final.md"
            echo "    polis post - --title 'My Title' --filename custom.md < content.txt"
            echo ""
            echo "Polis commands can output results as JSON for scripting and testing:"
            echo "  When --json is enabled:"
            echo "    - Output is valid JSON to stdout (success) or stderr (errors)"
            echo "    - Interactive prompts are auto-skipped with logged defaults"
            echo "    - ANSI color codes are disabled"
            echo "    - Exit codes: 0 (success) or 1 (error)"
            echo ""
            echo "  Example:"
            echo "    polis --json post my-post.md | jq -r '.data.content_hash'"
            echo "    polis --json comment my-comment.md https://example.com/post.md"
            echo "    echo '# Test' | polis --json post - | jq"
            echo ""
            exit 1
            ;;
    esac
}

main "$@"
